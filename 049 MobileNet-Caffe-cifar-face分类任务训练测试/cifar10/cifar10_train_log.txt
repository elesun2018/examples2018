Log file created at: 2018/06/25 08:50:02
Running on machine: ubuntu
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0625 08:50:02.737694 55699 caffe.cpp:211] Use CPU.
I0625 08:50:02.738327 55699 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 100
base_lr: 0.0001
display: 50
max_iter: 10000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 5000
snapshot: 2000
snapshot_prefix: "/home/sun/MobileNet-Caffe-master/cifar10/model/sun_mobilenet"
solver_mode: CPU
net: "/home/sun/MobileNet-Caffe-master/cifar10/mobilenet_train.prototxt"
train_state {
  level: 0
  stage: ""
}
I0625 08:50:02.738615 55699 solver.cpp:87] Creating training net from net file: /home/sun/MobileNet-Caffe-master/cifar10/mobilenet_train.prototxt
I0625 08:50:02.742029 55699 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/sun/MobileNet-Caffe-master/cifar10/mobilenet_train.prototxt
I0625 08:50:02.742097 55699 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0625 08:50:02.742553 55699 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0625 08:50:02.742810 55699 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer top1/acc
I0625 08:50:02.742872 55699 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer top5/acc
I0625 08:50:02.744132 55699 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "/home/sun/MobileNet-Caffe-master/cifar10/mean/mean.binaryproto"
  }
  data_param {
    source: "/home/sun/MobileNet-Caffe-master/cifar10/lmdb/cifar10_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "Convolution"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "Convolution"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "Convolution"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "Convolution"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "Convolution"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "Convolution"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "Convolution"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "Convolution"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "Convolution"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "Convolution"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "Convolution"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "Convolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "cifarfc7"
  type: "Convolution"
  bottom: "pool6"
  top: "cifarfc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cifarfc7"
  bottom: "label"
  top: "loss"
}
I0625 08:50:02.750284 55699 layer_factory.hpp:77] Creating layer data
I0625 08:50:02.750705 55699 db_lmdb.cpp:35] Opened lmdb /home/sun/MobileNet-Caffe-master/cifar10/lmdb/cifar10_train_lmdb
I0625 08:50:02.751013 55699 net.cpp:84] Creating Layer data
I0625 08:50:02.751118 55699 net.cpp:380] data -> data
I0625 08:50:02.751199 55699 net.cpp:380] data -> label
I0625 08:50:02.751303 55699 data_transformer.cpp:25] Loading mean file from: /home/sun/MobileNet-Caffe-master/cifar10/mean/mean.binaryproto
I0625 08:50:02.751945 55699 data_layer.cpp:45] output data size: 64,3,32,32
I0625 08:50:02.756585 55699 net.cpp:122] Setting up data
I0625 08:50:02.756691 55699 net.cpp:129] Top shape: 64 3 32 32 (196608)
I0625 08:50:02.756736 55699 net.cpp:129] Top shape: 64 (64)
I0625 08:50:02.756772 55699 net.cpp:137] Memory required for data: 786688
I0625 08:50:02.756821 55699 layer_factory.hpp:77] Creating layer conv1
I0625 08:50:02.756887 55699 net.cpp:84] Creating Layer conv1
I0625 08:50:02.756932 55699 net.cpp:406] conv1 <- data
I0625 08:50:02.756986 55699 net.cpp:380] conv1 -> conv1
I0625 08:50:02.757262 55699 net.cpp:122] Setting up conv1
I0625 08:50:02.757316 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:02.757352 55699 net.cpp:137] Memory required for data: 2883840
I0625 08:50:02.757406 55699 layer_factory.hpp:77] Creating layer conv1/bn
I0625 08:50:02.757449 55699 net.cpp:84] Creating Layer conv1/bn
I0625 08:50:02.757491 55699 net.cpp:406] conv1/bn <- conv1
I0625 08:50:02.757511 55699 net.cpp:367] conv1/bn -> conv1 (in-place)
I0625 08:50:02.757558 55699 net.cpp:122] Setting up conv1/bn
I0625 08:50:02.757603 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:02.757643 55699 net.cpp:137] Memory required for data: 4980992
I0625 08:50:02.757668 55699 layer_factory.hpp:77] Creating layer conv1/scale
I0625 08:50:02.757740 55699 net.cpp:84] Creating Layer conv1/scale
I0625 08:50:02.757814 55699 net.cpp:406] conv1/scale <- conv1
I0625 08:50:02.757846 55699 net.cpp:367] conv1/scale -> conv1 (in-place)
I0625 08:50:02.757941 55699 layer_factory.hpp:77] Creating layer conv1/scale
I0625 08:50:02.758095 55699 net.cpp:122] Setting up conv1/scale
I0625 08:50:02.758157 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:02.758169 55699 net.cpp:137] Memory required for data: 7078144
I0625 08:50:02.758198 55699 layer_factory.hpp:77] Creating layer relu1
I0625 08:50:02.758224 55699 net.cpp:84] Creating Layer relu1
I0625 08:50:02.758235 55699 net.cpp:406] relu1 <- conv1
I0625 08:50:02.758247 55699 net.cpp:367] relu1 -> conv1 (in-place)
I0625 08:50:02.758294 55699 net.cpp:122] Setting up relu1
I0625 08:50:02.758338 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:02.758373 55699 net.cpp:137] Memory required for data: 9175296
I0625 08:50:02.758388 55699 layer_factory.hpp:77] Creating layer conv2_1/dw
I0625 08:50:02.758435 55699 net.cpp:84] Creating Layer conv2_1/dw
I0625 08:50:02.758476 55699 net.cpp:406] conv2_1/dw <- conv1
I0625 08:50:02.758559 55699 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0625 08:50:02.758711 55699 net.cpp:122] Setting up conv2_1/dw
I0625 08:50:02.758769 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:02.758849 55699 net.cpp:137] Memory required for data: 11272448
I0625 08:50:02.758896 55699 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0625 08:50:02.758955 55699 net.cpp:84] Creating Layer conv2_1/dw/bn
I0625 08:50:02.758997 55699 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0625 08:50:02.759061 55699 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0625 08:50:02.759135 55699 net.cpp:122] Setting up conv2_1/dw/bn
I0625 08:50:02.759181 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:02.759217 55699 net.cpp:137] Memory required for data: 13369600
I0625 08:50:02.759266 55699 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0625 08:50:02.759330 55699 net.cpp:84] Creating Layer conv2_1/dw/scale
I0625 08:50:02.759377 55699 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0625 08:50:02.759419 55699 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0625 08:50:02.759481 55699 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0625 08:50:02.759558 55699 net.cpp:122] Setting up conv2_1/dw/scale
I0625 08:50:02.759608 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:02.759652 55699 net.cpp:137] Memory required for data: 15466752
I0625 08:50:02.759694 55699 layer_factory.hpp:77] Creating layer relu2_1/dw
I0625 08:50:02.759752 55699 net.cpp:84] Creating Layer relu2_1/dw
I0625 08:50:02.759798 55699 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0625 08:50:02.759840 55699 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0625 08:50:02.759888 55699 net.cpp:122] Setting up relu2_1/dw
I0625 08:50:02.759935 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:02.759970 55699 net.cpp:137] Memory required for data: 17563904
I0625 08:50:02.760006 55699 layer_factory.hpp:77] Creating layer conv2_1/sep
I0625 08:50:02.760072 55699 net.cpp:84] Creating Layer conv2_1/sep
I0625 08:50:02.760110 55699 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0625 08:50:02.760219 55699 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0625 08:50:02.760424 55699 net.cpp:122] Setting up conv2_1/sep
I0625 08:50:02.760479 55699 net.cpp:129] Top shape: 64 64 16 16 (1048576)
I0625 08:50:02.760514 55699 net.cpp:137] Memory required for data: 21758208
I0625 08:50:02.760553 55699 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0625 08:50:02.760594 55699 net.cpp:84] Creating Layer conv2_1/sep/bn
I0625 08:50:02.760632 55699 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0625 08:50:02.760658 55699 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0625 08:50:02.760694 55699 net.cpp:122] Setting up conv2_1/sep/bn
I0625 08:50:02.760736 55699 net.cpp:129] Top shape: 64 64 16 16 (1048576)
I0625 08:50:02.760829 55699 net.cpp:137] Memory required for data: 25952512
I0625 08:50:02.760874 55699 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0625 08:50:02.760915 55699 net.cpp:84] Creating Layer conv2_1/sep/scale
I0625 08:50:02.760958 55699 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0625 08:50:02.761019 55699 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0625 08:50:02.761096 55699 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0625 08:50:02.761214 55699 net.cpp:122] Setting up conv2_1/sep/scale
I0625 08:50:02.761265 55699 net.cpp:129] Top shape: 64 64 16 16 (1048576)
I0625 08:50:02.761302 55699 net.cpp:137] Memory required for data: 30146816
I0625 08:50:02.761350 55699 layer_factory.hpp:77] Creating layer relu2_1/sep
I0625 08:50:02.761409 55699 net.cpp:84] Creating Layer relu2_1/sep
I0625 08:50:02.761458 55699 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0625 08:50:02.761499 55699 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0625 08:50:02.761545 55699 net.cpp:122] Setting up relu2_1/sep
I0625 08:50:02.761586 55699 net.cpp:129] Top shape: 64 64 16 16 (1048576)
I0625 08:50:02.761626 55699 net.cpp:137] Memory required for data: 34341120
I0625 08:50:02.761662 55699 layer_factory.hpp:77] Creating layer conv2_2/dw
I0625 08:50:02.761708 55699 net.cpp:84] Creating Layer conv2_2/dw
I0625 08:50:02.761801 55699 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0625 08:50:02.761848 55699 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0625 08:50:02.761976 55699 net.cpp:122] Setting up conv2_2/dw
I0625 08:50:02.762022 55699 net.cpp:129] Top shape: 64 64 8 8 (262144)
I0625 08:50:02.762065 55699 net.cpp:137] Memory required for data: 35389696
I0625 08:50:02.762089 55699 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0625 08:50:02.762137 55699 net.cpp:84] Creating Layer conv2_2/dw/bn
I0625 08:50:02.762177 55699 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0625 08:50:02.762218 55699 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0625 08:50:02.762291 55699 net.cpp:122] Setting up conv2_2/dw/bn
I0625 08:50:02.762336 55699 net.cpp:129] Top shape: 64 64 8 8 (262144)
I0625 08:50:02.762370 55699 net.cpp:137] Memory required for data: 36438272
I0625 08:50:02.762413 55699 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0625 08:50:02.762457 55699 net.cpp:84] Creating Layer conv2_2/dw/scale
I0625 08:50:02.762496 55699 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0625 08:50:02.762547 55699 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0625 08:50:02.762606 55699 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0625 08:50:02.762682 55699 net.cpp:122] Setting up conv2_2/dw/scale
I0625 08:50:02.762730 55699 net.cpp:129] Top shape: 64 64 8 8 (262144)
I0625 08:50:02.762827 55699 net.cpp:137] Memory required for data: 37486848
I0625 08:50:02.762876 55699 layer_factory.hpp:77] Creating layer relu2_2/dw
I0625 08:50:02.762923 55699 net.cpp:84] Creating Layer relu2_2/dw
I0625 08:50:02.762970 55699 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0625 08:50:02.763010 55699 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0625 08:50:02.763056 55699 net.cpp:122] Setting up relu2_2/dw
I0625 08:50:02.763095 55699 net.cpp:129] Top shape: 64 64 8 8 (262144)
I0625 08:50:02.763129 55699 net.cpp:137] Memory required for data: 38535424
I0625 08:50:02.763164 55699 layer_factory.hpp:77] Creating layer conv2_2/sep
I0625 08:50:02.763218 55699 net.cpp:84] Creating Layer conv2_2/sep
I0625 08:50:02.763259 55699 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0625 08:50:02.763303 55699 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0625 08:50:02.763753 55699 net.cpp:122] Setting up conv2_2/sep
I0625 08:50:02.763804 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.763839 55699 net.cpp:137] Memory required for data: 40632576
I0625 08:50:02.763888 55699 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0625 08:50:02.763950 55699 net.cpp:84] Creating Layer conv2_2/sep/bn
I0625 08:50:02.764003 55699 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0625 08:50:02.764045 55699 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0625 08:50:02.764114 55699 net.cpp:122] Setting up conv2_2/sep/bn
I0625 08:50:02.764165 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.764200 55699 net.cpp:137] Memory required for data: 42729728
I0625 08:50:02.764248 55699 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0625 08:50:02.764302 55699 net.cpp:84] Creating Layer conv2_2/sep/scale
I0625 08:50:02.764348 55699 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0625 08:50:02.764407 55699 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0625 08:50:02.764464 55699 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0625 08:50:02.764552 55699 net.cpp:122] Setting up conv2_2/sep/scale
I0625 08:50:02.764613 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.764652 55699 net.cpp:137] Memory required for data: 44826880
I0625 08:50:02.764693 55699 layer_factory.hpp:77] Creating layer relu2_2/sep
I0625 08:50:02.764734 55699 net.cpp:84] Creating Layer relu2_2/sep
I0625 08:50:02.764772 55699 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0625 08:50:02.764823 55699 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0625 08:50:02.764873 55699 net.cpp:122] Setting up relu2_2/sep
I0625 08:50:02.764945 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.764989 55699 net.cpp:137] Memory required for data: 46924032
I0625 08:50:02.765075 55699 layer_factory.hpp:77] Creating layer conv3_1/dw
I0625 08:50:02.765125 55699 net.cpp:84] Creating Layer conv3_1/dw
I0625 08:50:02.766078 55699 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0625 08:50:02.766127 55699 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0625 08:50:02.766260 55699 net.cpp:122] Setting up conv3_1/dw
I0625 08:50:02.766307 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.766341 55699 net.cpp:137] Memory required for data: 49021184
I0625 08:50:02.766381 55699 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0625 08:50:02.766422 55699 net.cpp:84] Creating Layer conv3_1/dw/bn
I0625 08:50:02.766458 55699 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0625 08:50:02.766507 55699 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0625 08:50:02.766573 55699 net.cpp:122] Setting up conv3_1/dw/bn
I0625 08:50:02.766618 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.766652 55699 net.cpp:137] Memory required for data: 51118336
I0625 08:50:02.766702 55699 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0625 08:50:02.766746 55699 net.cpp:84] Creating Layer conv3_1/dw/scale
I0625 08:50:02.766830 55699 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0625 08:50:02.766898 55699 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0625 08:50:02.766955 55699 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0625 08:50:02.767024 55699 net.cpp:122] Setting up conv3_1/dw/scale
I0625 08:50:02.767069 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.767103 55699 net.cpp:137] Memory required for data: 53215488
I0625 08:50:02.767144 55699 layer_factory.hpp:77] Creating layer relu3_1/dw
I0625 08:50:02.767184 55699 net.cpp:84] Creating Layer relu3_1/dw
I0625 08:50:02.767220 55699 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0625 08:50:02.767259 55699 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0625 08:50:02.767302 55699 net.cpp:122] Setting up relu3_1/dw
I0625 08:50:02.767340 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.767374 55699 net.cpp:137] Memory required for data: 55312640
I0625 08:50:02.767408 55699 layer_factory.hpp:77] Creating layer conv3_1/sep
I0625 08:50:02.767462 55699 net.cpp:84] Creating Layer conv3_1/sep
I0625 08:50:02.767503 55699 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0625 08:50:02.767544 55699 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0625 08:50:02.768411 55699 net.cpp:122] Setting up conv3_1/sep
I0625 08:50:02.768461 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.768497 55699 net.cpp:137] Memory required for data: 57409792
I0625 08:50:02.768535 55699 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0625 08:50:02.768591 55699 net.cpp:84] Creating Layer conv3_1/sep/bn
I0625 08:50:02.768631 55699 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0625 08:50:02.768672 55699 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0625 08:50:02.768744 55699 net.cpp:122] Setting up conv3_1/sep/bn
I0625 08:50:02.768822 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.768862 55699 net.cpp:137] Memory required for data: 59506944
I0625 08:50:02.768906 55699 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0625 08:50:02.768959 55699 net.cpp:84] Creating Layer conv3_1/sep/scale
I0625 08:50:02.769001 55699 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0625 08:50:02.769052 55699 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0625 08:50:02.769107 55699 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0625 08:50:02.769182 55699 net.cpp:122] Setting up conv3_1/sep/scale
I0625 08:50:02.769228 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.769263 55699 net.cpp:137] Memory required for data: 61604096
I0625 08:50:02.769304 55699 layer_factory.hpp:77] Creating layer relu3_1/sep
I0625 08:50:02.769343 55699 net.cpp:84] Creating Layer relu3_1/sep
I0625 08:50:02.769379 55699 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0625 08:50:02.769428 55699 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0625 08:50:02.769474 55699 net.cpp:122] Setting up relu3_1/sep
I0625 08:50:02.769544 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:02.769582 55699 net.cpp:137] Memory required for data: 63701248
I0625 08:50:02.769616 55699 layer_factory.hpp:77] Creating layer conv3_2/dw
I0625 08:50:02.769672 55699 net.cpp:84] Creating Layer conv3_2/dw
I0625 08:50:02.769696 55699 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0625 08:50:02.769711 55699 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0625 08:50:02.769829 55699 net.cpp:122] Setting up conv3_2/dw
I0625 08:50:02.769850 55699 net.cpp:129] Top shape: 64 128 4 4 (131072)
I0625 08:50:02.769858 55699 net.cpp:137] Memory required for data: 64225536
I0625 08:50:02.769870 55699 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0625 08:50:02.769883 55699 net.cpp:84] Creating Layer conv3_2/dw/bn
I0625 08:50:02.769892 55699 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0625 08:50:02.769912 55699 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0625 08:50:02.769942 55699 net.cpp:122] Setting up conv3_2/dw/bn
I0625 08:50:02.769956 55699 net.cpp:129] Top shape: 64 128 4 4 (131072)
I0625 08:50:02.769964 55699 net.cpp:137] Memory required for data: 64749824
I0625 08:50:02.769978 55699 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0625 08:50:02.769991 55699 net.cpp:84] Creating Layer conv3_2/dw/scale
I0625 08:50:02.770000 55699 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0625 08:50:02.770010 55699 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0625 08:50:02.770037 55699 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0625 08:50:02.770064 55699 net.cpp:122] Setting up conv3_2/dw/scale
I0625 08:50:02.770077 55699 net.cpp:129] Top shape: 64 128 4 4 (131072)
I0625 08:50:02.770095 55699 net.cpp:137] Memory required for data: 65274112
I0625 08:50:02.770108 55699 layer_factory.hpp:77] Creating layer relu3_2/dw
I0625 08:50:02.770139 55699 net.cpp:84] Creating Layer relu3_2/dw
I0625 08:50:02.770153 55699 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0625 08:50:02.770164 55699 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0625 08:50:02.770176 55699 net.cpp:122] Setting up relu3_2/dw
I0625 08:50:02.770187 55699 net.cpp:129] Top shape: 64 128 4 4 (131072)
I0625 08:50:02.770195 55699 net.cpp:137] Memory required for data: 65798400
I0625 08:50:02.770202 55699 layer_factory.hpp:77] Creating layer conv3_2/sep
I0625 08:50:02.770216 55699 net.cpp:84] Creating Layer conv3_2/sep
I0625 08:50:02.770226 55699 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0625 08:50:02.770246 55699 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0625 08:50:02.772085 55699 net.cpp:122] Setting up conv3_2/sep
I0625 08:50:02.772141 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.772153 55699 net.cpp:137] Memory required for data: 66846976
I0625 08:50:02.772172 55699 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0625 08:50:02.772227 55699 net.cpp:84] Creating Layer conv3_2/sep/bn
I0625 08:50:02.772271 55699 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0625 08:50:02.772325 55699 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0625 08:50:02.772416 55699 net.cpp:122] Setting up conv3_2/sep/bn
I0625 08:50:02.772440 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.772449 55699 net.cpp:137] Memory required for data: 67895552
I0625 08:50:02.772464 55699 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0625 08:50:02.772539 55699 net.cpp:84] Creating Layer conv3_2/sep/scale
I0625 08:50:02.772583 55699 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0625 08:50:02.772603 55699 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0625 08:50:02.772651 55699 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0625 08:50:02.772756 55699 net.cpp:122] Setting up conv3_2/sep/scale
I0625 08:50:02.772805 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.772840 55699 net.cpp:137] Memory required for data: 68944128
I0625 08:50:02.772866 55699 layer_factory.hpp:77] Creating layer relu3_2/sep
I0625 08:50:02.772907 55699 net.cpp:84] Creating Layer relu3_2/sep
I0625 08:50:02.773947 55699 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0625 08:50:02.774044 55699 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0625 08:50:02.774096 55699 net.cpp:122] Setting up relu3_2/sep
I0625 08:50:02.774121 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.774132 55699 net.cpp:137] Memory required for data: 69992704
I0625 08:50:02.774145 55699 layer_factory.hpp:77] Creating layer conv4_1/dw
I0625 08:50:02.774164 55699 net.cpp:84] Creating Layer conv4_1/dw
I0625 08:50:02.774199 55699 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0625 08:50:02.774241 55699 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0625 08:50:02.774468 55699 net.cpp:122] Setting up conv4_1/dw
I0625 08:50:02.774518 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.774529 55699 net.cpp:137] Memory required for data: 71041280
I0625 08:50:02.774617 55699 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0625 08:50:02.774672 55699 net.cpp:84] Creating Layer conv4_1/dw/bn
I0625 08:50:02.774714 55699 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0625 08:50:02.774729 55699 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0625 08:50:02.774778 55699 net.cpp:122] Setting up conv4_1/dw/bn
I0625 08:50:02.774797 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.774806 55699 net.cpp:137] Memory required for data: 72089856
I0625 08:50:02.774843 55699 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0625 08:50:02.774889 55699 net.cpp:84] Creating Layer conv4_1/dw/scale
I0625 08:50:02.774901 55699 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0625 08:50:02.774924 55699 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0625 08:50:02.774950 55699 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0625 08:50:02.774984 55699 net.cpp:122] Setting up conv4_1/dw/scale
I0625 08:50:02.775001 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.775018 55699 net.cpp:137] Memory required for data: 73138432
I0625 08:50:02.775032 55699 layer_factory.hpp:77] Creating layer relu4_1/dw
I0625 08:50:02.775050 55699 net.cpp:84] Creating Layer relu4_1/dw
I0625 08:50:02.775060 55699 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0625 08:50:02.775085 55699 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0625 08:50:02.775300 55699 net.cpp:122] Setting up relu4_1/dw
I0625 08:50:02.775352 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.775387 55699 net.cpp:137] Memory required for data: 74187008
I0625 08:50:02.775421 55699 layer_factory.hpp:77] Creating layer conv4_1/sep
I0625 08:50:02.775476 55699 net.cpp:84] Creating Layer conv4_1/sep
I0625 08:50:02.775518 55699 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0625 08:50:02.775562 55699 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0625 08:50:02.778762 55699 net.cpp:122] Setting up conv4_1/sep
I0625 08:50:02.778838 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.778852 55699 net.cpp:137] Memory required for data: 75235584
I0625 08:50:02.778897 55699 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0625 08:50:02.778946 55699 net.cpp:84] Creating Layer conv4_1/sep/bn
I0625 08:50:02.778985 55699 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0625 08:50:02.779009 55699 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0625 08:50:02.779049 55699 net.cpp:122] Setting up conv4_1/sep/bn
I0625 08:50:02.779101 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.779139 55699 net.cpp:137] Memory required for data: 76284160
I0625 08:50:02.779167 55699 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0625 08:50:02.779191 55699 net.cpp:84] Creating Layer conv4_1/sep/scale
I0625 08:50:02.779203 55699 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0625 08:50:02.779222 55699 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0625 08:50:02.779255 55699 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0625 08:50:02.779319 55699 net.cpp:122] Setting up conv4_1/sep/scale
I0625 08:50:02.779364 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.779398 55699 net.cpp:137] Memory required for data: 77332736
I0625 08:50:02.779435 55699 layer_factory.hpp:77] Creating layer relu4_1/sep
I0625 08:50:02.779501 55699 net.cpp:84] Creating Layer relu4_1/sep
I0625 08:50:02.779552 55699 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0625 08:50:02.779594 55699 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0625 08:50:02.779639 55699 net.cpp:122] Setting up relu4_1/sep
I0625 08:50:02.779678 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:02.779711 55699 net.cpp:137] Memory required for data: 78381312
I0625 08:50:02.779727 55699 layer_factory.hpp:77] Creating layer conv4_2/dw
I0625 08:50:02.779767 55699 net.cpp:84] Creating Layer conv4_2/dw
I0625 08:50:02.779805 55699 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0625 08:50:02.779837 55699 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0625 08:50:02.780045 55699 net.cpp:122] Setting up conv4_2/dw
I0625 08:50:02.780094 55699 net.cpp:129] Top shape: 64 256 2 2 (65536)
I0625 08:50:02.780129 55699 net.cpp:137] Memory required for data: 78643456
I0625 08:50:02.780153 55699 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0625 08:50:02.780169 55699 net.cpp:84] Creating Layer conv4_2/dw/bn
I0625 08:50:02.780201 55699 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0625 08:50:02.780225 55699 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0625 08:50:02.780258 55699 net.cpp:122] Setting up conv4_2/dw/bn
I0625 08:50:02.780299 55699 net.cpp:129] Top shape: 64 256 2 2 (65536)
I0625 08:50:02.780333 55699 net.cpp:137] Memory required for data: 78905600
I0625 08:50:02.780361 55699 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0625 08:50:02.780403 55699 net.cpp:84] Creating Layer conv4_2/dw/scale
I0625 08:50:02.780441 55699 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0625 08:50:02.780465 55699 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0625 08:50:02.780491 55699 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0625 08:50:02.780625 55699 net.cpp:122] Setting up conv4_2/dw/scale
I0625 08:50:02.780675 55699 net.cpp:129] Top shape: 64 256 2 2 (65536)
I0625 08:50:02.780695 55699 net.cpp:137] Memory required for data: 79167744
I0625 08:50:02.780710 55699 layer_factory.hpp:77] Creating layer relu4_2/dw
I0625 08:50:02.780747 55699 net.cpp:84] Creating Layer relu4_2/dw
I0625 08:50:02.780784 55699 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0625 08:50:02.780807 55699 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0625 08:50:02.780848 55699 net.cpp:122] Setting up relu4_2/dw
I0625 08:50:02.780887 55699 net.cpp:129] Top shape: 64 256 2 2 (65536)
I0625 08:50:02.780921 55699 net.cpp:137] Memory required for data: 79429888
I0625 08:50:02.780956 55699 layer_factory.hpp:77] Creating layer conv4_2/sep
I0625 08:50:02.780998 55699 net.cpp:84] Creating Layer conv4_2/sep
I0625 08:50:02.781038 55699 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0625 08:50:02.781111 55699 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0625 08:50:02.788750 55699 net.cpp:122] Setting up conv4_2/sep
I0625 08:50:02.788805 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.788825 55699 net.cpp:137] Memory required for data: 79954176
I0625 08:50:02.788838 55699 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0625 08:50:02.788882 55699 net.cpp:84] Creating Layer conv4_2/sep/bn
I0625 08:50:02.788923 55699 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0625 08:50:02.788964 55699 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0625 08:50:02.789029 55699 net.cpp:122] Setting up conv4_2/sep/bn
I0625 08:50:02.789077 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.789110 55699 net.cpp:137] Memory required for data: 80478464
I0625 08:50:02.789153 55699 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0625 08:50:02.789196 55699 net.cpp:84] Creating Layer conv4_2/sep/scale
I0625 08:50:02.789234 55699 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0625 08:50:02.789273 55699 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0625 08:50:02.805136 55699 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0625 08:50:02.805254 55699 net.cpp:122] Setting up conv4_2/sep/scale
I0625 08:50:02.805315 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.805351 55699 net.cpp:137] Memory required for data: 81002752
I0625 08:50:02.805492 55699 layer_factory.hpp:77] Creating layer relu4_2/sep
I0625 08:50:02.805541 55699 net.cpp:84] Creating Layer relu4_2/sep
I0625 08:50:02.805589 55699 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0625 08:50:02.805649 55699 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0625 08:50:02.805696 55699 net.cpp:122] Setting up relu4_2/sep
I0625 08:50:02.805766 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.805801 55699 net.cpp:137] Memory required for data: 81527040
I0625 08:50:02.805820 55699 layer_factory.hpp:77] Creating layer conv5_1/dw
I0625 08:50:02.805840 55699 net.cpp:84] Creating Layer conv5_1/dw
I0625 08:50:02.805874 55699 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0625 08:50:02.805959 55699 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0625 08:50:02.806242 55699 net.cpp:122] Setting up conv5_1/dw
I0625 08:50:02.806289 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.806329 55699 net.cpp:137] Memory required for data: 82051328
I0625 08:50:02.806390 55699 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0625 08:50:02.806447 55699 net.cpp:84] Creating Layer conv5_1/dw/bn
I0625 08:50:02.806465 55699 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0625 08:50:02.806478 55699 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0625 08:50:02.806531 55699 net.cpp:122] Setting up conv5_1/dw/bn
I0625 08:50:02.806563 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.806573 55699 net.cpp:137] Memory required for data: 82575616
I0625 08:50:02.806591 55699 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0625 08:50:02.806612 55699 net.cpp:84] Creating Layer conv5_1/dw/scale
I0625 08:50:02.806623 55699 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0625 08:50:02.806635 55699 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0625 08:50:02.806664 55699 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0625 08:50:02.806722 55699 net.cpp:122] Setting up conv5_1/dw/scale
I0625 08:50:02.806746 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.806754 55699 net.cpp:137] Memory required for data: 83099904
I0625 08:50:02.806767 55699 layer_factory.hpp:77] Creating layer relu5_1/dw
I0625 08:50:02.806782 55699 net.cpp:84] Creating Layer relu5_1/dw
I0625 08:50:02.806790 55699 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0625 08:50:02.806807 55699 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0625 08:50:02.806820 55699 net.cpp:122] Setting up relu5_1/dw
I0625 08:50:02.806831 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.806839 55699 net.cpp:137] Memory required for data: 83624192
I0625 08:50:02.806848 55699 layer_factory.hpp:77] Creating layer conv5_1/sep
I0625 08:50:02.806869 55699 net.cpp:84] Creating Layer conv5_1/sep
I0625 08:50:02.806946 55699 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0625 08:50:02.806962 55699 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0625 08:50:02.820046 55699 net.cpp:122] Setting up conv5_1/sep
I0625 08:50:02.820121 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.820156 55699 net.cpp:137] Memory required for data: 84148480
I0625 08:50:02.820199 55699 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0625 08:50:02.820243 55699 net.cpp:84] Creating Layer conv5_1/sep/bn
I0625 08:50:02.820282 55699 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0625 08:50:02.820333 55699 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0625 08:50:02.820459 55699 net.cpp:122] Setting up conv5_1/sep/bn
I0625 08:50:02.820508 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.820542 55699 net.cpp:137] Memory required for data: 84672768
I0625 08:50:02.820600 55699 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0625 08:50:02.820675 55699 net.cpp:84] Creating Layer conv5_1/sep/scale
I0625 08:50:02.820720 55699 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0625 08:50:02.820761 55699 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0625 08:50:02.820857 55699 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0625 08:50:02.820958 55699 net.cpp:122] Setting up conv5_1/sep/scale
I0625 08:50:02.821069 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.821091 55699 net.cpp:137] Memory required for data: 85197056
I0625 08:50:02.821106 55699 layer_factory.hpp:77] Creating layer relu5_1/sep
I0625 08:50:02.821144 55699 net.cpp:84] Creating Layer relu5_1/sep
I0625 08:50:02.821180 55699 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0625 08:50:02.821218 55699 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0625 08:50:02.821261 55699 net.cpp:122] Setting up relu5_1/sep
I0625 08:50:02.821300 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.821333 55699 net.cpp:137] Memory required for data: 85721344
I0625 08:50:02.821367 55699 layer_factory.hpp:77] Creating layer conv5_2/dw
I0625 08:50:02.821445 55699 net.cpp:84] Creating Layer conv5_2/dw
I0625 08:50:02.821491 55699 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0625 08:50:02.821517 55699 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0625 08:50:02.821874 55699 net.cpp:122] Setting up conv5_2/dw
I0625 08:50:02.821929 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.821949 55699 net.cpp:137] Memory required for data: 86245632
I0625 08:50:02.821964 55699 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0625 08:50:02.822002 55699 net.cpp:84] Creating Layer conv5_2/dw/bn
I0625 08:50:02.822041 55699 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0625 08:50:02.822116 55699 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0625 08:50:02.822214 55699 net.cpp:122] Setting up conv5_2/dw/bn
I0625 08:50:02.822263 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.822306 55699 net.cpp:137] Memory required for data: 86769920
I0625 08:50:02.822367 55699 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0625 08:50:02.822450 55699 net.cpp:84] Creating Layer conv5_2/dw/scale
I0625 08:50:02.822495 55699 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0625 08:50:02.822554 55699 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0625 08:50:02.822619 55699 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0625 08:50:02.822788 55699 net.cpp:122] Setting up conv5_2/dw/scale
I0625 08:50:02.822839 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.822857 55699 net.cpp:137] Memory required for data: 87294208
I0625 08:50:02.822873 55699 layer_factory.hpp:77] Creating layer relu5_2/dw
I0625 08:50:02.822926 55699 net.cpp:84] Creating Layer relu5_2/dw
I0625 08:50:02.822968 55699 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0625 08:50:02.823014 55699 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0625 08:50:02.823060 55699 net.cpp:122] Setting up relu5_2/dw
I0625 08:50:02.823098 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.823132 55699 net.cpp:137] Memory required for data: 87818496
I0625 08:50:02.823168 55699 layer_factory.hpp:77] Creating layer conv5_2/sep
I0625 08:50:02.823211 55699 net.cpp:84] Creating Layer conv5_2/sep
I0625 08:50:02.823249 55699 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0625 08:50:02.823297 55699 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0625 08:50:02.837991 55699 net.cpp:122] Setting up conv5_2/sep
I0625 08:50:02.838050 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.838086 55699 net.cpp:137] Memory required for data: 88342784
I0625 08:50:02.838140 55699 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0625 08:50:02.838184 55699 net.cpp:84] Creating Layer conv5_2/sep/bn
I0625 08:50:02.838222 55699 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0625 08:50:02.838299 55699 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0625 08:50:02.838397 55699 net.cpp:122] Setting up conv5_2/sep/bn
I0625 08:50:02.838445 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.838480 55699 net.cpp:137] Memory required for data: 88867072
I0625 08:50:02.838565 55699 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0625 08:50:02.838629 55699 net.cpp:84] Creating Layer conv5_2/sep/scale
I0625 08:50:02.838671 55699 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0625 08:50:02.838712 55699 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0625 08:50:02.838888 55699 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0625 08:50:02.838969 55699 net.cpp:122] Setting up conv5_2/sep/scale
I0625 08:50:02.839000 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.839010 55699 net.cpp:137] Memory required for data: 89391360
I0625 08:50:02.839023 55699 layer_factory.hpp:77] Creating layer relu5_2/sep
I0625 08:50:02.839037 55699 net.cpp:84] Creating Layer relu5_2/sep
I0625 08:50:02.839047 55699 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0625 08:50:02.839057 55699 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0625 08:50:02.839071 55699 net.cpp:122] Setting up relu5_2/sep
I0625 08:50:02.839082 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.839089 55699 net.cpp:137] Memory required for data: 89915648
I0625 08:50:02.839097 55699 layer_factory.hpp:77] Creating layer conv5_3/dw
I0625 08:50:02.839172 55699 net.cpp:84] Creating Layer conv5_3/dw
I0625 08:50:02.839193 55699 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0625 08:50:02.839210 55699 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0625 08:50:02.839484 55699 net.cpp:122] Setting up conv5_3/dw
I0625 08:50:02.839522 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.839531 55699 net.cpp:137] Memory required for data: 90439936
I0625 08:50:02.839546 55699 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0625 08:50:02.839596 55699 net.cpp:84] Creating Layer conv5_3/dw/bn
I0625 08:50:02.839643 55699 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0625 08:50:02.839668 55699 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0625 08:50:02.839753 55699 net.cpp:122] Setting up conv5_3/dw/bn
I0625 08:50:02.839802 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.839836 55699 net.cpp:137] Memory required for data: 90964224
I0625 08:50:02.839864 55699 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0625 08:50:02.839936 55699 net.cpp:84] Creating Layer conv5_3/dw/scale
I0625 08:50:02.839982 55699 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0625 08:50:02.840021 55699 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0625 08:50:02.840118 55699 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0625 08:50:02.840270 55699 net.cpp:122] Setting up conv5_3/dw/scale
I0625 08:50:02.840318 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.840353 55699 net.cpp:137] Memory required for data: 91488512
I0625 08:50:02.840378 55699 layer_factory.hpp:77] Creating layer relu5_3/dw
I0625 08:50:02.840399 55699 net.cpp:84] Creating Layer relu5_3/dw
I0625 08:50:02.840435 55699 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0625 08:50:02.840490 55699 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0625 08:50:02.840541 55699 net.cpp:122] Setting up relu5_3/dw
I0625 08:50:02.840582 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.840616 55699 net.cpp:137] Memory required for data: 92012800
I0625 08:50:02.840651 55699 layer_factory.hpp:77] Creating layer conv5_3/sep
I0625 08:50:02.840730 55699 net.cpp:84] Creating Layer conv5_3/sep
I0625 08:50:02.840775 55699 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0625 08:50:02.840817 55699 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0625 08:50:02.853883 55699 net.cpp:122] Setting up conv5_3/sep
I0625 08:50:02.853946 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.853982 55699 net.cpp:137] Memory required for data: 92537088
I0625 08:50:02.854034 55699 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0625 08:50:02.854084 55699 net.cpp:84] Creating Layer conv5_3/sep/bn
I0625 08:50:02.854136 55699 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0625 08:50:02.854192 55699 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0625 08:50:02.854260 55699 net.cpp:122] Setting up conv5_3/sep/bn
I0625 08:50:02.854305 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.854341 55699 net.cpp:137] Memory required for data: 93061376
I0625 08:50:02.854384 55699 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0625 08:50:02.854434 55699 net.cpp:84] Creating Layer conv5_3/sep/scale
I0625 08:50:02.854507 55699 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0625 08:50:02.854552 55699 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0625 08:50:02.854609 55699 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0625 08:50:02.854676 55699 net.cpp:122] Setting up conv5_3/sep/scale
I0625 08:50:02.854827 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.854872 55699 net.cpp:137] Memory required for data: 93585664
I0625 08:50:02.854892 55699 layer_factory.hpp:77] Creating layer relu5_3/sep
I0625 08:50:02.854907 55699 net.cpp:84] Creating Layer relu5_3/sep
I0625 08:50:02.854925 55699 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0625 08:50:02.854938 55699 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0625 08:50:02.854977 55699 net.cpp:122] Setting up relu5_3/sep
I0625 08:50:02.855036 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.855072 55699 net.cpp:137] Memory required for data: 94109952
I0625 08:50:02.855108 55699 layer_factory.hpp:77] Creating layer conv5_4/dw
I0625 08:50:02.855159 55699 net.cpp:84] Creating Layer conv5_4/dw
I0625 08:50:02.855199 55699 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0625 08:50:02.855242 55699 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0625 08:50:02.855545 55699 net.cpp:122] Setting up conv5_4/dw
I0625 08:50:02.855615 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.855655 55699 net.cpp:137] Memory required for data: 94634240
I0625 08:50:02.855720 55699 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0625 08:50:02.855768 55699 net.cpp:84] Creating Layer conv5_4/dw/bn
I0625 08:50:02.855806 55699 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0625 08:50:02.855854 55699 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0625 08:50:02.855916 55699 net.cpp:122] Setting up conv5_4/dw/bn
I0625 08:50:02.855979 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.856016 55699 net.cpp:137] Memory required for data: 95158528
I0625 08:50:02.856060 55699 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0625 08:50:02.856109 55699 net.cpp:84] Creating Layer conv5_4/dw/scale
I0625 08:50:02.856149 55699 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0625 08:50:02.856195 55699 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0625 08:50:02.856258 55699 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0625 08:50:02.856374 55699 net.cpp:122] Setting up conv5_4/dw/scale
I0625 08:50:02.856422 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.856457 55699 net.cpp:137] Memory required for data: 95682816
I0625 08:50:02.856513 55699 layer_factory.hpp:77] Creating layer relu5_4/dw
I0625 08:50:02.856570 55699 net.cpp:84] Creating Layer relu5_4/dw
I0625 08:50:02.856606 55699 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0625 08:50:02.856645 55699 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0625 08:50:02.856775 55699 net.cpp:122] Setting up relu5_4/dw
I0625 08:50:02.856825 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.856860 55699 net.cpp:137] Memory required for data: 96207104
I0625 08:50:02.856895 55699 layer_factory.hpp:77] Creating layer conv5_4/sep
I0625 08:50:02.856978 55699 net.cpp:84] Creating Layer conv5_4/sep
I0625 08:50:02.857024 55699 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0625 08:50:02.857115 55699 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0625 08:50:02.872671 55699 net.cpp:122] Setting up conv5_4/sep
I0625 08:50:02.872761 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.872776 55699 net.cpp:137] Memory required for data: 96731392
I0625 08:50:02.872800 55699 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0625 08:50:02.872829 55699 net.cpp:84] Creating Layer conv5_4/sep/bn
I0625 08:50:02.872867 55699 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0625 08:50:02.872910 55699 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0625 08:50:02.873005 55699 net.cpp:122] Setting up conv5_4/sep/bn
I0625 08:50:02.873055 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.873090 55699 net.cpp:137] Memory required for data: 97255680
I0625 08:50:02.873133 55699 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0625 08:50:02.873260 55699 net.cpp:84] Creating Layer conv5_4/sep/scale
I0625 08:50:02.873314 55699 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0625 08:50:02.873391 55699 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0625 08:50:02.873458 55699 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0625 08:50:02.873663 55699 net.cpp:122] Setting up conv5_4/sep/scale
I0625 08:50:02.873728 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.873803 55699 net.cpp:137] Memory required for data: 97779968
I0625 08:50:02.873828 55699 layer_factory.hpp:77] Creating layer relu5_4/sep
I0625 08:50:02.873847 55699 net.cpp:84] Creating Layer relu5_4/sep
I0625 08:50:02.873910 55699 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0625 08:50:02.873931 55699 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0625 08:50:02.873955 55699 net.cpp:122] Setting up relu5_4/sep
I0625 08:50:02.873973 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.873987 55699 net.cpp:137] Memory required for data: 98304256
I0625 08:50:02.873996 55699 layer_factory.hpp:77] Creating layer conv5_5/dw
I0625 08:50:02.874019 55699 net.cpp:84] Creating Layer conv5_5/dw
I0625 08:50:02.874055 55699 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0625 08:50:02.874132 55699 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0625 08:50:02.874467 55699 net.cpp:122] Setting up conv5_5/dw
I0625 08:50:02.874519 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.874538 55699 net.cpp:137] Memory required for data: 98828544
I0625 08:50:02.874552 55699 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0625 08:50:02.874589 55699 net.cpp:84] Creating Layer conv5_5/dw/bn
I0625 08:50:02.874627 55699 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0625 08:50:02.874651 55699 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0625 08:50:02.874687 55699 net.cpp:122] Setting up conv5_5/dw/bn
I0625 08:50:02.874728 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.874743 55699 net.cpp:137] Memory required for data: 99352832
I0625 08:50:02.874797 55699 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0625 08:50:02.874827 55699 net.cpp:84] Creating Layer conv5_5/dw/scale
I0625 08:50:02.874842 55699 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0625 08:50:02.874907 55699 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0625 08:50:02.874966 55699 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0625 08:50:02.875036 55699 net.cpp:122] Setting up conv5_5/dw/scale
I0625 08:50:02.875080 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.875115 55699 net.cpp:137] Memory required for data: 99877120
I0625 08:50:02.875139 55699 layer_factory.hpp:77] Creating layer relu5_5/dw
I0625 08:50:02.875172 55699 net.cpp:84] Creating Layer relu5_5/dw
I0625 08:50:02.875221 55699 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0625 08:50:02.875283 55699 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0625 08:50:02.875306 55699 net.cpp:122] Setting up relu5_5/dw
I0625 08:50:02.875344 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.875377 55699 net.cpp:137] Memory required for data: 100401408
I0625 08:50:02.875391 55699 layer_factory.hpp:77] Creating layer conv5_5/sep
I0625 08:50:02.875417 55699 net.cpp:84] Creating Layer conv5_5/sep
I0625 08:50:02.875452 55699 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0625 08:50:02.875474 55699 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0625 08:50:02.891268 55699 net.cpp:122] Setting up conv5_5/sep
I0625 08:50:02.891358 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.891371 55699 net.cpp:137] Memory required for data: 100925696
I0625 08:50:02.891393 55699 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0625 08:50:02.891440 55699 net.cpp:84] Creating Layer conv5_5/sep/bn
I0625 08:50:02.891481 55699 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0625 08:50:02.891559 55699 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0625 08:50:02.891669 55699 net.cpp:122] Setting up conv5_5/sep/bn
I0625 08:50:02.891719 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.891809 55699 net.cpp:137] Memory required for data: 101449984
I0625 08:50:02.891871 55699 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0625 08:50:02.891937 55699 net.cpp:84] Creating Layer conv5_5/sep/scale
I0625 08:50:02.891985 55699 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0625 08:50:02.892030 55699 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0625 08:50:02.892099 55699 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0625 08:50:02.892175 55699 net.cpp:122] Setting up conv5_5/sep/scale
I0625 08:50:02.892223 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.892258 55699 net.cpp:137] Memory required for data: 101974272
I0625 08:50:02.892285 55699 layer_factory.hpp:77] Creating layer relu5_5/sep
I0625 08:50:02.892307 55699 net.cpp:84] Creating Layer relu5_5/sep
I0625 08:50:02.892324 55699 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0625 08:50:02.892336 55699 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0625 08:50:02.892376 55699 net.cpp:122] Setting up relu5_5/sep
I0625 08:50:02.892418 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:02.892454 55699 net.cpp:137] Memory required for data: 102498560
I0625 08:50:02.892474 55699 layer_factory.hpp:77] Creating layer conv5_6/dw
I0625 08:50:02.892513 55699 net.cpp:84] Creating Layer conv5_6/dw
I0625 08:50:02.892554 55699 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0625 08:50:02.892598 55699 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0625 08:50:02.892904 55699 net.cpp:122] Setting up conv5_6/dw
I0625 08:50:02.892956 55699 net.cpp:129] Top shape: 64 512 1 1 (32768)
I0625 08:50:02.892989 55699 net.cpp:137] Memory required for data: 102629632
I0625 08:50:02.893013 55699 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0625 08:50:02.893043 55699 net.cpp:84] Creating Layer conv5_6/dw/bn
I0625 08:50:02.893082 55699 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0625 08:50:02.893100 55699 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0625 08:50:02.893213 55699 net.cpp:122] Setting up conv5_6/dw/bn
I0625 08:50:02.893263 55699 net.cpp:129] Top shape: 64 512 1 1 (32768)
I0625 08:50:02.893276 55699 net.cpp:137] Memory required for data: 102760704
I0625 08:50:02.893292 55699 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0625 08:50:02.893344 55699 net.cpp:84] Creating Layer conv5_6/dw/scale
I0625 08:50:02.893389 55699 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0625 08:50:02.893431 55699 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0625 08:50:02.893522 55699 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0625 08:50:02.894090 55699 net.cpp:122] Setting up conv5_6/dw/scale
I0625 08:50:02.894150 55699 net.cpp:129] Top shape: 64 512 1 1 (32768)
I0625 08:50:02.894163 55699 net.cpp:137] Memory required for data: 102891776
I0625 08:50:02.894191 55699 layer_factory.hpp:77] Creating layer relu5_6/dw
I0625 08:50:02.894217 55699 net.cpp:84] Creating Layer relu5_6/dw
I0625 08:50:02.894258 55699 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0625 08:50:02.894316 55699 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0625 08:50:02.894373 55699 net.cpp:122] Setting up relu5_6/dw
I0625 08:50:02.894415 55699 net.cpp:129] Top shape: 64 512 1 1 (32768)
I0625 08:50:02.894449 55699 net.cpp:137] Memory required for data: 103022848
I0625 08:50:02.894469 55699 layer_factory.hpp:77] Creating layer conv5_6/sep
I0625 08:50:02.894526 55699 net.cpp:84] Creating Layer conv5_6/sep
I0625 08:50:02.894572 55699 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0625 08:50:02.894598 55699 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0625 08:50:02.921488 55699 net.cpp:122] Setting up conv5_6/sep
I0625 08:50:02.921569 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.921613 55699 net.cpp:137] Memory required for data: 103284992
I0625 08:50:02.921643 55699 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0625 08:50:02.921689 55699 net.cpp:84] Creating Layer conv5_6/sep/bn
I0625 08:50:02.921728 55699 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0625 08:50:02.921771 55699 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0625 08:50:02.921885 55699 net.cpp:122] Setting up conv5_6/sep/bn
I0625 08:50:02.921931 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.921967 55699 net.cpp:137] Memory required for data: 103547136
I0625 08:50:02.922009 55699 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0625 08:50:02.922044 55699 net.cpp:84] Creating Layer conv5_6/sep/scale
I0625 08:50:02.922081 55699 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0625 08:50:02.922152 55699 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0625 08:50:02.922219 55699 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0625 08:50:02.922341 55699 net.cpp:122] Setting up conv5_6/sep/scale
I0625 08:50:02.922405 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.922443 55699 net.cpp:137] Memory required for data: 103809280
I0625 08:50:02.922484 55699 layer_factory.hpp:77] Creating layer relu5_6/sep
I0625 08:50:02.922528 55699 net.cpp:84] Creating Layer relu5_6/sep
I0625 08:50:02.922565 55699 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0625 08:50:02.922605 55699 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0625 08:50:02.922648 55699 net.cpp:122] Setting up relu5_6/sep
I0625 08:50:02.922673 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.922705 55699 net.cpp:137] Memory required for data: 104071424
I0625 08:50:02.922740 55699 layer_factory.hpp:77] Creating layer conv6/dw
I0625 08:50:02.922814 55699 net.cpp:84] Creating Layer conv6/dw
I0625 08:50:02.922857 55699 net.cpp:406] conv6/dw <- conv5_6/sep
I0625 08:50:02.922899 55699 net.cpp:380] conv6/dw -> conv6/dw
I0625 08:50:02.923418 55699 net.cpp:122] Setting up conv6/dw
I0625 08:50:02.923467 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.923502 55699 net.cpp:137] Memory required for data: 104333568
I0625 08:50:02.923540 55699 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0625 08:50:02.923593 55699 net.cpp:84] Creating Layer conv6/dw/bn
I0625 08:50:02.923633 55699 net.cpp:406] conv6/dw/bn <- conv6/dw
I0625 08:50:02.923683 55699 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0625 08:50:02.923749 55699 net.cpp:122] Setting up conv6/dw/bn
I0625 08:50:02.923794 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.923827 55699 net.cpp:137] Memory required for data: 104595712
I0625 08:50:02.923877 55699 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0625 08:50:02.923920 55699 net.cpp:84] Creating Layer conv6/dw/scale
I0625 08:50:02.923959 55699 net.cpp:406] conv6/dw/scale <- conv6/dw
I0625 08:50:02.923997 55699 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0625 08:50:02.924078 55699 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0625 08:50:02.924150 55699 net.cpp:122] Setting up conv6/dw/scale
I0625 08:50:02.924196 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.924230 55699 net.cpp:137] Memory required for data: 104857856
I0625 08:50:02.924270 55699 layer_factory.hpp:77] Creating layer relu6/dw
I0625 08:50:02.924316 55699 net.cpp:84] Creating Layer relu6/dw
I0625 08:50:02.924355 55699 net.cpp:406] relu6/dw <- conv6/dw
I0625 08:50:02.924393 55699 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0625 08:50:02.924437 55699 net.cpp:122] Setting up relu6/dw
I0625 08:50:02.924475 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.924509 55699 net.cpp:137] Memory required for data: 105120000
I0625 08:50:02.924543 55699 layer_factory.hpp:77] Creating layer conv6/sep
I0625 08:50:02.924587 55699 net.cpp:84] Creating Layer conv6/sep
I0625 08:50:02.924623 55699 net.cpp:406] conv6/sep <- conv6/dw
I0625 08:50:02.924664 55699 net.cpp:380] conv6/sep -> conv6/sep
I0625 08:50:02.975160 55699 net.cpp:122] Setting up conv6/sep
I0625 08:50:02.975245 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.975289 55699 net.cpp:137] Memory required for data: 105382144
I0625 08:50:02.975317 55699 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0625 08:50:02.975365 55699 net.cpp:84] Creating Layer conv6/sep/bn
I0625 08:50:02.975406 55699 net.cpp:406] conv6/sep/bn <- conv6/sep
I0625 08:50:02.975510 55699 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0625 08:50:02.975586 55699 net.cpp:122] Setting up conv6/sep/bn
I0625 08:50:02.975632 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.975667 55699 net.cpp:137] Memory required for data: 105644288
I0625 08:50:02.975694 55699 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0625 08:50:02.975742 55699 net.cpp:84] Creating Layer conv6/sep/scale
I0625 08:50:02.975782 55699 net.cpp:406] conv6/sep/scale <- conv6/sep
I0625 08:50:02.975826 55699 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0625 08:50:02.975890 55699 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0625 08:50:02.975980 55699 net.cpp:122] Setting up conv6/sep/scale
I0625 08:50:02.976042 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.976079 55699 net.cpp:137] Memory required for data: 105906432
I0625 08:50:02.976120 55699 layer_factory.hpp:77] Creating layer relu6/sep
I0625 08:50:02.976163 55699 net.cpp:84] Creating Layer relu6/sep
I0625 08:50:02.976202 55699 net.cpp:406] relu6/sep <- conv6/sep
I0625 08:50:02.976240 55699 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0625 08:50:02.976284 55699 net.cpp:122] Setting up relu6/sep
I0625 08:50:02.976325 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.976359 55699 net.cpp:137] Memory required for data: 106168576
I0625 08:50:02.976379 55699 layer_factory.hpp:77] Creating layer pool6
I0625 08:50:02.976402 55699 net.cpp:84] Creating Layer pool6
I0625 08:50:02.976419 55699 net.cpp:406] pool6 <- conv6/sep
I0625 08:50:02.976433 55699 net.cpp:380] pool6 -> pool6
I0625 08:50:02.976526 55699 net.cpp:122] Setting up pool6
I0625 08:50:02.976577 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:02.976614 55699 net.cpp:137] Memory required for data: 106430720
I0625 08:50:02.976649 55699 layer_factory.hpp:77] Creating layer cifarfc7
I0625 08:50:02.976696 55699 net.cpp:84] Creating Layer cifarfc7
I0625 08:50:02.976734 55699 net.cpp:406] cifarfc7 <- pool6
I0625 08:50:02.976797 55699 net.cpp:380] cifarfc7 -> cifarfc7
I0625 08:50:02.977336 55699 net.cpp:122] Setting up cifarfc7
I0625 08:50:02.977386 55699 net.cpp:129] Top shape: 64 10 1 1 (640)
I0625 08:50:02.977424 55699 net.cpp:137] Memory required for data: 106433280
I0625 08:50:02.977465 55699 layer_factory.hpp:77] Creating layer loss
I0625 08:50:02.977517 55699 net.cpp:84] Creating Layer loss
I0625 08:50:02.977557 55699 net.cpp:406] loss <- cifarfc7
I0625 08:50:02.977596 55699 net.cpp:406] loss <- label
I0625 08:50:02.977638 55699 net.cpp:380] loss -> loss
I0625 08:50:02.977691 55699 layer_factory.hpp:77] Creating layer loss
I0625 08:50:02.977789 55699 net.cpp:122] Setting up loss
I0625 08:50:02.977841 55699 net.cpp:129] Top shape: (1)
I0625 08:50:02.977879 55699 net.cpp:132]     with loss weight 1
I0625 08:50:02.977937 55699 net.cpp:137] Memory required for data: 106433284
I0625 08:50:02.977977 55699 net.cpp:198] loss needs backward computation.
I0625 08:50:02.978013 55699 net.cpp:198] cifarfc7 needs backward computation.
I0625 08:50:02.978047 55699 net.cpp:198] pool6 needs backward computation.
I0625 08:50:02.978066 55699 net.cpp:198] relu6/sep needs backward computation.
I0625 08:50:02.978075 55699 net.cpp:198] conv6/sep/scale needs backward computation.
I0625 08:50:02.978106 55699 net.cpp:198] conv6/sep/bn needs backward computation.
I0625 08:50:02.978139 55699 net.cpp:198] conv6/sep needs backward computation.
I0625 08:50:02.978174 55699 net.cpp:198] relu6/dw needs backward computation.
I0625 08:50:02.978193 55699 net.cpp:198] conv6/dw/scale needs backward computation.
I0625 08:50:02.978204 55699 net.cpp:198] conv6/dw/bn needs backward computation.
I0625 08:50:02.978233 55699 net.cpp:198] conv6/dw needs backward computation.
I0625 08:50:02.978252 55699 net.cpp:198] relu5_6/sep needs backward computation.
I0625 08:50:02.978262 55699 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0625 08:50:02.978276 55699 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0625 08:50:02.978284 55699 net.cpp:198] conv5_6/sep needs backward computation.
I0625 08:50:02.978341 55699 net.cpp:198] relu5_6/dw needs backward computation.
I0625 08:50:02.978379 55699 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0625 08:50:02.978399 55699 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0625 08:50:02.978407 55699 net.cpp:198] conv5_6/dw needs backward computation.
I0625 08:50:02.978421 55699 net.cpp:198] relu5_5/sep needs backward computation.
I0625 08:50:02.978430 55699 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0625 08:50:02.978444 55699 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0625 08:50:02.978452 55699 net.cpp:198] conv5_5/sep needs backward computation.
I0625 08:50:02.978467 55699 net.cpp:198] relu5_5/dw needs backward computation.
I0625 08:50:02.978477 55699 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0625 08:50:02.978489 55699 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0625 08:50:02.978498 55699 net.cpp:198] conv5_5/dw needs backward computation.
I0625 08:50:02.978513 55699 net.cpp:198] relu5_4/sep needs backward computation.
I0625 08:50:02.978521 55699 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0625 08:50:02.978531 55699 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0625 08:50:02.978561 55699 net.cpp:198] conv5_4/sep needs backward computation.
I0625 08:50:02.978581 55699 net.cpp:198] relu5_4/dw needs backward computation.
I0625 08:50:02.978590 55699 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0625 08:50:02.978605 55699 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0625 08:50:02.978613 55699 net.cpp:198] conv5_4/dw needs backward computation.
I0625 08:50:02.978627 55699 net.cpp:198] relu5_3/sep needs backward computation.
I0625 08:50:02.978636 55699 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0625 08:50:02.978649 55699 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0625 08:50:02.978658 55699 net.cpp:198] conv5_3/sep needs backward computation.
I0625 08:50:02.978672 55699 net.cpp:198] relu5_3/dw needs backward computation.
I0625 08:50:02.978682 55699 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0625 08:50:02.978694 55699 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0625 08:50:02.978703 55699 net.cpp:198] conv5_3/dw needs backward computation.
I0625 08:50:02.978714 55699 net.cpp:198] relu5_2/sep needs backward computation.
I0625 08:50:02.978754 55699 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0625 08:50:02.978809 55699 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0625 08:50:02.978847 55699 net.cpp:198] conv5_2/sep needs backward computation.
I0625 08:50:02.978866 55699 net.cpp:198] relu5_2/dw needs backward computation.
I0625 08:50:02.978875 55699 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0625 08:50:02.978905 55699 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0625 08:50:02.978924 55699 net.cpp:198] conv5_2/dw needs backward computation.
I0625 08:50:02.978935 55699 net.cpp:198] relu5_1/sep needs backward computation.
I0625 08:50:02.978947 55699 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0625 08:50:02.978956 55699 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0625 08:50:02.978971 55699 net.cpp:198] conv5_1/sep needs backward computation.
I0625 08:50:02.978979 55699 net.cpp:198] relu5_1/dw needs backward computation.
I0625 08:50:02.978993 55699 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0625 08:50:02.979002 55699 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0625 08:50:02.979017 55699 net.cpp:198] conv5_1/dw needs backward computation.
I0625 08:50:02.979025 55699 net.cpp:198] relu4_2/sep needs backward computation.
I0625 08:50:02.979039 55699 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0625 08:50:02.979048 55699 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0625 08:50:02.979058 55699 net.cpp:198] conv4_2/sep needs backward computation.
I0625 08:50:02.979089 55699 net.cpp:198] relu4_2/dw needs backward computation.
I0625 08:50:02.979149 55699 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0625 08:50:02.979187 55699 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0625 08:50:02.979221 55699 net.cpp:198] conv4_2/dw needs backward computation.
I0625 08:50:02.979255 55699 net.cpp:198] relu4_1/sep needs backward computation.
I0625 08:50:02.979290 55699 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0625 08:50:02.979308 55699 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0625 08:50:02.979317 55699 net.cpp:198] conv4_1/sep needs backward computation.
I0625 08:50:02.979332 55699 net.cpp:198] relu4_1/dw needs backward computation.
I0625 08:50:02.979341 55699 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0625 08:50:02.979354 55699 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0625 08:50:02.979363 55699 net.cpp:198] conv4_1/dw needs backward computation.
I0625 08:50:02.979377 55699 net.cpp:198] relu3_2/sep needs backward computation.
I0625 08:50:02.979385 55699 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0625 08:50:02.979399 55699 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0625 08:50:02.979408 55699 net.cpp:198] conv3_2/sep needs backward computation.
I0625 08:50:02.979421 55699 net.cpp:198] relu3_2/dw needs backward computation.
I0625 08:50:02.979430 55699 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0625 08:50:02.979444 55699 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0625 08:50:02.979452 55699 net.cpp:198] conv3_2/dw needs backward computation.
I0625 08:50:02.979466 55699 net.cpp:198] relu3_1/sep needs backward computation.
I0625 08:50:02.979475 55699 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0625 08:50:02.979488 55699 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0625 08:50:02.979497 55699 net.cpp:198] conv3_1/sep needs backward computation.
I0625 08:50:02.979507 55699 net.cpp:198] relu3_1/dw needs backward computation.
I0625 08:50:02.979538 55699 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0625 08:50:02.979573 55699 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0625 08:50:02.979591 55699 net.cpp:198] conv3_1/dw needs backward computation.
I0625 08:50:02.979601 55699 net.cpp:198] relu2_2/sep needs backward computation.
I0625 08:50:02.979614 55699 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0625 08:50:02.979624 55699 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0625 08:50:02.979636 55699 net.cpp:198] conv2_2/sep needs backward computation.
I0625 08:50:02.979645 55699 net.cpp:198] relu2_2/dw needs backward computation.
I0625 08:50:02.979660 55699 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0625 08:50:02.979667 55699 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0625 08:50:02.979681 55699 net.cpp:198] conv2_2/dw needs backward computation.
I0625 08:50:02.979691 55699 net.cpp:198] relu2_1/sep needs backward computation.
I0625 08:50:02.979703 55699 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0625 08:50:02.979740 55699 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0625 08:50:02.979775 55699 net.cpp:198] conv2_1/sep needs backward computation.
I0625 08:50:02.979792 55699 net.cpp:198] relu2_1/dw needs backward computation.
I0625 08:50:02.979807 55699 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0625 08:50:02.979816 55699 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0625 08:50:02.979830 55699 net.cpp:198] conv2_1/dw needs backward computation.
I0625 08:50:02.979840 55699 net.cpp:198] relu1 needs backward computation.
I0625 08:50:02.979853 55699 net.cpp:198] conv1/scale needs backward computation.
I0625 08:50:02.979861 55699 net.cpp:198] conv1/bn needs backward computation.
I0625 08:50:02.979874 55699 net.cpp:198] conv1 needs backward computation.
I0625 08:50:02.979884 55699 net.cpp:200] data does not need backward computation.
I0625 08:50:02.979898 55699 net.cpp:242] This network produces output loss
I0625 08:50:02.980018 55699 net.cpp:255] Network initialization done.
I0625 08:50:02.983772 55699 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/sun/MobileNet-Caffe-master/cifar10/mobilenet_train.prototxt
I0625 08:50:02.983831 55699 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0625 08:50:02.983875 55699 solver.cpp:172] Creating test net (#0) specified by net file: /home/sun/MobileNet-Caffe-master/cifar10/mobilenet_train.prototxt
I0625 08:50:02.984081 55699 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0625 08:50:02.985352 55699 net.cpp:51] Initializing net from parameters: 
name: "MOBILENET"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    mean_file: "/home/sun/MobileNet-Caffe-master/cifar10/mean/mean.binaryproto"
  }
  data_param {
    source: "/home/sun/MobileNet-Caffe-master/cifar10/lmdb/cifar10_test_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/dw"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_1/sep"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv2_2/dw"
  type: "Convolution"
  bottom: "conv2_1/sep"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv2_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv2_2/dw/scale"
  type: "Scale"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/dw"
  type: "ReLU"
  bottom: "conv2_2/dw"
  top: "conv2_2/dw"
}
layer {
  name: "conv2_2/sep"
  type: "Convolution"
  bottom: "conv2_2/dw"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv2_2/sep/scale"
  type: "Scale"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2_2/sep"
  type: "ReLU"
  bottom: "conv2_2/sep"
  top: "conv2_2/sep"
}
layer {
  name: "conv3_1/dw"
  type: "Convolution"
  bottom: "conv2_2/sep"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/dw"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv3_1/sep/scale"
  type: "Scale"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_1/sep"
  type: "ReLU"
  bottom: "conv3_1/sep"
  top: "conv3_1/sep"
}
layer {
  name: "conv3_2/dw"
  type: "Convolution"
  bottom: "conv3_1/sep"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/dw"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv3_2/sep/scale"
  type: "Scale"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3_2/sep"
  type: "ReLU"
  bottom: "conv3_2/sep"
  top: "conv3_2/sep"
}
layer {
  name: "conv4_1/dw"
  type: "Convolution"
  bottom: "conv3_2/sep"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/dw"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv4_1/sep/scale"
  type: "Scale"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_1/sep"
  type: "ReLU"
  bottom: "conv4_1/sep"
  top: "conv4_1/sep"
}
layer {
  name: "conv4_2/dw"
  type: "Convolution"
  bottom: "conv4_1/sep"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/dw"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv4_2/sep/scale"
  type: "Scale"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu4_2/sep"
  type: "ReLU"
  bottom: "conv4_2/sep"
  top: "conv4_2/sep"
}
layer {
  name: "conv5_1/dw"
  type: "Convolution"
  bottom: "conv4_2/sep"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/dw"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_1/sep/scale"
  type: "Scale"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_1/sep"
  type: "ReLU"
  bottom: "conv5_1/sep"
  top: "conv5_1/sep"
}
layer {
  name: "conv5_2/dw"
  type: "Convolution"
  bottom: "conv5_1/sep"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/dw"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_2/sep/scale"
  type: "Scale"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_2/sep"
  type: "ReLU"
  bottom: "conv5_2/sep"
  top: "conv5_2/sep"
}
layer {
  name: "conv5_3/dw"
  type: "Convolution"
  bottom: "conv5_2/sep"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/dw"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_3/sep/scale"
  type: "Scale"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_3/sep"
  type: "ReLU"
  bottom: "conv5_3/sep"
  top: "conv5_3/sep"
}
layer {
  name: "conv5_4/dw"
  type: "Convolution"
  bottom: "conv5_3/sep"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_4/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_4/dw/scale"
  type: "Scale"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/dw"
  type: "ReLU"
  bottom: "conv5_4/dw"
  top: "conv5_4/dw"
}
layer {
  name: "conv5_4/sep"
  type: "Convolution"
  bottom: "conv5_4/dw"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_4/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_4/sep/scale"
  type: "Scale"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_4/sep"
  type: "ReLU"
  bottom: "conv5_4/sep"
  top: "conv5_4/sep"
}
layer {
  name: "conv5_5/dw"
  type: "Convolution"
  bottom: "conv5_4/sep"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_5/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_5/dw/scale"
  type: "Scale"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/dw"
  type: "ReLU"
  bottom: "conv5_5/dw"
  top: "conv5_5/dw"
}
layer {
  name: "conv5_5/sep"
  type: "Convolution"
  bottom: "conv5_5/dw"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_5/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_5/sep/scale"
  type: "Scale"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_5/sep"
  type: "ReLU"
  bottom: "conv5_5/sep"
  top: "conv5_5/sep"
}
layer {
  name: "conv5_6/dw"
  type: "Convolution"
  bottom: "conv5_5/sep"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 512
    stride: 2
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv5_6/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_6/dw/scale"
  type: "Scale"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/dw"
  type: "ReLU"
  bottom: "conv5_6/dw"
  top: "conv5_6/dw"
}
layer {
  name: "conv5_6/sep"
  type: "Convolution"
  bottom: "conv5_6/dw"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_6/sep/bn"
  type: "BatchNorm"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv5_6/sep/scale"
  type: "Scale"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu5_6/sep"
  type: "ReLU"
  bottom: "conv5_6/sep"
  top: "conv5_6/sep"
}
layer {
  name: "conv6/dw"
  type: "Convolution"
  bottom: "conv5_6/sep"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 1024
    stride: 1
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}
layer {
  name: "conv6/dw/bn"
  type: "BatchNorm"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv6/dw/scale"
  type: "Scale"
  bottom: "conv6/dw"
  top: "conv6/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/dw"
  type: "ReLU"
  bottom: "conv6/dw"
  top: "conv6/dw"
}
layer {
  name: "conv6/sep"
  type: "Convolution"
  bottom: "conv6/dw"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6/sep/bn"
  type: "BatchNorm"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-05
  }
}
layer {
  name: "conv6/sep/scale"
  type: "Scale"
  bottom: "conv6/sep"
  top: "conv6/sep"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu6/sep"
  type: "ReLU"
  bottom: "conv6/sep"
  top: "conv6/sep"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv6/sep"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "cifarfc7"
  type: "Convolution"
  bottom: "pool6"
  top: "cifarfc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "cifarfc7"
  bottom: "label"
  top: "loss"
}
layer {
  name: "top1/acc"
  type: "Accuracy"
  bottom: "cifarfc7"
  bottom: "label"
  top: "top1/acc"
  include {
    phase: TEST
  }
}
layer {
  name: "top5/acc"
  type: "Accuracy"
  bottom: "cifarfc7"
  bottom: "label"
  top: "top5/acc"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 3
  }
}
I0625 08:50:03.008731 55699 layer_factory.hpp:77] Creating layer data
I0625 08:50:03.009079 55699 db_lmdb.cpp:35] Opened lmdb /home/sun/MobileNet-Caffe-master/cifar10/lmdb/cifar10_test_lmdb
I0625 08:50:03.009198 55699 net.cpp:84] Creating Layer data
I0625 08:50:03.009249 55699 net.cpp:380] data -> data
I0625 08:50:03.009304 55699 net.cpp:380] data -> label
I0625 08:50:03.009354 55699 data_transformer.cpp:25] Loading mean file from: /home/sun/MobileNet-Caffe-master/cifar10/mean/mean.binaryproto
I0625 08:50:03.009507 55699 data_layer.cpp:45] output data size: 64,3,32,32
I0625 08:50:03.012850 55699 net.cpp:122] Setting up data
I0625 08:50:03.012931 55699 net.cpp:129] Top shape: 64 3 32 32 (196608)
I0625 08:50:03.013020 55699 net.cpp:129] Top shape: 64 (64)
I0625 08:50:03.013056 55699 net.cpp:137] Memory required for data: 786688
I0625 08:50:03.013093 55699 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 08:50:03.013139 55699 net.cpp:84] Creating Layer label_data_1_split
I0625 08:50:03.013175 55699 net.cpp:406] label_data_1_split <- label
I0625 08:50:03.013223 55699 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0625 08:50:03.013270 55699 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0625 08:50:03.013314 55699 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0625 08:50:03.013423 55699 net.cpp:122] Setting up label_data_1_split
I0625 08:50:03.013468 55699 net.cpp:129] Top shape: 64 (64)
I0625 08:50:03.013514 55699 net.cpp:129] Top shape: 64 (64)
I0625 08:50:03.013550 55699 net.cpp:129] Top shape: 64 (64)
I0625 08:50:03.013590 55699 net.cpp:137] Memory required for data: 787456
I0625 08:50:03.013631 55699 layer_factory.hpp:77] Creating layer conv1
I0625 08:50:03.013679 55699 net.cpp:84] Creating Layer conv1
I0625 08:50:03.013716 55699 net.cpp:406] conv1 <- data
I0625 08:50:03.013758 55699 net.cpp:380] conv1 -> conv1
I0625 08:50:03.013871 55699 net.cpp:122] Setting up conv1
I0625 08:50:03.013926 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:03.013945 55699 net.cpp:137] Memory required for data: 2884608
I0625 08:50:03.013962 55699 layer_factory.hpp:77] Creating layer conv1/bn
I0625 08:50:03.014014 55699 net.cpp:84] Creating Layer conv1/bn
I0625 08:50:03.014053 55699 net.cpp:406] conv1/bn <- conv1
I0625 08:50:03.014092 55699 net.cpp:367] conv1/bn -> conv1 (in-place)
I0625 08:50:03.014199 55699 net.cpp:122] Setting up conv1/bn
I0625 08:50:03.014286 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:03.014320 55699 net.cpp:137] Memory required for data: 4981760
I0625 08:50:03.014369 55699 layer_factory.hpp:77] Creating layer conv1/scale
I0625 08:50:03.014433 55699 net.cpp:84] Creating Layer conv1/scale
I0625 08:50:03.014474 55699 net.cpp:406] conv1/scale <- conv1
I0625 08:50:03.014521 55699 net.cpp:367] conv1/scale -> conv1 (in-place)
I0625 08:50:03.014580 55699 layer_factory.hpp:77] Creating layer conv1/scale
I0625 08:50:03.014652 55699 net.cpp:122] Setting up conv1/scale
I0625 08:50:03.014703 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:03.014739 55699 net.cpp:137] Memory required for data: 7078912
I0625 08:50:03.014811 55699 layer_factory.hpp:77] Creating layer relu1
I0625 08:50:03.014892 55699 net.cpp:84] Creating Layer relu1
I0625 08:50:03.015054 55699 net.cpp:406] relu1 <- conv1
I0625 08:50:03.015074 55699 net.cpp:367] relu1 -> conv1 (in-place)
I0625 08:50:03.015117 55699 net.cpp:122] Setting up relu1
I0625 08:50:03.015239 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:03.015277 55699 net.cpp:137] Memory required for data: 9176064
I0625 08:50:03.015318 55699 layer_factory.hpp:77] Creating layer conv2_1/dw
I0625 08:50:03.015347 55699 net.cpp:84] Creating Layer conv2_1/dw
I0625 08:50:03.015389 55699 net.cpp:406] conv2_1/dw <- conv1
I0625 08:50:03.015414 55699 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0625 08:50:03.015478 55699 net.cpp:122] Setting up conv2_1/dw
I0625 08:50:03.015522 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:03.015556 55699 net.cpp:137] Memory required for data: 11273216
I0625 08:50:03.015575 55699 layer_factory.hpp:77] Creating layer conv2_1/dw/bn
I0625 08:50:03.015625 55699 net.cpp:84] Creating Layer conv2_1/dw/bn
I0625 08:50:03.015664 55699 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0625 08:50:03.015712 55699 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0625 08:50:03.015774 55699 net.cpp:122] Setting up conv2_1/dw/bn
I0625 08:50:03.015825 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:03.015882 55699 net.cpp:137] Memory required for data: 13370368
I0625 08:50:03.015929 55699 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0625 08:50:03.015980 55699 net.cpp:84] Creating Layer conv2_1/dw/scale
I0625 08:50:03.016018 55699 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0625 08:50:03.016074 55699 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0625 08:50:03.016131 55699 layer_factory.hpp:77] Creating layer conv2_1/dw/scale
I0625 08:50:03.016201 55699 net.cpp:122] Setting up conv2_1/dw/scale
I0625 08:50:03.016247 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:03.016288 55699 net.cpp:137] Memory required for data: 15467520
I0625 08:50:03.016309 55699 layer_factory.hpp:77] Creating layer relu2_1/dw
I0625 08:50:03.016345 55699 net.cpp:84] Creating Layer relu2_1/dw
I0625 08:50:03.016382 55699 net.cpp:406] relu2_1/dw <- conv2_1/dw
I0625 08:50:03.016415 55699 net.cpp:367] relu2_1/dw -> conv2_1/dw (in-place)
I0625 08:50:03.016458 55699 net.cpp:122] Setting up relu2_1/dw
I0625 08:50:03.016497 55699 net.cpp:129] Top shape: 64 32 16 16 (524288)
I0625 08:50:03.016531 55699 net.cpp:137] Memory required for data: 17564672
I0625 08:50:03.016572 55699 layer_factory.hpp:77] Creating layer conv2_1/sep
I0625 08:50:03.016599 55699 net.cpp:84] Creating Layer conv2_1/sep
I0625 08:50:03.016618 55699 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0625 08:50:03.016631 55699 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0625 08:50:03.016798 55699 net.cpp:122] Setting up conv2_1/sep
I0625 08:50:03.016858 55699 net.cpp:129] Top shape: 64 64 16 16 (1048576)
I0625 08:50:03.016870 55699 net.cpp:137] Memory required for data: 21758976
I0625 08:50:03.016890 55699 layer_factory.hpp:77] Creating layer conv2_1/sep/bn
I0625 08:50:03.016904 55699 net.cpp:84] Creating Layer conv2_1/sep/bn
I0625 08:50:03.016937 55699 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0625 08:50:03.016963 55699 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0625 08:50:03.017014 55699 net.cpp:122] Setting up conv2_1/sep/bn
I0625 08:50:03.017066 55699 net.cpp:129] Top shape: 64 64 16 16 (1048576)
I0625 08:50:03.017109 55699 net.cpp:137] Memory required for data: 25953280
I0625 08:50:03.017148 55699 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0625 08:50:03.017191 55699 net.cpp:84] Creating Layer conv2_1/sep/scale
I0625 08:50:03.017230 55699 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0625 08:50:03.017253 55699 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0625 08:50:03.017308 55699 layer_factory.hpp:77] Creating layer conv2_1/sep/scale
I0625 08:50:03.017379 55699 net.cpp:122] Setting up conv2_1/sep/scale
I0625 08:50:03.017426 55699 net.cpp:129] Top shape: 64 64 16 16 (1048576)
I0625 08:50:03.017467 55699 net.cpp:137] Memory required for data: 30147584
I0625 08:50:03.017491 55699 layer_factory.hpp:77] Creating layer relu2_1/sep
I0625 08:50:03.017529 55699 net.cpp:84] Creating Layer relu2_1/sep
I0625 08:50:03.017572 55699 net.cpp:406] relu2_1/sep <- conv2_1/sep
I0625 08:50:03.017647 55699 net.cpp:367] relu2_1/sep -> conv2_1/sep (in-place)
I0625 08:50:03.017694 55699 net.cpp:122] Setting up relu2_1/sep
I0625 08:50:03.017735 55699 net.cpp:129] Top shape: 64 64 16 16 (1048576)
I0625 08:50:03.038477 55699 net.cpp:137] Memory required for data: 34341888
I0625 08:50:03.038511 55699 layer_factory.hpp:77] Creating layer conv2_2/dw
I0625 08:50:03.038573 55699 net.cpp:84] Creating Layer conv2_2/dw
I0625 08:50:03.038631 55699 net.cpp:406] conv2_2/dw <- conv2_1/sep
I0625 08:50:03.038671 55699 net.cpp:380] conv2_2/dw -> conv2_2/dw
I0625 08:50:03.038791 55699 net.cpp:122] Setting up conv2_2/dw
I0625 08:50:03.038884 55699 net.cpp:129] Top shape: 64 64 8 8 (262144)
I0625 08:50:03.038923 55699 net.cpp:137] Memory required for data: 35390464
I0625 08:50:03.038947 55699 layer_factory.hpp:77] Creating layer conv2_2/dw/bn
I0625 08:50:03.038977 55699 net.cpp:84] Creating Layer conv2_2/dw/bn
I0625 08:50:03.039016 55699 net.cpp:406] conv2_2/dw/bn <- conv2_2/dw
I0625 08:50:03.039041 55699 net.cpp:367] conv2_2/dw/bn -> conv2_2/dw (in-place)
I0625 08:50:03.039103 55699 net.cpp:122] Setting up conv2_2/dw/bn
I0625 08:50:03.039149 55699 net.cpp:129] Top shape: 64 64 8 8 (262144)
I0625 08:50:03.039183 55699 net.cpp:137] Memory required for data: 36439040
I0625 08:50:03.039206 55699 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0625 08:50:03.039250 55699 net.cpp:84] Creating Layer conv2_2/dw/scale
I0625 08:50:03.039300 55699 net.cpp:406] conv2_2/dw/scale <- conv2_2/dw
I0625 08:50:03.039353 55699 net.cpp:367] conv2_2/dw/scale -> conv2_2/dw (in-place)
I0625 08:50:03.039412 55699 layer_factory.hpp:77] Creating layer conv2_2/dw/scale
I0625 08:50:03.039520 55699 net.cpp:122] Setting up conv2_2/dw/scale
I0625 08:50:03.039571 55699 net.cpp:129] Top shape: 64 64 8 8 (262144)
I0625 08:50:03.039604 55699 net.cpp:137] Memory required for data: 37487616
I0625 08:50:03.039630 55699 layer_factory.hpp:77] Creating layer relu2_2/dw
I0625 08:50:03.039649 55699 net.cpp:84] Creating Layer relu2_2/dw
I0625 08:50:03.039681 55699 net.cpp:406] relu2_2/dw <- conv2_2/dw
I0625 08:50:03.039716 55699 net.cpp:367] relu2_2/dw -> conv2_2/dw (in-place)
I0625 08:50:03.039777 55699 net.cpp:122] Setting up relu2_2/dw
I0625 08:50:03.039816 55699 net.cpp:129] Top shape: 64 64 8 8 (262144)
I0625 08:50:03.039850 55699 net.cpp:137] Memory required for data: 38536192
I0625 08:50:03.039866 55699 layer_factory.hpp:77] Creating layer conv2_2/sep
I0625 08:50:03.039906 55699 net.cpp:84] Creating Layer conv2_2/sep
I0625 08:50:03.039942 55699 net.cpp:406] conv2_2/sep <- conv2_2/dw
I0625 08:50:03.039978 55699 net.cpp:380] conv2_2/sep -> conv2_2/sep
I0625 08:50:03.040469 55699 net.cpp:122] Setting up conv2_2/sep
I0625 08:50:03.040520 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.040558 55699 net.cpp:137] Memory required for data: 40633344
I0625 08:50:03.040597 55699 layer_factory.hpp:77] Creating layer conv2_2/sep/bn
I0625 08:50:03.040649 55699 net.cpp:84] Creating Layer conv2_2/sep/bn
I0625 08:50:03.040689 55699 net.cpp:406] conv2_2/sep/bn <- conv2_2/sep
I0625 08:50:03.040715 55699 net.cpp:367] conv2_2/sep/bn -> conv2_2/sep (in-place)
I0625 08:50:03.040756 55699 net.cpp:122] Setting up conv2_2/sep/bn
I0625 08:50:03.040803 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.040838 55699 net.cpp:137] Memory required for data: 42730496
I0625 08:50:03.040865 55699 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0625 08:50:03.040889 55699 net.cpp:84] Creating Layer conv2_2/sep/scale
I0625 08:50:03.040901 55699 net.cpp:406] conv2_2/sep/scale <- conv2_2/sep
I0625 08:50:03.040930 55699 net.cpp:367] conv2_2/sep/scale -> conv2_2/sep (in-place)
I0625 08:50:03.040982 55699 layer_factory.hpp:77] Creating layer conv2_2/sep/scale
I0625 08:50:03.041056 55699 net.cpp:122] Setting up conv2_2/sep/scale
I0625 08:50:03.041112 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.041151 55699 net.cpp:137] Memory required for data: 44827648
I0625 08:50:03.041177 55699 layer_factory.hpp:77] Creating layer relu2_2/sep
I0625 08:50:03.041249 55699 net.cpp:84] Creating Layer relu2_2/sep
I0625 08:50:03.041292 55699 net.cpp:406] relu2_2/sep <- conv2_2/sep
I0625 08:50:03.041350 55699 net.cpp:367] relu2_2/sep -> conv2_2/sep (in-place)
I0625 08:50:03.041414 55699 net.cpp:122] Setting up relu2_2/sep
I0625 08:50:03.041456 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.041491 55699 net.cpp:137] Memory required for data: 46924800
I0625 08:50:03.041507 55699 layer_factory.hpp:77] Creating layer conv3_1/dw
I0625 08:50:03.041558 55699 net.cpp:84] Creating Layer conv3_1/dw
I0625 08:50:03.041600 55699 net.cpp:406] conv3_1/dw <- conv2_2/sep
I0625 08:50:03.041642 55699 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0625 08:50:03.041836 55699 net.cpp:122] Setting up conv3_1/dw
I0625 08:50:03.041867 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.041878 55699 net.cpp:137] Memory required for data: 49021952
I0625 08:50:03.041893 55699 layer_factory.hpp:77] Creating layer conv3_1/dw/bn
I0625 08:50:03.041934 55699 net.cpp:84] Creating Layer conv3_1/dw/bn
I0625 08:50:03.041970 55699 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0625 08:50:03.041995 55699 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0625 08:50:03.042064 55699 net.cpp:122] Setting up conv3_1/dw/bn
I0625 08:50:03.042124 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.042150 55699 net.cpp:137] Memory required for data: 51119104
I0625 08:50:03.042186 55699 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0625 08:50:03.042227 55699 net.cpp:84] Creating Layer conv3_1/dw/scale
I0625 08:50:03.042248 55699 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0625 08:50:03.042261 55699 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0625 08:50:03.042320 55699 layer_factory.hpp:77] Creating layer conv3_1/dw/scale
I0625 08:50:03.042398 55699 net.cpp:122] Setting up conv3_1/dw/scale
I0625 08:50:03.042445 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.042479 55699 net.cpp:137] Memory required for data: 53216256
I0625 08:50:03.042500 55699 layer_factory.hpp:77] Creating layer relu3_1/dw
I0625 08:50:03.042537 55699 net.cpp:84] Creating Layer relu3_1/dw
I0625 08:50:03.042573 55699 net.cpp:406] relu3_1/dw <- conv3_1/dw
I0625 08:50:03.042596 55699 net.cpp:367] relu3_1/dw -> conv3_1/dw (in-place)
I0625 08:50:03.042611 55699 net.cpp:122] Setting up relu3_1/dw
I0625 08:50:03.042645 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.042680 55699 net.cpp:137] Memory required for data: 55313408
I0625 08:50:03.042695 55699 layer_factory.hpp:77] Creating layer conv3_1/sep
I0625 08:50:03.042734 55699 net.cpp:84] Creating Layer conv3_1/sep
I0625 08:50:03.042788 55699 net.cpp:406] conv3_1/sep <- conv3_1/dw
I0625 08:50:03.042842 55699 net.cpp:380] conv3_1/sep -> conv3_1/sep
I0625 08:50:03.043756 55699 net.cpp:122] Setting up conv3_1/sep
I0625 08:50:03.043807 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.043946 55699 net.cpp:137] Memory required for data: 57410560
I0625 08:50:03.044016 55699 layer_factory.hpp:77] Creating layer conv3_1/sep/bn
I0625 08:50:03.044102 55699 net.cpp:84] Creating Layer conv3_1/sep/bn
I0625 08:50:03.044126 55699 net.cpp:406] conv3_1/sep/bn <- conv3_1/sep
I0625 08:50:03.044147 55699 net.cpp:367] conv3_1/sep/bn -> conv3_1/sep (in-place)
I0625 08:50:03.044286 55699 net.cpp:122] Setting up conv3_1/sep/bn
I0625 08:50:03.044317 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.044325 55699 net.cpp:137] Memory required for data: 59507712
I0625 08:50:03.044349 55699 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0625 08:50:03.044414 55699 net.cpp:84] Creating Layer conv3_1/sep/scale
I0625 08:50:03.044456 55699 net.cpp:406] conv3_1/sep/scale <- conv3_1/sep
I0625 08:50:03.044492 55699 net.cpp:367] conv3_1/sep/scale -> conv3_1/sep (in-place)
I0625 08:50:03.044548 55699 layer_factory.hpp:77] Creating layer conv3_1/sep/scale
I0625 08:50:03.044600 55699 net.cpp:122] Setting up conv3_1/sep/scale
I0625 08:50:03.044679 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.044744 55699 net.cpp:137] Memory required for data: 61604864
I0625 08:50:03.044849 55699 layer_factory.hpp:77] Creating layer relu3_1/sep
I0625 08:50:03.044870 55699 net.cpp:84] Creating Layer relu3_1/sep
I0625 08:50:03.044935 55699 net.cpp:406] relu3_1/sep <- conv3_1/sep
I0625 08:50:03.044955 55699 net.cpp:367] relu3_1/sep -> conv3_1/sep (in-place)
I0625 08:50:03.044996 55699 net.cpp:122] Setting up relu3_1/sep
I0625 08:50:03.045013 55699 net.cpp:129] Top shape: 64 128 8 8 (524288)
I0625 08:50:03.045045 55699 net.cpp:137] Memory required for data: 63702016
I0625 08:50:03.045061 55699 layer_factory.hpp:77] Creating layer conv3_2/dw
I0625 08:50:03.045203 55699 net.cpp:84] Creating Layer conv3_2/dw
I0625 08:50:03.045251 55699 net.cpp:406] conv3_2/dw <- conv3_1/sep
I0625 08:50:03.045295 55699 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0625 08:50:03.045477 55699 net.cpp:122] Setting up conv3_2/dw
I0625 08:50:03.045537 55699 net.cpp:129] Top shape: 64 128 4 4 (131072)
I0625 08:50:03.045577 55699 net.cpp:137] Memory required for data: 64226304
I0625 08:50:03.045615 55699 layer_factory.hpp:77] Creating layer conv3_2/dw/bn
I0625 08:50:03.045657 55699 net.cpp:84] Creating Layer conv3_2/dw/bn
I0625 08:50:03.045694 55699 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0625 08:50:03.045734 55699 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0625 08:50:03.045821 55699 net.cpp:122] Setting up conv3_2/dw/bn
I0625 08:50:03.045871 55699 net.cpp:129] Top shape: 64 128 4 4 (131072)
I0625 08:50:03.045904 55699 net.cpp:137] Memory required for data: 64750592
I0625 08:50:03.045948 55699 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0625 08:50:03.046028 55699 net.cpp:84] Creating Layer conv3_2/dw/scale
I0625 08:50:03.046073 55699 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0625 08:50:03.046093 55699 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0625 08:50:03.046180 55699 layer_factory.hpp:77] Creating layer conv3_2/dw/scale
I0625 08:50:03.046275 55699 net.cpp:122] Setting up conv3_2/dw/scale
I0625 08:50:03.046324 55699 net.cpp:129] Top shape: 64 128 4 4 (131072)
I0625 08:50:03.046337 55699 net.cpp:137] Memory required for data: 65274880
I0625 08:50:03.046355 55699 layer_factory.hpp:77] Creating layer relu3_2/dw
I0625 08:50:03.046370 55699 net.cpp:84] Creating Layer relu3_2/dw
I0625 08:50:03.046412 55699 net.cpp:406] relu3_2/dw <- conv3_2/dw
I0625 08:50:03.046504 55699 net.cpp:367] relu3_2/dw -> conv3_2/dw (in-place)
I0625 08:50:03.046558 55699 net.cpp:122] Setting up relu3_2/dw
I0625 08:50:03.046600 55699 net.cpp:129] Top shape: 64 128 4 4 (131072)
I0625 08:50:03.046635 55699 net.cpp:137] Memory required for data: 65799168
I0625 08:50:03.046676 55699 layer_factory.hpp:77] Creating layer conv3_2/sep
I0625 08:50:03.046720 55699 net.cpp:84] Creating Layer conv3_2/sep
I0625 08:50:03.046758 55699 net.cpp:406] conv3_2/sep <- conv3_2/dw
I0625 08:50:03.046777 55699 net.cpp:380] conv3_2/sep -> conv3_2/sep
I0625 08:50:03.048617 55699 net.cpp:122] Setting up conv3_2/sep
I0625 08:50:03.048669 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.048704 55699 net.cpp:137] Memory required for data: 66847744
I0625 08:50:03.048743 55699 layer_factory.hpp:77] Creating layer conv3_2/sep/bn
I0625 08:50:03.048785 55699 net.cpp:84] Creating Layer conv3_2/sep/bn
I0625 08:50:03.048822 55699 net.cpp:406] conv3_2/sep/bn <- conv3_2/sep
I0625 08:50:03.048872 55699 net.cpp:367] conv3_2/sep/bn -> conv3_2/sep (in-place)
I0625 08:50:03.048964 55699 net.cpp:122] Setting up conv3_2/sep/bn
I0625 08:50:03.049011 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.049055 55699 net.cpp:137] Memory required for data: 67896320
I0625 08:50:03.049100 55699 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0625 08:50:03.049144 55699 net.cpp:84] Creating Layer conv3_2/sep/scale
I0625 08:50:03.049180 55699 net.cpp:406] conv3_2/sep/scale <- conv3_2/sep
I0625 08:50:03.049232 55699 net.cpp:367] conv3_2/sep/scale -> conv3_2/sep (in-place)
I0625 08:50:03.049289 55699 layer_factory.hpp:77] Creating layer conv3_2/sep/scale
I0625 08:50:03.049365 55699 net.cpp:122] Setting up conv3_2/sep/scale
I0625 08:50:03.049440 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.049477 55699 net.cpp:137] Memory required for data: 68944896
I0625 08:50:03.049518 55699 layer_factory.hpp:77] Creating layer relu3_2/sep
I0625 08:50:03.049559 55699 net.cpp:84] Creating Layer relu3_2/sep
I0625 08:50:03.049595 55699 net.cpp:406] relu3_2/sep <- conv3_2/sep
I0625 08:50:03.049634 55699 net.cpp:367] relu3_2/sep -> conv3_2/sep (in-place)
I0625 08:50:03.049677 55699 net.cpp:122] Setting up relu3_2/sep
I0625 08:50:03.049716 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.049751 55699 net.cpp:137] Memory required for data: 69993472
I0625 08:50:03.049785 55699 layer_factory.hpp:77] Creating layer conv4_1/dw
I0625 08:50:03.049839 55699 net.cpp:84] Creating Layer conv4_1/dw
I0625 08:50:03.049880 55699 net.cpp:406] conv4_1/dw <- conv3_2/sep
I0625 08:50:03.049922 55699 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0625 08:50:03.050115 55699 net.cpp:122] Setting up conv4_1/dw
I0625 08:50:03.050163 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.050199 55699 net.cpp:137] Memory required for data: 71042048
I0625 08:50:03.050236 55699 layer_factory.hpp:77] Creating layer conv4_1/dw/bn
I0625 08:50:03.050277 55699 net.cpp:84] Creating Layer conv4_1/dw/bn
I0625 08:50:03.050314 55699 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0625 08:50:03.050354 55699 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0625 08:50:03.050416 55699 net.cpp:122] Setting up conv4_1/dw/bn
I0625 08:50:03.050462 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.050495 55699 net.cpp:137] Memory required for data: 72090624
I0625 08:50:03.050536 55699 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0625 08:50:03.050578 55699 net.cpp:84] Creating Layer conv4_1/dw/scale
I0625 08:50:03.050616 55699 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0625 08:50:03.050657 55699 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0625 08:50:03.050719 55699 layer_factory.hpp:77] Creating layer conv4_1/dw/scale
I0625 08:50:03.050789 55699 net.cpp:122] Setting up conv4_1/dw/scale
I0625 08:50:03.050855 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.050891 55699 net.cpp:137] Memory required for data: 73139200
I0625 08:50:03.050932 55699 layer_factory.hpp:77] Creating layer relu4_1/dw
I0625 08:50:03.050972 55699 net.cpp:84] Creating Layer relu4_1/dw
I0625 08:50:03.051019 55699 net.cpp:406] relu4_1/dw <- conv4_1/dw
I0625 08:50:03.051107 55699 net.cpp:367] relu4_1/dw -> conv4_1/dw (in-place)
I0625 08:50:03.051157 55699 net.cpp:122] Setting up relu4_1/dw
I0625 08:50:03.051199 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.051234 55699 net.cpp:137] Memory required for data: 74187776
I0625 08:50:03.051268 55699 layer_factory.hpp:77] Creating layer conv4_1/sep
I0625 08:50:03.051324 55699 net.cpp:84] Creating Layer conv4_1/sep
I0625 08:50:03.051367 55699 net.cpp:406] conv4_1/sep <- conv4_1/dw
I0625 08:50:03.051409 55699 net.cpp:380] conv4_1/sep -> conv4_1/sep
I0625 08:50:03.054987 55699 net.cpp:122] Setting up conv4_1/sep
I0625 08:50:03.055037 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.055073 55699 net.cpp:137] Memory required for data: 75236352
I0625 08:50:03.055110 55699 layer_factory.hpp:77] Creating layer conv4_1/sep/bn
I0625 08:50:03.055164 55699 net.cpp:84] Creating Layer conv4_1/sep/bn
I0625 08:50:03.069766 55699 net.cpp:406] conv4_1/sep/bn <- conv4_1/sep
I0625 08:50:03.069895 55699 net.cpp:367] conv4_1/sep/bn -> conv4_1/sep (in-place)
I0625 08:50:03.070001 55699 net.cpp:122] Setting up conv4_1/sep/bn
I0625 08:50:03.070053 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.070088 55699 net.cpp:137] Memory required for data: 76284928
I0625 08:50:03.070119 55699 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0625 08:50:03.070197 55699 net.cpp:84] Creating Layer conv4_1/sep/scale
I0625 08:50:03.070242 55699 net.cpp:406] conv4_1/sep/scale <- conv4_1/sep
I0625 08:50:03.070303 55699 net.cpp:367] conv4_1/sep/scale -> conv4_1/sep (in-place)
I0625 08:50:03.070428 55699 layer_factory.hpp:77] Creating layer conv4_1/sep/scale
I0625 08:50:03.070538 55699 net.cpp:122] Setting up conv4_1/sep/scale
I0625 08:50:03.070586 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.070605 55699 net.cpp:137] Memory required for data: 77333504
I0625 08:50:03.070668 55699 layer_factory.hpp:77] Creating layer relu4_1/sep
I0625 08:50:03.070750 55699 net.cpp:84] Creating Layer relu4_1/sep
I0625 08:50:03.070835 55699 net.cpp:406] relu4_1/sep <- conv4_1/sep
I0625 08:50:03.070879 55699 net.cpp:367] relu4_1/sep -> conv4_1/sep (in-place)
I0625 08:50:03.070924 55699 net.cpp:122] Setting up relu4_1/sep
I0625 08:50:03.070964 55699 net.cpp:129] Top shape: 64 256 4 4 (262144)
I0625 08:50:03.070997 55699 net.cpp:137] Memory required for data: 78382080
I0625 08:50:03.071013 55699 layer_factory.hpp:77] Creating layer conv4_2/dw
I0625 08:50:03.071055 55699 net.cpp:84] Creating Layer conv4_2/dw
I0625 08:50:03.071094 55699 net.cpp:406] conv4_2/dw <- conv4_1/sep
I0625 08:50:03.071120 55699 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0625 08:50:03.071316 55699 net.cpp:122] Setting up conv4_2/dw
I0625 08:50:03.071379 55699 net.cpp:129] Top shape: 64 256 2 2 (65536)
I0625 08:50:03.071418 55699 net.cpp:137] Memory required for data: 78644224
I0625 08:50:03.071441 55699 layer_factory.hpp:77] Creating layer conv4_2/dw/bn
I0625 08:50:03.071528 55699 net.cpp:84] Creating Layer conv4_2/dw/bn
I0625 08:50:03.071602 55699 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0625 08:50:03.071624 55699 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0625 08:50:03.071717 55699 net.cpp:122] Setting up conv4_2/dw/bn
I0625 08:50:03.071768 55699 net.cpp:129] Top shape: 64 256 2 2 (65536)
I0625 08:50:03.071804 55699 net.cpp:137] Memory required for data: 78906368
I0625 08:50:03.071832 55699 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0625 08:50:03.071892 55699 net.cpp:84] Creating Layer conv4_2/dw/scale
I0625 08:50:03.071938 55699 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0625 08:50:03.071964 55699 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0625 08:50:03.071997 55699 layer_factory.hpp:77] Creating layer conv4_2/dw/scale
I0625 08:50:03.072088 55699 net.cpp:122] Setting up conv4_2/dw/scale
I0625 08:50:03.072137 55699 net.cpp:129] Top shape: 64 256 2 2 (65536)
I0625 08:50:03.072172 55699 net.cpp:137] Memory required for data: 79168512
I0625 08:50:03.072198 55699 layer_factory.hpp:77] Creating layer relu4_2/dw
I0625 08:50:03.072216 55699 net.cpp:84] Creating Layer relu4_2/dw
I0625 08:50:03.072249 55699 net.cpp:406] relu4_2/dw <- conv4_2/dw
I0625 08:50:03.072288 55699 net.cpp:367] relu4_2/dw -> conv4_2/dw (in-place)
I0625 08:50:03.072332 55699 net.cpp:122] Setting up relu4_2/dw
I0625 08:50:03.072374 55699 net.cpp:129] Top shape: 64 256 2 2 (65536)
I0625 08:50:03.072408 55699 net.cpp:137] Memory required for data: 79430656
I0625 08:50:03.072427 55699 layer_factory.hpp:77] Creating layer conv4_2/sep
I0625 08:50:03.072458 55699 net.cpp:84] Creating Layer conv4_2/sep
I0625 08:50:03.072506 55699 net.cpp:406] conv4_2/sep <- conv4_2/dw
I0625 08:50:03.072551 55699 net.cpp:380] conv4_2/sep -> conv4_2/sep
I0625 08:50:03.079902 55699 net.cpp:122] Setting up conv4_2/sep
I0625 08:50:03.080003 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.080046 55699 net.cpp:137] Memory required for data: 79954944
I0625 08:50:03.080088 55699 layer_factory.hpp:77] Creating layer conv4_2/sep/bn
I0625 08:50:03.080133 55699 net.cpp:84] Creating Layer conv4_2/sep/bn
I0625 08:50:03.080171 55699 net.cpp:406] conv4_2/sep/bn <- conv4_2/sep
I0625 08:50:03.080222 55699 net.cpp:367] conv4_2/sep/bn -> conv4_2/sep (in-place)
I0625 08:50:03.080308 55699 net.cpp:122] Setting up conv4_2/sep/bn
I0625 08:50:03.080355 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.080390 55699 net.cpp:137] Memory required for data: 80479232
I0625 08:50:03.080411 55699 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0625 08:50:03.080440 55699 net.cpp:84] Creating Layer conv4_2/sep/scale
I0625 08:50:03.080477 55699 net.cpp:406] conv4_2/sep/scale <- conv4_2/sep
I0625 08:50:03.080569 55699 net.cpp:367] conv4_2/sep/scale -> conv4_2/sep (in-place)
I0625 08:50:03.080613 55699 layer_factory.hpp:77] Creating layer conv4_2/sep/scale
I0625 08:50:03.080735 55699 net.cpp:122] Setting up conv4_2/sep/scale
I0625 08:50:03.080770 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.080804 55699 net.cpp:137] Memory required for data: 81003520
I0625 08:50:03.080847 55699 layer_factory.hpp:77] Creating layer relu4_2/sep
I0625 08:50:03.080889 55699 net.cpp:84] Creating Layer relu4_2/sep
I0625 08:50:03.080927 55699 net.cpp:406] relu4_2/sep <- conv4_2/sep
I0625 08:50:03.080966 55699 net.cpp:367] relu4_2/sep -> conv4_2/sep (in-place)
I0625 08:50:03.081010 55699 net.cpp:122] Setting up relu4_2/sep
I0625 08:50:03.081050 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.081063 55699 net.cpp:137] Memory required for data: 81527808
I0625 08:50:03.081079 55699 layer_factory.hpp:77] Creating layer conv5_1/dw
I0625 08:50:03.081136 55699 net.cpp:84] Creating Layer conv5_1/dw
I0625 08:50:03.081182 55699 net.cpp:406] conv5_1/dw <- conv4_2/sep
I0625 08:50:03.081226 55699 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0625 08:50:03.081576 55699 net.cpp:122] Setting up conv5_1/dw
I0625 08:50:03.081629 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.081665 55699 net.cpp:137] Memory required for data: 82052096
I0625 08:50:03.081703 55699 layer_factory.hpp:77] Creating layer conv5_1/dw/bn
I0625 08:50:03.081744 55699 net.cpp:84] Creating Layer conv5_1/dw/bn
I0625 08:50:03.081781 55699 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0625 08:50:03.081831 55699 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0625 08:50:03.081923 55699 net.cpp:122] Setting up conv5_1/dw/bn
I0625 08:50:03.081971 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.082006 55699 net.cpp:137] Memory required for data: 82576384
I0625 08:50:03.082048 55699 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0625 08:50:03.082103 55699 net.cpp:84] Creating Layer conv5_1/dw/scale
I0625 08:50:03.082142 55699 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0625 08:50:03.082216 55699 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0625 08:50:03.082298 55699 layer_factory.hpp:77] Creating layer conv5_1/dw/scale
I0625 08:50:03.082406 55699 net.cpp:122] Setting up conv5_1/dw/scale
I0625 08:50:03.082454 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.082489 55699 net.cpp:137] Memory required for data: 83100672
I0625 08:50:03.082530 55699 layer_factory.hpp:77] Creating layer relu5_1/dw
I0625 08:50:03.082569 55699 net.cpp:84] Creating Layer relu5_1/dw
I0625 08:50:03.082607 55699 net.cpp:406] relu5_1/dw <- conv5_1/dw
I0625 08:50:03.082644 55699 net.cpp:367] relu5_1/dw -> conv5_1/dw (in-place)
I0625 08:50:03.082686 55699 net.cpp:122] Setting up relu5_1/dw
I0625 08:50:03.082726 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.082759 55699 net.cpp:137] Memory required for data: 83624960
I0625 08:50:03.082772 55699 layer_factory.hpp:77] Creating layer conv5_1/sep
I0625 08:50:03.082806 55699 net.cpp:84] Creating Layer conv5_1/sep
I0625 08:50:03.082876 55699 net.cpp:406] conv5_1/sep <- conv5_1/dw
I0625 08:50:03.082933 55699 net.cpp:380] conv5_1/sep -> conv5_1/sep
I0625 08:50:03.097581 55699 net.cpp:122] Setting up conv5_1/sep
I0625 08:50:03.097679 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.097724 55699 net.cpp:137] Memory required for data: 84149248
I0625 08:50:03.097753 55699 layer_factory.hpp:77] Creating layer conv5_1/sep/bn
I0625 08:50:03.097800 55699 net.cpp:84] Creating Layer conv5_1/sep/bn
I0625 08:50:03.097839 55699 net.cpp:406] conv5_1/sep/bn <- conv5_1/sep
I0625 08:50:03.097883 55699 net.cpp:367] conv5_1/sep/bn -> conv5_1/sep (in-place)
I0625 08:50:03.097970 55699 net.cpp:122] Setting up conv5_1/sep/bn
I0625 08:50:03.098031 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.098069 55699 net.cpp:137] Memory required for data: 84673536
I0625 08:50:03.098114 55699 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0625 08:50:03.098214 55699 net.cpp:84] Creating Layer conv5_1/sep/scale
I0625 08:50:03.098254 55699 net.cpp:406] conv5_1/sep/scale <- conv5_1/sep
I0625 08:50:03.098309 55699 net.cpp:367] conv5_1/sep/scale -> conv5_1/sep (in-place)
I0625 08:50:03.098373 55699 layer_factory.hpp:77] Creating layer conv5_1/sep/scale
I0625 08:50:03.098449 55699 net.cpp:122] Setting up conv5_1/sep/scale
I0625 08:50:03.098505 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.098541 55699 net.cpp:137] Memory required for data: 85197824
I0625 08:50:03.098582 55699 layer_factory.hpp:77] Creating layer relu5_1/sep
I0625 08:50:03.098624 55699 net.cpp:84] Creating Layer relu5_1/sep
I0625 08:50:03.098660 55699 net.cpp:406] relu5_1/sep <- conv5_1/sep
I0625 08:50:03.098698 55699 net.cpp:367] relu5_1/sep -> conv5_1/sep (in-place)
I0625 08:50:03.098742 55699 net.cpp:122] Setting up relu5_1/sep
I0625 08:50:03.098803 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.098850 55699 net.cpp:137] Memory required for data: 85722112
I0625 08:50:03.098886 55699 layer_factory.hpp:77] Creating layer conv5_2/dw
I0625 08:50:03.098932 55699 net.cpp:84] Creating Layer conv5_2/dw
I0625 08:50:03.098969 55699 net.cpp:406] conv5_2/dw <- conv5_1/sep
I0625 08:50:03.099052 55699 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0625 08:50:03.099346 55699 net.cpp:122] Setting up conv5_2/dw
I0625 08:50:03.099395 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.099428 55699 net.cpp:137] Memory required for data: 86246400
I0625 08:50:03.099467 55699 layer_factory.hpp:77] Creating layer conv5_2/dw/bn
I0625 08:50:03.099508 55699 net.cpp:84] Creating Layer conv5_2/dw/bn
I0625 08:50:03.099545 55699 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0625 08:50:03.099583 55699 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0625 08:50:03.099647 55699 net.cpp:122] Setting up conv5_2/dw/bn
I0625 08:50:03.099691 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.099725 55699 net.cpp:137] Memory required for data: 86770688
I0625 08:50:03.099767 55699 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0625 08:50:03.099850 55699 net.cpp:84] Creating Layer conv5_2/dw/scale
I0625 08:50:03.099895 55699 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0625 08:50:03.099936 55699 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0625 08:50:03.100000 55699 layer_factory.hpp:77] Creating layer conv5_2/dw/scale
I0625 08:50:03.100111 55699 net.cpp:122] Setting up conv5_2/dw/scale
I0625 08:50:03.100159 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.100193 55699 net.cpp:137] Memory required for data: 87294976
I0625 08:50:03.100234 55699 layer_factory.hpp:77] Creating layer relu5_2/dw
I0625 08:50:03.100275 55699 net.cpp:84] Creating Layer relu5_2/dw
I0625 08:50:03.100311 55699 net.cpp:406] relu5_2/dw <- conv5_2/dw
I0625 08:50:03.100349 55699 net.cpp:367] relu5_2/dw -> conv5_2/dw (in-place)
I0625 08:50:03.100391 55699 net.cpp:122] Setting up relu5_2/dw
I0625 08:50:03.100431 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.100464 55699 net.cpp:137] Memory required for data: 87819264
I0625 08:50:03.100498 55699 layer_factory.hpp:77] Creating layer conv5_2/sep
I0625 08:50:03.100553 55699 net.cpp:84] Creating Layer conv5_2/sep
I0625 08:50:03.100594 55699 net.cpp:406] conv5_2/sep <- conv5_2/dw
I0625 08:50:03.100646 55699 net.cpp:380] conv5_2/sep -> conv5_2/sep
I0625 08:50:03.114398 55699 net.cpp:122] Setting up conv5_2/sep
I0625 08:50:03.114480 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.114519 55699 net.cpp:137] Memory required for data: 88343552
I0625 08:50:03.114562 55699 layer_factory.hpp:77] Creating layer conv5_2/sep/bn
I0625 08:50:03.114609 55699 net.cpp:84] Creating Layer conv5_2/sep/bn
I0625 08:50:03.114648 55699 net.cpp:406] conv5_2/sep/bn <- conv5_2/sep
I0625 08:50:03.114689 55699 net.cpp:367] conv5_2/sep/bn -> conv5_2/sep (in-place)
I0625 08:50:03.114755 55699 net.cpp:122] Setting up conv5_2/sep/bn
I0625 08:50:03.114817 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.114894 55699 net.cpp:137] Memory required for data: 88867840
I0625 08:50:03.114941 55699 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0625 08:50:03.114994 55699 net.cpp:84] Creating Layer conv5_2/sep/scale
I0625 08:50:03.115033 55699 net.cpp:406] conv5_2/sep/scale <- conv5_2/sep
I0625 08:50:03.115073 55699 net.cpp:367] conv5_2/sep/scale -> conv5_2/sep (in-place)
I0625 08:50:03.115130 55699 layer_factory.hpp:77] Creating layer conv5_2/sep/scale
I0625 08:50:03.115198 55699 net.cpp:122] Setting up conv5_2/sep/scale
I0625 08:50:03.115244 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.115278 55699 net.cpp:137] Memory required for data: 89392128
I0625 08:50:03.115319 55699 layer_factory.hpp:77] Creating layer relu5_2/sep
I0625 08:50:03.115360 55699 net.cpp:84] Creating Layer relu5_2/sep
I0625 08:50:03.115397 55699 net.cpp:406] relu5_2/sep <- conv5_2/sep
I0625 08:50:03.115449 55699 net.cpp:367] relu5_2/sep -> conv5_2/sep (in-place)
I0625 08:50:03.115495 55699 net.cpp:122] Setting up relu5_2/sep
I0625 08:50:03.115511 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.115520 55699 net.cpp:137] Memory required for data: 89916416
I0625 08:50:03.115537 55699 layer_factory.hpp:77] Creating layer conv5_3/dw
I0625 08:50:03.115556 55699 net.cpp:84] Creating Layer conv5_3/dw
I0625 08:50:03.115591 55699 net.cpp:406] conv5_3/dw <- conv5_2/sep
I0625 08:50:03.115623 55699 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0625 08:50:03.115888 55699 net.cpp:122] Setting up conv5_3/dw
I0625 08:50:03.115947 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.115985 55699 net.cpp:137] Memory required for data: 90440704
I0625 08:50:03.116025 55699 layer_factory.hpp:77] Creating layer conv5_3/dw/bn
I0625 08:50:03.116075 55699 net.cpp:84] Creating Layer conv5_3/dw/bn
I0625 08:50:03.116113 55699 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0625 08:50:03.116153 55699 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0625 08:50:03.116219 55699 net.cpp:122] Setting up conv5_3/dw/bn
I0625 08:50:03.116266 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.116310 55699 net.cpp:137] Memory required for data: 90964992
I0625 08:50:03.116356 55699 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0625 08:50:03.116405 55699 net.cpp:84] Creating Layer conv5_3/dw/scale
I0625 08:50:03.116466 55699 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0625 08:50:03.116514 55699 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0625 08:50:03.116570 55699 layer_factory.hpp:77] Creating layer conv5_3/dw/scale
I0625 08:50:03.116638 55699 net.cpp:122] Setting up conv5_3/dw/scale
I0625 08:50:03.116689 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.116726 55699 net.cpp:137] Memory required for data: 91489280
I0625 08:50:03.116767 55699 layer_factory.hpp:77] Creating layer relu5_3/dw
I0625 08:50:03.116807 55699 net.cpp:84] Creating Layer relu5_3/dw
I0625 08:50:03.116844 55699 net.cpp:406] relu5_3/dw <- conv5_3/dw
I0625 08:50:03.116883 55699 net.cpp:367] relu5_3/dw -> conv5_3/dw (in-place)
I0625 08:50:03.116926 55699 net.cpp:122] Setting up relu5_3/dw
I0625 08:50:03.116966 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.116998 55699 net.cpp:137] Memory required for data: 92013568
I0625 08:50:03.117033 55699 layer_factory.hpp:77] Creating layer conv5_3/sep
I0625 08:50:03.117112 55699 net.cpp:84] Creating Layer conv5_3/sep
I0625 08:50:03.117158 55699 net.cpp:406] conv5_3/sep <- conv5_3/dw
I0625 08:50:03.117202 55699 net.cpp:380] conv5_3/sep -> conv5_3/sep
I0625 08:50:03.130605 55699 net.cpp:122] Setting up conv5_3/sep
I0625 08:50:03.130679 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.130715 55699 net.cpp:137] Memory required for data: 92537856
I0625 08:50:03.130741 55699 layer_factory.hpp:77] Creating layer conv5_3/sep/bn
I0625 08:50:03.130823 55699 net.cpp:84] Creating Layer conv5_3/sep/bn
I0625 08:50:03.130872 55699 net.cpp:406] conv5_3/sep/bn <- conv5_3/sep
I0625 08:50:03.130914 55699 net.cpp:367] conv5_3/sep/bn -> conv5_3/sep (in-place)
I0625 08:50:03.131067 55699 net.cpp:122] Setting up conv5_3/sep/bn
I0625 08:50:03.131130 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.131167 55699 net.cpp:137] Memory required for data: 93062144
I0625 08:50:03.131212 55699 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0625 08:50:03.131258 55699 net.cpp:84] Creating Layer conv5_3/sep/scale
I0625 08:50:03.131296 55699 net.cpp:406] conv5_3/sep/scale <- conv5_3/sep
I0625 08:50:03.131348 55699 net.cpp:367] conv5_3/sep/scale -> conv5_3/sep (in-place)
I0625 08:50:03.131409 55699 layer_factory.hpp:77] Creating layer conv5_3/sep/scale
I0625 08:50:03.131487 55699 net.cpp:122] Setting up conv5_3/sep/scale
I0625 08:50:03.131536 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.131570 55699 net.cpp:137] Memory required for data: 93586432
I0625 08:50:03.131611 55699 layer_factory.hpp:77] Creating layer relu5_3/sep
I0625 08:50:03.131662 55699 net.cpp:84] Creating Layer relu5_3/sep
I0625 08:50:03.131703 55699 net.cpp:406] relu5_3/sep <- conv5_3/sep
I0625 08:50:03.131744 55699 net.cpp:367] relu5_3/sep -> conv5_3/sep (in-place)
I0625 08:50:03.131788 55699 net.cpp:122] Setting up relu5_3/sep
I0625 08:50:03.131829 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.131862 55699 net.cpp:137] Memory required for data: 94110720
I0625 08:50:03.131897 55699 layer_factory.hpp:77] Creating layer conv5_4/dw
I0625 08:50:03.131942 55699 net.cpp:84] Creating Layer conv5_4/dw
I0625 08:50:03.131981 55699 net.cpp:406] conv5_4/dw <- conv5_3/sep
I0625 08:50:03.132024 55699 net.cpp:380] conv5_4/dw -> conv5_4/dw
I0625 08:50:03.132356 55699 net.cpp:122] Setting up conv5_4/dw
I0625 08:50:03.132407 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.132442 55699 net.cpp:137] Memory required for data: 94635008
I0625 08:50:03.132483 55699 layer_factory.hpp:77] Creating layer conv5_4/dw/bn
I0625 08:50:03.132524 55699 net.cpp:84] Creating Layer conv5_4/dw/bn
I0625 08:50:03.132561 55699 net.cpp:406] conv5_4/dw/bn <- conv5_4/dw
I0625 08:50:03.132601 55699 net.cpp:367] conv5_4/dw/bn -> conv5_4/dw (in-place)
I0625 08:50:03.132665 55699 net.cpp:122] Setting up conv5_4/dw/bn
I0625 08:50:03.132716 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.132751 55699 net.cpp:137] Memory required for data: 95159296
I0625 08:50:03.132796 55699 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0625 08:50:03.132838 55699 net.cpp:84] Creating Layer conv5_4/dw/scale
I0625 08:50:03.132876 55699 net.cpp:406] conv5_4/dw/scale <- conv5_4/dw
I0625 08:50:03.132927 55699 net.cpp:367] conv5_4/dw/scale -> conv5_4/dw (in-place)
I0625 08:50:03.132997 55699 layer_factory.hpp:77] Creating layer conv5_4/dw/scale
I0625 08:50:03.133088 55699 net.cpp:122] Setting up conv5_4/dw/scale
I0625 08:50:03.133136 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.133170 55699 net.cpp:137] Memory required for data: 95683584
I0625 08:50:03.133213 55699 layer_factory.hpp:77] Creating layer relu5_4/dw
I0625 08:50:03.133252 55699 net.cpp:84] Creating Layer relu5_4/dw
I0625 08:50:03.133291 55699 net.cpp:406] relu5_4/dw <- conv5_4/dw
I0625 08:50:03.133340 55699 net.cpp:367] relu5_4/dw -> conv5_4/dw (in-place)
I0625 08:50:03.133388 55699 net.cpp:122] Setting up relu5_4/dw
I0625 08:50:03.133428 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.133462 55699 net.cpp:137] Memory required for data: 96207872
I0625 08:50:03.133497 55699 layer_factory.hpp:77] Creating layer conv5_4/sep
I0625 08:50:03.133540 55699 net.cpp:84] Creating Layer conv5_4/sep
I0625 08:50:03.133579 55699 net.cpp:406] conv5_4/sep <- conv5_4/dw
I0625 08:50:03.133612 55699 net.cpp:380] conv5_4/sep -> conv5_4/sep
I0625 08:50:03.147511 55699 net.cpp:122] Setting up conv5_4/sep
I0625 08:50:03.147598 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.147613 55699 net.cpp:137] Memory required for data: 96732160
I0625 08:50:03.147640 55699 layer_factory.hpp:77] Creating layer conv5_4/sep/bn
I0625 08:50:03.147722 55699 net.cpp:84] Creating Layer conv5_4/sep/bn
I0625 08:50:03.147783 55699 net.cpp:406] conv5_4/sep/bn <- conv5_4/sep
I0625 08:50:03.147902 55699 net.cpp:367] conv5_4/sep/bn -> conv5_4/sep (in-place)
I0625 08:50:03.147990 55699 net.cpp:122] Setting up conv5_4/sep/bn
I0625 08:50:03.148037 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.148078 55699 net.cpp:137] Memory required for data: 97256448
I0625 08:50:03.148121 55699 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0625 08:50:03.148167 55699 net.cpp:84] Creating Layer conv5_4/sep/scale
I0625 08:50:03.148205 55699 net.cpp:406] conv5_4/sep/scale <- conv5_4/sep
I0625 08:50:03.148244 55699 net.cpp:367] conv5_4/sep/scale -> conv5_4/sep (in-place)
I0625 08:50:03.148306 55699 layer_factory.hpp:77] Creating layer conv5_4/sep/scale
I0625 08:50:03.148375 55699 net.cpp:122] Setting up conv5_4/sep/scale
I0625 08:50:03.148419 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.148454 55699 net.cpp:137] Memory required for data: 97780736
I0625 08:50:03.148494 55699 layer_factory.hpp:77] Creating layer relu5_4/sep
I0625 08:50:03.148535 55699 net.cpp:84] Creating Layer relu5_4/sep
I0625 08:50:03.148571 55699 net.cpp:406] relu5_4/sep <- conv5_4/sep
I0625 08:50:03.148615 55699 net.cpp:367] relu5_4/sep -> conv5_4/sep (in-place)
I0625 08:50:03.148663 55699 net.cpp:122] Setting up relu5_4/sep
I0625 08:50:03.148703 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.148737 55699 net.cpp:137] Memory required for data: 98305024
I0625 08:50:03.148772 55699 layer_factory.hpp:77] Creating layer conv5_5/dw
I0625 08:50:03.148815 55699 net.cpp:84] Creating Layer conv5_5/dw
I0625 08:50:03.148852 55699 net.cpp:406] conv5_5/dw <- conv5_4/sep
I0625 08:50:03.148895 55699 net.cpp:380] conv5_5/dw -> conv5_5/dw
I0625 08:50:03.149170 55699 net.cpp:122] Setting up conv5_5/dw
I0625 08:50:03.149217 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.149251 55699 net.cpp:137] Memory required for data: 98829312
I0625 08:50:03.149291 55699 layer_factory.hpp:77] Creating layer conv5_5/dw/bn
I0625 08:50:03.149338 55699 net.cpp:84] Creating Layer conv5_5/dw/bn
I0625 08:50:03.149376 55699 net.cpp:406] conv5_5/dw/bn <- conv5_5/dw
I0625 08:50:03.149416 55699 net.cpp:367] conv5_5/dw/bn -> conv5_5/dw (in-place)
I0625 08:50:03.149503 55699 net.cpp:122] Setting up conv5_5/dw/bn
I0625 08:50:03.149552 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.149587 55699 net.cpp:137] Memory required for data: 99353600
I0625 08:50:03.149672 55699 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0625 08:50:03.149721 55699 net.cpp:84] Creating Layer conv5_5/dw/scale
I0625 08:50:03.149760 55699 net.cpp:406] conv5_5/dw/scale <- conv5_5/dw
I0625 08:50:03.149801 55699 net.cpp:367] conv5_5/dw/scale -> conv5_5/dw (in-place)
I0625 08:50:03.149863 55699 layer_factory.hpp:77] Creating layer conv5_5/dw/scale
I0625 08:50:03.149932 55699 net.cpp:122] Setting up conv5_5/dw/scale
I0625 08:50:03.149978 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.150012 55699 net.cpp:137] Memory required for data: 99877888
I0625 08:50:03.150053 55699 layer_factory.hpp:77] Creating layer relu5_5/dw
I0625 08:50:03.150092 55699 net.cpp:84] Creating Layer relu5_5/dw
I0625 08:50:03.150130 55699 net.cpp:406] relu5_5/dw <- conv5_5/dw
I0625 08:50:03.150168 55699 net.cpp:367] relu5_5/dw -> conv5_5/dw (in-place)
I0625 08:50:03.150212 55699 net.cpp:122] Setting up relu5_5/dw
I0625 08:50:03.150251 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.150285 55699 net.cpp:137] Memory required for data: 100402176
I0625 08:50:03.150319 55699 layer_factory.hpp:77] Creating layer conv5_5/sep
I0625 08:50:03.150396 55699 net.cpp:84] Creating Layer conv5_5/sep
I0625 08:50:03.150444 55699 net.cpp:406] conv5_5/sep <- conv5_5/dw
I0625 08:50:03.150486 55699 net.cpp:380] conv5_5/sep -> conv5_5/sep
I0625 08:50:03.163789 55699 net.cpp:122] Setting up conv5_5/sep
I0625 08:50:03.163846 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.163882 55699 net.cpp:137] Memory required for data: 100926464
I0625 08:50:03.163906 55699 layer_factory.hpp:77] Creating layer conv5_5/sep/bn
I0625 08:50:03.164041 55699 net.cpp:84] Creating Layer conv5_5/sep/bn
I0625 08:50:03.164088 55699 net.cpp:406] conv5_5/sep/bn <- conv5_5/sep
I0625 08:50:03.164129 55699 net.cpp:367] conv5_5/sep/bn -> conv5_5/sep (in-place)
I0625 08:50:03.164194 55699 net.cpp:122] Setting up conv5_5/sep/bn
I0625 08:50:03.164225 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.164233 55699 net.cpp:137] Memory required for data: 101450752
I0625 08:50:03.164248 55699 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0625 08:50:03.164283 55699 net.cpp:84] Creating Layer conv5_5/sep/scale
I0625 08:50:03.164300 55699 net.cpp:406] conv5_5/sep/scale <- conv5_5/sep
I0625 08:50:03.164319 55699 net.cpp:367] conv5_5/sep/scale -> conv5_5/sep (in-place)
I0625 08:50:03.164345 55699 layer_factory.hpp:77] Creating layer conv5_5/sep/scale
I0625 08:50:03.164376 55699 net.cpp:122] Setting up conv5_5/sep/scale
I0625 08:50:03.164391 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.164399 55699 net.cpp:137] Memory required for data: 101975040
I0625 08:50:03.164412 55699 layer_factory.hpp:77] Creating layer relu5_5/sep
I0625 08:50:03.164423 55699 net.cpp:84] Creating Layer relu5_5/sep
I0625 08:50:03.164433 55699 net.cpp:406] relu5_5/sep <- conv5_5/sep
I0625 08:50:03.164443 55699 net.cpp:367] relu5_5/sep -> conv5_5/sep (in-place)
I0625 08:50:03.164454 55699 net.cpp:122] Setting up relu5_5/sep
I0625 08:50:03.164465 55699 net.cpp:129] Top shape: 64 512 2 2 (131072)
I0625 08:50:03.164474 55699 net.cpp:137] Memory required for data: 102499328
I0625 08:50:03.164486 55699 layer_factory.hpp:77] Creating layer conv5_6/dw
I0625 08:50:03.164506 55699 net.cpp:84] Creating Layer conv5_6/dw
I0625 08:50:03.164544 55699 net.cpp:406] conv5_6/dw <- conv5_5/sep
I0625 08:50:03.164585 55699 net.cpp:380] conv5_6/dw -> conv5_6/dw
I0625 08:50:03.164875 55699 net.cpp:122] Setting up conv5_6/dw
I0625 08:50:03.164925 55699 net.cpp:129] Top shape: 64 512 1 1 (32768)
I0625 08:50:03.164961 55699 net.cpp:137] Memory required for data: 102630400
I0625 08:50:03.165001 55699 layer_factory.hpp:77] Creating layer conv5_6/dw/bn
I0625 08:50:03.165050 55699 net.cpp:84] Creating Layer conv5_6/dw/bn
I0625 08:50:03.165089 55699 net.cpp:406] conv5_6/dw/bn <- conv5_6/dw
I0625 08:50:03.165129 55699 net.cpp:367] conv5_6/dw/bn -> conv5_6/dw (in-place)
I0625 08:50:03.165189 55699 net.cpp:122] Setting up conv5_6/dw/bn
I0625 08:50:03.165233 55699 net.cpp:129] Top shape: 64 512 1 1 (32768)
I0625 08:50:03.165283 55699 net.cpp:137] Memory required for data: 102761472
I0625 08:50:03.165310 55699 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0625 08:50:03.165356 55699 net.cpp:84] Creating Layer conv5_6/dw/scale
I0625 08:50:03.165396 55699 net.cpp:406] conv5_6/dw/scale <- conv5_6/dw
I0625 08:50:03.165437 55699 net.cpp:367] conv5_6/dw/scale -> conv5_6/dw (in-place)
I0625 08:50:03.165498 55699 layer_factory.hpp:77] Creating layer conv5_6/dw/scale
I0625 08:50:03.165540 55699 net.cpp:122] Setting up conv5_6/dw/scale
I0625 08:50:03.165555 55699 net.cpp:129] Top shape: 64 512 1 1 (32768)
I0625 08:50:03.165563 55699 net.cpp:137] Memory required for data: 102892544
I0625 08:50:03.165585 55699 layer_factory.hpp:77] Creating layer relu5_6/dw
I0625 08:50:03.165638 55699 net.cpp:84] Creating Layer relu5_6/dw
I0625 08:50:03.165674 55699 net.cpp:406] relu5_6/dw <- conv5_6/dw
I0625 08:50:03.165688 55699 net.cpp:367] relu5_6/dw -> conv5_6/dw (in-place)
I0625 08:50:03.165704 55699 net.cpp:122] Setting up relu5_6/dw
I0625 08:50:03.165715 55699 net.cpp:129] Top shape: 64 512 1 1 (32768)
I0625 08:50:03.165750 55699 net.cpp:137] Memory required for data: 103023616
I0625 08:50:03.165786 55699 layer_factory.hpp:77] Creating layer conv5_6/sep
I0625 08:50:03.165863 55699 net.cpp:84] Creating Layer conv5_6/sep
I0625 08:50:03.165908 55699 net.cpp:406] conv5_6/sep <- conv5_6/dw
I0625 08:50:03.165951 55699 net.cpp:380] conv5_6/sep -> conv5_6/sep
I0625 08:50:03.193253 55699 net.cpp:122] Setting up conv5_6/sep
I0625 08:50:03.193334 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.193410 55699 net.cpp:137] Memory required for data: 103285760
I0625 08:50:03.193457 55699 layer_factory.hpp:77] Creating layer conv5_6/sep/bn
I0625 08:50:03.193519 55699 net.cpp:84] Creating Layer conv5_6/sep/bn
I0625 08:50:03.193572 55699 net.cpp:406] conv5_6/sep/bn <- conv5_6/sep
I0625 08:50:03.193616 55699 net.cpp:367] conv5_6/sep/bn -> conv5_6/sep (in-place)
I0625 08:50:03.193691 55699 net.cpp:122] Setting up conv5_6/sep/bn
I0625 08:50:03.193737 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.193791 55699 net.cpp:137] Memory required for data: 103547904
I0625 08:50:03.193837 55699 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0625 08:50:03.193882 55699 net.cpp:84] Creating Layer conv5_6/sep/scale
I0625 08:50:03.193920 55699 net.cpp:406] conv5_6/sep/scale <- conv5_6/sep
I0625 08:50:03.193945 55699 net.cpp:367] conv5_6/sep/scale -> conv5_6/sep (in-place)
I0625 08:50:03.194033 55699 layer_factory.hpp:77] Creating layer conv5_6/sep/scale
I0625 08:50:03.194113 55699 net.cpp:122] Setting up conv5_6/sep/scale
I0625 08:50:03.194161 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.194185 55699 net.cpp:137] Memory required for data: 103810048
I0625 08:50:03.194200 55699 layer_factory.hpp:77] Creating layer relu5_6/sep
I0625 08:50:03.194252 55699 net.cpp:84] Creating Layer relu5_6/sep
I0625 08:50:03.194273 55699 net.cpp:406] relu5_6/sep <- conv5_6/sep
I0625 08:50:03.194286 55699 net.cpp:367] relu5_6/sep -> conv5_6/sep (in-place)
I0625 08:50:03.194301 55699 net.cpp:122] Setting up relu5_6/sep
I0625 08:50:03.194314 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.194321 55699 net.cpp:137] Memory required for data: 104072192
I0625 08:50:03.194329 55699 layer_factory.hpp:77] Creating layer conv6/dw
I0625 08:50:03.194346 55699 net.cpp:84] Creating Layer conv6/dw
I0625 08:50:03.194355 55699 net.cpp:406] conv6/dw <- conv5_6/sep
I0625 08:50:03.194367 55699 net.cpp:380] conv6/dw -> conv6/dw
I0625 08:50:03.194937 55699 net.cpp:122] Setting up conv6/dw
I0625 08:50:03.194981 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.194993 55699 net.cpp:137] Memory required for data: 104334336
I0625 08:50:03.195052 55699 layer_factory.hpp:77] Creating layer conv6/dw/bn
I0625 08:50:03.195070 55699 net.cpp:84] Creating Layer conv6/dw/bn
I0625 08:50:03.195080 55699 net.cpp:406] conv6/dw/bn <- conv6/dw
I0625 08:50:03.195103 55699 net.cpp:367] conv6/dw/bn -> conv6/dw (in-place)
I0625 08:50:03.195152 55699 net.cpp:122] Setting up conv6/dw/bn
I0625 08:50:03.195168 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.195176 55699 net.cpp:137] Memory required for data: 104596480
I0625 08:50:03.195190 55699 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0625 08:50:03.195211 55699 net.cpp:84] Creating Layer conv6/dw/scale
I0625 08:50:03.195232 55699 net.cpp:406] conv6/dw/scale <- conv6/dw
I0625 08:50:03.195260 55699 net.cpp:367] conv6/dw/scale -> conv6/dw (in-place)
I0625 08:50:03.195330 55699 layer_factory.hpp:77] Creating layer conv6/dw/scale
I0625 08:50:03.195432 55699 net.cpp:122] Setting up conv6/dw/scale
I0625 08:50:03.195480 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.195525 55699 net.cpp:137] Memory required for data: 104858624
I0625 08:50:03.195566 55699 layer_factory.hpp:77] Creating layer relu6/dw
I0625 08:50:03.195607 55699 net.cpp:84] Creating Layer relu6/dw
I0625 08:50:03.195643 55699 net.cpp:406] relu6/dw <- conv6/dw
I0625 08:50:03.195667 55699 net.cpp:367] relu6/dw -> conv6/dw (in-place)
I0625 08:50:03.195684 55699 net.cpp:122] Setting up relu6/dw
I0625 08:50:03.195720 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.195753 55699 net.cpp:137] Memory required for data: 105120768
I0625 08:50:03.195772 55699 layer_factory.hpp:77] Creating layer conv6/sep
I0625 08:50:03.195801 55699 net.cpp:84] Creating Layer conv6/sep
I0625 08:50:03.195838 55699 net.cpp:406] conv6/sep <- conv6/dw
I0625 08:50:03.195880 55699 net.cpp:380] conv6/sep -> conv6/sep
I0625 08:50:03.269353 55699 net.cpp:122] Setting up conv6/sep
I0625 08:50:03.269484 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.269500 55699 net.cpp:137] Memory required for data: 105382912
I0625 08:50:03.269516 55699 layer_factory.hpp:77] Creating layer conv6/sep/bn
I0625 08:50:03.269556 55699 net.cpp:84] Creating Layer conv6/sep/bn
I0625 08:50:03.269598 55699 net.cpp:406] conv6/sep/bn <- conv6/sep
I0625 08:50:03.269644 55699 net.cpp:367] conv6/sep/bn -> conv6/sep (in-place)
I0625 08:50:03.269697 55699 net.cpp:122] Setting up conv6/sep/bn
I0625 08:50:03.269750 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.269764 55699 net.cpp:137] Memory required for data: 105645056
I0625 08:50:03.269805 55699 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0625 08:50:03.269851 55699 net.cpp:84] Creating Layer conv6/sep/scale
I0625 08:50:03.269889 55699 net.cpp:406] conv6/sep/scale <- conv6/sep
I0625 08:50:03.269942 55699 net.cpp:367] conv6/sep/scale -> conv6/sep (in-place)
I0625 08:50:03.270022 55699 layer_factory.hpp:77] Creating layer conv6/sep/scale
I0625 08:50:03.270099 55699 net.cpp:122] Setting up conv6/sep/scale
I0625 08:50:03.270155 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.270174 55699 net.cpp:137] Memory required for data: 105907200
I0625 08:50:03.270195 55699 layer_factory.hpp:77] Creating layer relu6/sep
I0625 08:50:03.270236 55699 net.cpp:84] Creating Layer relu6/sep
I0625 08:50:03.270273 55699 net.cpp:406] relu6/sep <- conv6/sep
I0625 08:50:03.270313 55699 net.cpp:367] relu6/sep -> conv6/sep (in-place)
I0625 08:50:03.270357 55699 net.cpp:122] Setting up relu6/sep
I0625 08:50:03.270398 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.270432 55699 net.cpp:137] Memory required for data: 106169344
I0625 08:50:03.270467 55699 layer_factory.hpp:77] Creating layer pool6
I0625 08:50:03.270493 55699 net.cpp:84] Creating Layer pool6
I0625 08:50:03.270526 55699 net.cpp:406] pool6 <- conv6/sep
I0625 08:50:03.270546 55699 net.cpp:380] pool6 -> pool6
I0625 08:50:03.270578 55699 net.cpp:122] Setting up pool6
I0625 08:50:03.270612 55699 net.cpp:129] Top shape: 64 1024 1 1 (65536)
I0625 08:50:03.270651 55699 net.cpp:137] Memory required for data: 106431488
I0625 08:50:03.270689 55699 layer_factory.hpp:77] Creating layer cifarfc7
I0625 08:50:03.270761 55699 net.cpp:84] Creating Layer cifarfc7
I0625 08:50:03.270819 55699 net.cpp:406] cifarfc7 <- pool6
I0625 08:50:03.270844 55699 net.cpp:380] cifarfc7 -> cifarfc7
I0625 08:50:03.271407 55699 net.cpp:122] Setting up cifarfc7
I0625 08:50:03.271471 55699 net.cpp:129] Top shape: 64 10 1 1 (640)
I0625 08:50:03.271492 55699 net.cpp:137] Memory required for data: 106434048
I0625 08:50:03.271507 55699 layer_factory.hpp:77] Creating layer cifarfc7_cifarfc7_0_split
I0625 08:50:03.271548 55699 net.cpp:84] Creating Layer cifarfc7_cifarfc7_0_split
I0625 08:50:03.271585 55699 net.cpp:406] cifarfc7_cifarfc7_0_split <- cifarfc7
I0625 08:50:03.271621 55699 net.cpp:380] cifarfc7_cifarfc7_0_split -> cifarfc7_cifarfc7_0_split_0
I0625 08:50:03.271682 55699 net.cpp:380] cifarfc7_cifarfc7_0_split -> cifarfc7_cifarfc7_0_split_1
I0625 08:50:03.271736 55699 net.cpp:380] cifarfc7_cifarfc7_0_split -> cifarfc7_cifarfc7_0_split_2
I0625 08:50:03.271786 55699 net.cpp:122] Setting up cifarfc7_cifarfc7_0_split
I0625 08:50:03.271809 55699 net.cpp:129] Top shape: 64 10 1 1 (640)
I0625 08:50:03.271826 55699 net.cpp:129] Top shape: 64 10 1 1 (640)
I0625 08:50:03.271837 55699 net.cpp:129] Top shape: 64 10 1 1 (640)
I0625 08:50:03.271847 55699 net.cpp:137] Memory required for data: 106441728
I0625 08:50:03.271862 55699 layer_factory.hpp:77] Creating layer loss
I0625 08:50:03.271921 55699 net.cpp:84] Creating Layer loss
I0625 08:50:03.271966 55699 net.cpp:406] loss <- cifarfc7_cifarfc7_0_split_0
I0625 08:50:03.272009 55699 net.cpp:406] loss <- label_data_1_split_0
I0625 08:50:03.272049 55699 net.cpp:380] loss -> loss
I0625 08:50:03.272097 55699 layer_factory.hpp:77] Creating layer loss
I0625 08:50:03.272168 55699 net.cpp:122] Setting up loss
I0625 08:50:03.272213 55699 net.cpp:129] Top shape: (1)
I0625 08:50:03.272279 55699 net.cpp:132]     with loss weight 1
I0625 08:50:03.272313 55699 net.cpp:137] Memory required for data: 106441732
I0625 08:50:03.272323 55699 layer_factory.hpp:77] Creating layer top1/acc
I0625 08:50:03.272400 55699 net.cpp:84] Creating Layer top1/acc
I0625 08:50:03.272445 55699 net.cpp:406] top1/acc <- cifarfc7_cifarfc7_0_split_1
I0625 08:50:03.272469 55699 net.cpp:406] top1/acc <- label_data_1_split_1
I0625 08:50:03.272483 55699 net.cpp:380] top1/acc -> top1/acc
I0625 08:50:03.272539 55699 net.cpp:122] Setting up top1/acc
I0625 08:50:03.272584 55699 net.cpp:129] Top shape: (1)
I0625 08:50:03.272619 55699 net.cpp:137] Memory required for data: 106441736
I0625 08:50:03.272634 55699 layer_factory.hpp:77] Creating layer top5/acc
I0625 08:50:03.272681 55699 net.cpp:84] Creating Layer top5/acc
I0625 08:50:03.272719 55699 net.cpp:406] top5/acc <- cifarfc7_cifarfc7_0_split_2
I0625 08:50:03.272734 55699 net.cpp:406] top5/acc <- label_data_1_split_2
I0625 08:50:03.272748 55699 net.cpp:380] top5/acc -> top5/acc
I0625 08:50:03.272763 55699 net.cpp:122] Setting up top5/acc
I0625 08:50:03.272801 55699 net.cpp:129] Top shape: (1)
I0625 08:50:03.272820 55699 net.cpp:137] Memory required for data: 106441740
I0625 08:50:03.272830 55699 net.cpp:200] top5/acc does not need backward computation.
I0625 08:50:03.272845 55699 net.cpp:200] top1/acc does not need backward computation.
I0625 08:50:03.272855 55699 net.cpp:198] loss needs backward computation.
I0625 08:50:03.272869 55699 net.cpp:198] cifarfc7_cifarfc7_0_split needs backward computation.
I0625 08:50:03.272879 55699 net.cpp:198] cifarfc7 needs backward computation.
I0625 08:50:03.272889 55699 net.cpp:198] pool6 needs backward computation.
I0625 08:50:03.272904 55699 net.cpp:198] relu6/sep needs backward computation.
I0625 08:50:03.272912 55699 net.cpp:198] conv6/sep/scale needs backward computation.
I0625 08:50:03.272927 55699 net.cpp:198] conv6/sep/bn needs backward computation.
I0625 08:50:03.272934 55699 net.cpp:198] conv6/sep needs backward computation.
I0625 08:50:03.272969 55699 net.cpp:198] relu6/dw needs backward computation.
I0625 08:50:03.272985 55699 net.cpp:198] conv6/dw/scale needs backward computation.
I0625 08:50:03.272995 55699 net.cpp:198] conv6/dw/bn needs backward computation.
I0625 08:50:03.273010 55699 net.cpp:198] conv6/dw needs backward computation.
I0625 08:50:03.273020 55699 net.cpp:198] relu5_6/sep needs backward computation.
I0625 08:50:03.273052 55699 net.cpp:198] conv5_6/sep/scale needs backward computation.
I0625 08:50:03.273085 55699 net.cpp:198] conv5_6/sep/bn needs backward computation.
I0625 08:50:03.273098 55699 net.cpp:198] conv5_6/sep needs backward computation.
I0625 08:50:03.273108 55699 net.cpp:198] relu5_6/dw needs backward computation.
I0625 08:50:03.273123 55699 net.cpp:198] conv5_6/dw/scale needs backward computation.
I0625 08:50:03.273131 55699 net.cpp:198] conv5_6/dw/bn needs backward computation.
I0625 08:50:03.273141 55699 net.cpp:198] conv5_6/dw needs backward computation.
I0625 08:50:03.273152 55699 net.cpp:198] relu5_5/sep needs backward computation.
I0625 08:50:03.273166 55699 net.cpp:198] conv5_5/sep/scale needs backward computation.
I0625 08:50:03.273175 55699 net.cpp:198] conv5_5/sep/bn needs backward computation.
I0625 08:50:03.273185 55699 net.cpp:198] conv5_5/sep needs backward computation.
I0625 08:50:03.273200 55699 net.cpp:198] relu5_5/dw needs backward computation.
I0625 08:50:03.273208 55699 net.cpp:198] conv5_5/dw/scale needs backward computation.
I0625 08:50:03.273222 55699 net.cpp:198] conv5_5/dw/bn needs backward computation.
I0625 08:50:03.273231 55699 net.cpp:198] conv5_5/dw needs backward computation.
I0625 08:50:03.273263 55699 net.cpp:198] relu5_4/sep needs backward computation.
I0625 08:50:03.273283 55699 net.cpp:198] conv5_4/sep/scale needs backward computation.
I0625 08:50:03.273291 55699 net.cpp:198] conv5_4/sep/bn needs backward computation.
I0625 08:50:03.273301 55699 net.cpp:198] conv5_4/sep needs backward computation.
I0625 08:50:03.273315 55699 net.cpp:198] relu5_4/dw needs backward computation.
I0625 08:50:03.273376 55699 net.cpp:198] conv5_4/dw/scale needs backward computation.
I0625 08:50:03.273414 55699 net.cpp:198] conv5_4/dw/bn needs backward computation.
I0625 08:50:03.273433 55699 net.cpp:198] conv5_4/dw needs backward computation.
I0625 08:50:03.273443 55699 net.cpp:198] relu5_3/sep needs backward computation.
I0625 08:50:03.273454 55699 net.cpp:198] conv5_3/sep/scale needs backward computation.
I0625 08:50:03.273468 55699 net.cpp:198] conv5_3/sep/bn needs backward computation.
I0625 08:50:03.273476 55699 net.cpp:198] conv5_3/sep needs backward computation.
I0625 08:50:03.273488 55699 net.cpp:198] relu5_3/dw needs backward computation.
I0625 08:50:03.273501 55699 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0625 08:50:03.273510 55699 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0625 08:50:03.273524 55699 net.cpp:198] conv5_3/dw needs backward computation.
I0625 08:50:03.273532 55699 net.cpp:198] relu5_2/sep needs backward computation.
I0625 08:50:03.273543 55699 net.cpp:198] conv5_2/sep/scale needs backward computation.
I0625 08:50:03.273556 55699 net.cpp:198] conv5_2/sep/bn needs backward computation.
I0625 08:50:03.273566 55699 net.cpp:198] conv5_2/sep needs backward computation.
I0625 08:50:03.273579 55699 net.cpp:198] relu5_2/dw needs backward computation.
I0625 08:50:03.273588 55699 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0625 08:50:03.273598 55699 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0625 08:50:03.273612 55699 net.cpp:198] conv5_2/dw needs backward computation.
I0625 08:50:03.273669 55699 net.cpp:198] relu5_1/sep needs backward computation.
I0625 08:50:03.273715 55699 net.cpp:198] conv5_1/sep/scale needs backward computation.
I0625 08:50:03.273730 55699 net.cpp:198] conv5_1/sep/bn needs backward computation.
I0625 08:50:03.273746 55699 net.cpp:198] conv5_1/sep needs backward computation.
I0625 08:50:03.273756 55699 net.cpp:198] relu5_1/dw needs backward computation.
I0625 08:50:03.273789 55699 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0625 08:50:03.273808 55699 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0625 08:50:03.273816 55699 net.cpp:198] conv5_1/dw needs backward computation.
I0625 08:50:03.273828 55699 net.cpp:198] relu4_2/sep needs backward computation.
I0625 08:50:03.273859 55699 net.cpp:198] conv4_2/sep/scale needs backward computation.
I0625 08:50:03.273877 55699 net.cpp:198] conv4_2/sep/bn needs backward computation.
I0625 08:50:03.273886 55699 net.cpp:198] conv4_2/sep needs backward computation.
I0625 08:50:03.273897 55699 net.cpp:198] relu4_2/dw needs backward computation.
I0625 08:50:03.273912 55699 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0625 08:50:03.273921 55699 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0625 08:50:03.273934 55699 net.cpp:198] conv4_2/dw needs backward computation.
I0625 08:50:03.273943 55699 net.cpp:198] relu4_1/sep needs backward computation.
I0625 08:50:03.273954 55699 net.cpp:198] conv4_1/sep/scale needs backward computation.
I0625 08:50:03.273967 55699 net.cpp:198] conv4_1/sep/bn needs backward computation.
I0625 08:50:03.273977 55699 net.cpp:198] conv4_1/sep needs backward computation.
I0625 08:50:03.273986 55699 net.cpp:198] relu4_1/dw needs backward computation.
I0625 08:50:03.274000 55699 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0625 08:50:03.274009 55699 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0625 08:50:03.274022 55699 net.cpp:198] conv4_1/dw needs backward computation.
I0625 08:50:03.274031 55699 net.cpp:198] relu3_2/sep needs backward computation.
I0625 08:50:03.274042 55699 net.cpp:198] conv3_2/sep/scale needs backward computation.
I0625 08:50:03.274056 55699 net.cpp:198] conv3_2/sep/bn needs backward computation.
I0625 08:50:03.274065 55699 net.cpp:198] conv3_2/sep needs backward computation.
I0625 08:50:03.274075 55699 net.cpp:198] relu3_2/dw needs backward computation.
I0625 08:50:03.274091 55699 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0625 08:50:03.274181 55699 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0625 08:50:03.274219 55699 net.cpp:198] conv3_2/dw needs backward computation.
I0625 08:50:03.274240 55699 net.cpp:198] relu3_1/sep needs backward computation.
I0625 08:50:03.274250 55699 net.cpp:198] conv3_1/sep/scale needs backward computation.
I0625 08:50:03.274263 55699 net.cpp:198] conv3_1/sep/bn needs backward computation.
I0625 08:50:03.274272 55699 net.cpp:198] conv3_1/sep needs backward computation.
I0625 08:50:03.274283 55699 net.cpp:198] relu3_1/dw needs backward computation.
I0625 08:50:03.274297 55699 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0625 08:50:03.274307 55699 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0625 08:50:03.274320 55699 net.cpp:198] conv3_1/dw needs backward computation.
I0625 08:50:03.274330 55699 net.cpp:198] relu2_2/sep needs backward computation.
I0625 08:50:03.274344 55699 net.cpp:198] conv2_2/sep/scale needs backward computation.
I0625 08:50:03.274353 55699 net.cpp:198] conv2_2/sep/bn needs backward computation.
I0625 08:50:03.274363 55699 net.cpp:198] conv2_2/sep needs backward computation.
I0625 08:50:03.274377 55699 net.cpp:198] relu2_2/dw needs backward computation.
I0625 08:50:03.274386 55699 net.cpp:198] conv2_2/dw/scale needs backward computation.
I0625 08:50:03.274400 55699 net.cpp:198] conv2_2/dw/bn needs backward computation.
I0625 08:50:03.274410 55699 net.cpp:198] conv2_2/dw needs backward computation.
I0625 08:50:03.274420 55699 net.cpp:198] relu2_1/sep needs backward computation.
I0625 08:50:03.274435 55699 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0625 08:50:03.274443 55699 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0625 08:50:03.274457 55699 net.cpp:198] conv2_1/sep needs backward computation.
I0625 08:50:03.274466 55699 net.cpp:198] relu2_1/dw needs backward computation.
I0625 08:50:03.274477 55699 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0625 08:50:03.274490 55699 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0625 08:50:03.274499 55699 net.cpp:198] conv2_1/dw needs backward computation.
I0625 08:50:03.274510 55699 net.cpp:198] relu1 needs backward computation.
I0625 08:50:03.274524 55699 net.cpp:198] conv1/scale needs backward computation.
I0625 08:50:03.274533 55699 net.cpp:198] conv1/bn needs backward computation.
I0625 08:50:03.274546 55699 net.cpp:198] conv1 needs backward computation.
I0625 08:50:03.274557 55699 net.cpp:200] label_data_1_split does not need backward computation.
I0625 08:50:03.274572 55699 net.cpp:200] data does not need backward computation.
I0625 08:50:03.274581 55699 net.cpp:242] This network produces output loss
I0625 08:50:03.274592 55699 net.cpp:242] This network produces output top1/acc
I0625 08:50:03.274641 55699 net.cpp:242] This network produces output top5/acc
I0625 08:50:03.274746 55699 net.cpp:255] Network initialization done.
I0625 08:50:03.275341 55699 solver.cpp:56] Solver scaffolding done.
I0625 08:50:03.275779 55699 caffe.cpp:155] Finetuning from model/pretrain_mobilenetv1_ImageNet.caffemodel
I0625 08:50:03.369635 55699 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: model/pretrain_mobilenetv1_ImageNet.caffemodel
I0625 08:50:03.369738 55699 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0625 08:50:03.369763 55699 net.cpp:744] Ignoring source layer label_data_1_split
I0625 08:50:03.375737 55699 net.cpp:744] Ignoring source layer fc7
I0625 08:50:03.375820 55699 net.cpp:744] Ignoring source layer fc7_fc7_0_split
I0625 08:50:03.375834 55699 net.cpp:744] Ignoring source layer top1/acc
I0625 08:50:03.375843 55699 net.cpp:744] Ignoring source layer top5/acc
I0625 08:50:03.432042 55699 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: model/pretrain_mobilenetv1_ImageNet.caffemodel
I0625 08:50:03.432142 55699 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0625 08:50:03.437511 55699 net.cpp:744] Ignoring source layer fc7
I0625 08:50:03.437647 55699 net.cpp:744] Ignoring source layer fc7_fc7_0_split
I0625 08:50:03.438838 55699 caffe.cpp:248] Starting Optimization
I0625 08:50:03.438920 55699 solver.cpp:272] Solving MOBILENET
I0625 08:50:03.438935 55699 solver.cpp:273] Learning Rate Policy: step
I0625 08:50:03.446864 55699 solver.cpp:330] Iteration 0, Testing net (#0)
I0625 08:51:33.213769 55699 solver.cpp:397]     Test net output #0: loss = 2.96707 (* 1 = 2.96707 loss)
I0625 08:51:33.213987 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.120312
I0625 08:51:33.214041 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.308437
I0625 08:51:35.936079 55699 solver.cpp:218] Iteration 0 (-1.38685e-40 iter/s, 92.497s/50 iters), loss = 3.04761
I0625 08:51:35.936218 55699 solver.cpp:237]     Train net output #0: loss = 3.04761 (* 1 = 3.04761 loss)
I0625 08:51:35.936250 55699 sgd_solver.cpp:105] Iteration 0, lr = 0.0001
I0625 08:53:35.270906 55699 solver.cpp:218] Iteration 50 (0.418992 iter/s, 119.334s/50 iters), loss = 1.93916
I0625 08:53:35.271195 55699 solver.cpp:237]     Train net output #0: loss = 1.93916 (* 1 = 1.93916 loss)
I0625 08:53:35.271253 55699 sgd_solver.cpp:105] Iteration 50, lr = 0.0001
I0625 08:55:33.003502 55699 solver.cpp:330] Iteration 100, Testing net (#0)
I0625 08:56:20.562011 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 08:57:02.205605 55699 solver.cpp:397]     Test net output #0: loss = 1.95905 (* 1 = 1.95905 loss)
I0625 08:57:02.205802 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.2675
I0625 08:57:02.205826 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.599531
I0625 08:57:04.539855 55699 solver.cpp:218] Iteration 100 (0.238928 iter/s, 209.268s/50 iters), loss = 2.03323
I0625 08:57:04.539966 55699 solver.cpp:237]     Train net output #0: loss = 2.03323 (* 1 = 2.03323 loss)
I0625 08:57:04.539989 55699 sgd_solver.cpp:105] Iteration 100, lr = 0.0001
I0625 08:59:04.580709 55699 solver.cpp:218] Iteration 150 (0.416528 iter/s, 120.04s/50 iters), loss = 1.81332
I0625 08:59:04.580994 55699 solver.cpp:237]     Train net output #0: loss = 1.81332 (* 1 = 1.81332 loss)
I0625 08:59:04.581050 55699 sgd_solver.cpp:105] Iteration 150, lr = 0.0001
I0625 09:00:56.521293 55699 solver.cpp:330] Iteration 200, Testing net (#0)
I0625 09:02:22.610339 55699 solver.cpp:397]     Test net output #0: loss = 1.80438 (* 1 = 1.80438 loss)
I0625 09:02:22.610548 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.314375
I0625 09:02:22.610601 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.676562
I0625 09:02:24.874440 55699 solver.cpp:218] Iteration 200 (0.249634 iter/s, 200.293s/50 iters), loss = 1.83181
I0625 09:02:24.874999 55699 solver.cpp:237]     Train net output #0: loss = 1.83181 (* 1 = 1.83181 loss)
I0625 09:02:24.875212 55699 sgd_solver.cpp:105] Iteration 200, lr = 0.0001
I0625 09:04:19.588325 55699 solver.cpp:218] Iteration 250 (0.43587 iter/s, 114.713s/50 iters), loss = 1.65347
I0625 09:04:19.588598 55699 solver.cpp:237]     Train net output #0: loss = 1.65347 (* 1 = 1.65347 loss)
I0625 09:04:19.588652 55699 sgd_solver.cpp:105] Iteration 250, lr = 0.0001
I0625 09:06:12.250990 55699 solver.cpp:330] Iteration 300, Testing net (#0)
I0625 09:06:19.984246 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 09:07:39.012082 55699 solver.cpp:397]     Test net output #0: loss = 1.69318 (* 1 = 1.69318 loss)
I0625 09:07:39.012362 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.358594
I0625 09:07:39.012421 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.729219
I0625 09:07:41.328565 55699 solver.cpp:218] Iteration 300 (0.247845 iter/s, 201.739s/50 iters), loss = 1.70784
I0625 09:07:41.328667 55699 solver.cpp:237]     Train net output #0: loss = 1.70784 (* 1 = 1.70784 loss)
I0625 09:07:41.328719 55699 sgd_solver.cpp:105] Iteration 300, lr = 0.0001
I0625 09:09:38.181926 55699 solver.cpp:218] Iteration 350 (0.427888 iter/s, 116.853s/50 iters), loss = 1.72848
I0625 09:09:38.182251 55699 solver.cpp:237]     Train net output #0: loss = 1.72848 (* 1 = 1.72848 loss)
I0625 09:09:38.182304 55699 sgd_solver.cpp:105] Iteration 350, lr = 0.0001
I0625 09:11:31.433707 55699 solver.cpp:330] Iteration 400, Testing net (#0)
I0625 09:12:27.539898 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 09:12:57.637226 55699 solver.cpp:397]     Test net output #0: loss = 1.59711 (* 1 = 1.59711 loss)
I0625 09:12:57.637356 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.41125
I0625 09:12:57.637379 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.757344
I0625 09:12:59.935921 55699 solver.cpp:218] Iteration 400 (0.247828 iter/s, 201.753s/50 iters), loss = 1.62274
I0625 09:12:59.936030 55699 solver.cpp:237]     Train net output #0: loss = 1.62274 (* 1 = 1.62274 loss)
I0625 09:12:59.936051 55699 sgd_solver.cpp:105] Iteration 400, lr = 0.0001
I0625 09:14:54.914001 55699 solver.cpp:218] Iteration 450 (0.43487 iter/s, 114.977s/50 iters), loss = 1.41327
I0625 09:14:54.914278 55699 solver.cpp:237]     Train net output #0: loss = 1.41327 (* 1 = 1.41327 loss)
I0625 09:14:54.914331 55699 sgd_solver.cpp:105] Iteration 450, lr = 0.0001
I0625 09:16:47.324041 55699 solver.cpp:330] Iteration 500, Testing net (#0)
I0625 09:18:13.491271 55699 solver.cpp:397]     Test net output #0: loss = 1.54851 (* 1 = 1.54851 loss)
I0625 09:18:13.491518 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.417031
I0625 09:18:13.491574 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.783437
I0625 09:18:15.759590 55699 solver.cpp:218] Iteration 500 (0.248948 iter/s, 200.845s/50 iters), loss = 1.66162
I0625 09:18:15.759723 55699 solver.cpp:237]     Train net output #0: loss = 1.66162 (* 1 = 1.66162 loss)
I0625 09:18:15.759758 55699 sgd_solver.cpp:105] Iteration 500, lr = 0.0001
I0625 09:20:10.590186 55699 solver.cpp:218] Iteration 550 (0.435426 iter/s, 114.83s/50 iters), loss = 1.37841
I0625 09:20:10.590456 55699 solver.cpp:237]     Train net output #0: loss = 1.37841 (* 1 = 1.37841 loss)
I0625 09:20:10.590513 55699 sgd_solver.cpp:105] Iteration 550, lr = 0.0001
I0625 09:22:03.264895 55699 solver.cpp:330] Iteration 600, Testing net (#0)
I0625 09:22:21.376832 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 09:23:29.633149 55699 solver.cpp:397]     Test net output #0: loss = 1.49981 (* 1 = 1.49981 loss)
I0625 09:23:29.633384 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.440313
I0625 09:23:29.633414 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.784531
I0625 09:23:31.938968 55699 solver.cpp:218] Iteration 600 (0.248326 iter/s, 201.348s/50 iters), loss = 1.59069
I0625 09:23:31.939087 55699 solver.cpp:237]     Train net output #0: loss = 1.59069 (* 1 = 1.59069 loss)
I0625 09:23:31.939141 55699 sgd_solver.cpp:105] Iteration 600, lr = 0.0001
I0625 09:25:27.386329 55699 solver.cpp:218] Iteration 650 (0.433099 iter/s, 115.447s/50 iters), loss = 1.46902
I0625 09:25:27.386595 55699 solver.cpp:237]     Train net output #0: loss = 1.46902 (* 1 = 1.46902 loss)
I0625 09:25:27.386626 55699 sgd_solver.cpp:105] Iteration 650, lr = 0.0001
I0625 09:27:21.391614 55699 solver.cpp:330] Iteration 700, Testing net (#0)
I0625 09:28:29.898447 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 09:28:49.696087 55699 solver.cpp:397]     Test net output #0: loss = 1.4455 (* 1 = 1.4455 loss)
I0625 09:28:49.696182 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.475937
I0625 09:28:49.696229 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.799219
I0625 09:28:51.996580 55699 solver.cpp:218] Iteration 700 (0.244369 iter/s, 204.609s/50 iters), loss = 1.604
I0625 09:28:51.996723 55699 solver.cpp:237]     Train net output #0: loss = 1.604 (* 1 = 1.604 loss)
I0625 09:28:51.996752 55699 sgd_solver.cpp:105] Iteration 700, lr = 0.0001
I0625 09:30:49.433118 55699 solver.cpp:218] Iteration 750 (0.425764 iter/s, 117.436s/50 iters), loss = 1.77688
I0625 09:30:49.433568 55699 solver.cpp:237]     Train net output #0: loss = 1.77688 (* 1 = 1.77688 loss)
I0625 09:30:49.433624 55699 sgd_solver.cpp:105] Iteration 750, lr = 0.0001
I0625 09:31:54.275216 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0625 09:32:46.683495 55699 solver.cpp:330] Iteration 800, Testing net (#0)
I0625 09:34:13.201048 55699 solver.cpp:397]     Test net output #0: loss = 1.4962 (* 1 = 1.4962 loss)
I0625 09:34:13.201184 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.45625
I0625 09:34:13.201207 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.789375
I0625 09:34:15.516046 55699 solver.cpp:218] Iteration 800 (0.242622 iter/s, 206.082s/50 iters), loss = 1.40184
I0625 09:34:15.516162 55699 solver.cpp:237]     Train net output #0: loss = 1.40184 (* 1 = 1.40184 loss)
I0625 09:34:15.516183 55699 sgd_solver.cpp:105] Iteration 800, lr = 0.0001
I0625 09:36:11.452155 55699 solver.cpp:218] Iteration 850 (0.431276 iter/s, 115.935s/50 iters), loss = 1.30124
I0625 09:36:11.452435 55699 solver.cpp:237]     Train net output #0: loss = 1.30124 (* 1 = 1.30124 loss)
I0625 09:36:11.452466 55699 sgd_solver.cpp:105] Iteration 850, lr = 0.0001
I0625 09:38:04.701946 55699 solver.cpp:330] Iteration 900, Testing net (#0)
I0625 09:38:34.071101 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 09:39:31.329169 55699 solver.cpp:397]     Test net output #0: loss = 1.44026 (* 1 = 1.44026 loss)
I0625 09:39:31.329416 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.476719
I0625 09:39:31.329470 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.810781
I0625 09:39:33.676391 55699 solver.cpp:218] Iteration 900 (0.247252 iter/s, 202.223s/50 iters), loss = 1.43028
I0625 09:39:33.676499 55699 solver.cpp:237]     Train net output #0: loss = 1.43028 (* 1 = 1.43028 loss)
I0625 09:39:33.676520 55699 sgd_solver.cpp:105] Iteration 900, lr = 0.0001
I0625 09:41:29.658215 55699 solver.cpp:218] Iteration 950 (0.431105 iter/s, 115.981s/50 iters), loss = 1.24801
I0625 09:41:29.658463 55699 solver.cpp:237]     Train net output #0: loss = 1.24801 (* 1 = 1.24801 loss)
I0625 09:41:29.658495 55699 sgd_solver.cpp:105] Iteration 950, lr = 0.0001
I0625 09:43:23.641957 55699 solver.cpp:330] Iteration 1000, Testing net (#0)
I0625 09:44:41.468489 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 09:44:50.186841 55699 solver.cpp:397]     Test net output #0: loss = 1.36382 (* 1 = 1.36382 loss)
I0625 09:44:50.186941 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.509375
I0625 09:44:50.186985 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.825312
I0625 09:44:52.462769 55699 solver.cpp:218] Iteration 1000 (0.246543 iter/s, 202.804s/50 iters), loss = 1.38301
I0625 09:44:52.462898 55699 solver.cpp:237]     Train net output #0: loss = 1.38301 (* 1 = 1.38301 loss)
I0625 09:44:52.462958 55699 sgd_solver.cpp:105] Iteration 1000, lr = 0.0001
I0625 09:46:48.675185 55699 solver.cpp:218] Iteration 1050 (0.430248 iter/s, 116.212s/50 iters), loss = 1.31021
I0625 09:46:48.675465 55699 solver.cpp:237]     Train net output #0: loss = 1.31021 (* 1 = 1.31021 loss)
I0625 09:46:48.675524 55699 sgd_solver.cpp:105] Iteration 1050, lr = 0.0001
I0625 09:48:41.887195 55699 solver.cpp:330] Iteration 1100, Testing net (#0)
I0625 09:50:08.264353 55699 solver.cpp:397]     Test net output #0: loss = 1.34317 (* 1 = 1.34317 loss)
I0625 09:50:08.264513 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.517031
I0625 09:50:08.264536 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.835
I0625 09:50:10.556119 55699 solver.cpp:218] Iteration 1100 (0.247672 iter/s, 201.88s/50 iters), loss = 1.33657
I0625 09:50:10.556222 55699 solver.cpp:237]     Train net output #0: loss = 1.33657 (* 1 = 1.33657 loss)
I0625 09:50:10.556274 55699 sgd_solver.cpp:105] Iteration 1100, lr = 0.0001
I0625 09:52:06.201221 55699 solver.cpp:218] Iteration 1150 (0.432361 iter/s, 115.644s/50 iters), loss = 1.33484
I0625 09:52:06.201514 55699 solver.cpp:237]     Train net output #0: loss = 1.33484 (* 1 = 1.33484 loss)
I0625 09:52:06.201545 55699 sgd_solver.cpp:105] Iteration 1150, lr = 0.0001
I0625 09:53:59.519496 55699 solver.cpp:330] Iteration 1200, Testing net (#0)
I0625 09:54:39.223067 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 09:55:25.890779 55699 solver.cpp:397]     Test net output #0: loss = 1.34693 (* 1 = 1.34693 loss)
I0625 09:55:25.891077 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.512969
I0625 09:55:25.891113 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.835469
I0625 09:55:28.169456 55699 solver.cpp:218] Iteration 1200 (0.247565 iter/s, 201.967s/50 iters), loss = 1.31323
I0625 09:55:28.169569 55699 solver.cpp:237]     Train net output #0: loss = 1.31323 (* 1 = 1.31323 loss)
I0625 09:55:28.169618 55699 sgd_solver.cpp:105] Iteration 1200, lr = 0.0001
I0625 09:57:23.835558 55699 solver.cpp:218] Iteration 1250 (0.432283 iter/s, 115.665s/50 iters), loss = 1.30213
I0625 09:57:23.835796 55699 solver.cpp:237]     Train net output #0: loss = 1.30213 (* 1 = 1.30213 loss)
I0625 09:57:23.835850 55699 sgd_solver.cpp:105] Iteration 1250, lr = 0.0001
I0625 09:59:17.145417 55699 solver.cpp:330] Iteration 1300, Testing net (#0)
I0625 10:00:44.318106 55699 solver.cpp:397]     Test net output #0: loss = 1.30504 (* 1 = 1.30504 loss)
I0625 10:00:44.318341 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.529375
I0625 10:00:44.318393 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.833594
I0625 10:00:46.596210 55699 solver.cpp:218] Iteration 1300 (0.246597 iter/s, 202.76s/50 iters), loss = 1.36837
I0625 10:00:46.596318 55699 solver.cpp:237]     Train net output #0: loss = 1.36837 (* 1 = 1.36837 loss)
I0625 10:00:46.596369 55699 sgd_solver.cpp:105] Iteration 1300, lr = 0.0001
I0625 10:02:42.160272 55699 solver.cpp:218] Iteration 1350 (0.432664 iter/s, 115.563s/50 iters), loss = 1.61736
I0625 10:02:42.160542 55699 solver.cpp:237]     Train net output #0: loss = 1.61736 (* 1 = 1.61736 loss)
I0625 10:02:42.160596 55699 sgd_solver.cpp:105] Iteration 1350, lr = 0.0001
I0625 10:04:35.785431 55699 solver.cpp:330] Iteration 1400, Testing net (#0)
I0625 10:04:38.393030 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 10:06:02.527751 55699 solver.cpp:397]     Test net output #0: loss = 1.31638 (* 1 = 1.31638 loss)
I0625 10:06:02.527884 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.529844
I0625 10:06:02.527906 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.835781
I0625 10:06:04.805649 55699 solver.cpp:218] Iteration 1400 (0.246737 iter/s, 202.645s/50 iters), loss = 1.49635
I0625 10:06:04.805754 55699 solver.cpp:237]     Train net output #0: loss = 1.49635 (* 1 = 1.49635 loss)
I0625 10:06:04.805806 55699 sgd_solver.cpp:105] Iteration 1400, lr = 0.0001
I0625 10:08:00.098820 55699 solver.cpp:218] Iteration 1450 (0.433678 iter/s, 115.293s/50 iters), loss = 1.43747
I0625 10:08:00.099082 55699 solver.cpp:237]     Train net output #0: loss = 1.43747 (* 1 = 1.43747 loss)
I0625 10:08:00.099136 55699 sgd_solver.cpp:105] Iteration 1450, lr = 0.0001
I0625 10:09:52.932353 55699 solver.cpp:330] Iteration 1500, Testing net (#0)
I0625 10:10:44.029880 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 10:11:19.609925 55699 solver.cpp:397]     Test net output #0: loss = 1.33767 (* 1 = 1.33767 loss)
I0625 10:11:19.610164 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.51625
I0625 10:11:19.610219 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.84375
I0625 10:11:21.887418 55699 solver.cpp:218] Iteration 1500 (0.247785 iter/s, 201.788s/50 iters), loss = 1.04428
I0625 10:11:21.887538 55699 solver.cpp:237]     Train net output #0: loss = 1.04428 (* 1 = 1.04428 loss)
I0625 10:11:21.887594 55699 sgd_solver.cpp:105] Iteration 1500, lr = 0.0001
I0625 10:13:17.830420 55699 solver.cpp:218] Iteration 1550 (0.43125 iter/s, 115.942s/50 iters), loss = 1.09654
I0625 10:13:17.830684 55699 solver.cpp:237]     Train net output #0: loss = 1.09654 (* 1 = 1.09654 loss)
I0625 10:13:17.830739 55699 sgd_solver.cpp:105] Iteration 1550, lr = 0.0001
I0625 10:13:36.364730 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0625 10:15:11.390589 55699 solver.cpp:330] Iteration 1600, Testing net (#0)
I0625 10:16:37.954704 55699 solver.cpp:397]     Test net output #0: loss = 1.21981 (* 1 = 1.21981 loss)
I0625 10:16:37.954860 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.566094
I0625 10:16:37.954917 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.857813
I0625 10:16:40.237119 55699 solver.cpp:218] Iteration 1600 (0.247028 iter/s, 202.406s/50 iters), loss = 1.12803
I0625 10:16:40.237229 55699 solver.cpp:237]     Train net output #0: loss = 1.12803 (* 1 = 1.12803 loss)
I0625 10:16:40.237251 55699 sgd_solver.cpp:105] Iteration 1600, lr = 0.0001
I0625 10:18:36.093760 55699 solver.cpp:218] Iteration 1650 (0.43157 iter/s, 115.856s/50 iters), loss = 1.38044
I0625 10:18:36.094051 55699 solver.cpp:237]     Train net output #0: loss = 1.38044 (* 1 = 1.38044 loss)
I0625 10:18:36.094107 55699 sgd_solver.cpp:105] Iteration 1650, lr = 0.0001
I0625 10:20:29.382541 55699 solver.cpp:330] Iteration 1700, Testing net (#0)
I0625 10:20:42.345404 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 10:21:55.849573 55699 solver.cpp:397]     Test net output #0: loss = 1.26816 (* 1 = 1.26816 loss)
I0625 10:21:55.849810 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.554688
I0625 10:21:55.849866 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.84125
I0625 10:21:58.136468 55699 solver.cpp:218] Iteration 1700 (0.247473 iter/s, 202.042s/50 iters), loss = 1.02498
I0625 10:21:58.136575 55699 solver.cpp:237]     Train net output #0: loss = 1.02498 (* 1 = 1.02498 loss)
I0625 10:21:58.136631 55699 sgd_solver.cpp:105] Iteration 1700, lr = 0.0001
I0625 10:23:53.920163 55699 solver.cpp:218] Iteration 1750 (0.431842 iter/s, 115.783s/50 iters), loss = 1.27716
I0625 10:23:53.920449 55699 solver.cpp:237]     Train net output #0: loss = 1.27716 (* 1 = 1.27716 loss)
I0625 10:23:53.920506 55699 sgd_solver.cpp:105] Iteration 1750, lr = 0.0001
I0625 10:25:47.903992 55699 solver.cpp:330] Iteration 1800, Testing net (#0)
I0625 10:26:49.705754 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 10:27:14.725666 55699 solver.cpp:397]     Test net output #0: loss = 1.27552 (* 1 = 1.27552 loss)
I0625 10:27:14.725749 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.542188
I0625 10:27:14.725769 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.845156
I0625 10:27:17.000036 55699 solver.cpp:218] Iteration 1800 (0.24621 iter/s, 203.079s/50 iters), loss = 1.28256
I0625 10:27:17.000142 55699 solver.cpp:237]     Train net output #0: loss = 1.28256 (* 1 = 1.28256 loss)
I0625 10:27:17.000193 55699 sgd_solver.cpp:105] Iteration 1800, lr = 0.0001
I0625 10:29:12.522689 55699 solver.cpp:218] Iteration 1850 (0.432818 iter/s, 115.522s/50 iters), loss = 1.08265
I0625 10:29:12.522977 55699 solver.cpp:237]     Train net output #0: loss = 1.08265 (* 1 = 1.08265 loss)
I0625 10:29:12.523028 55699 sgd_solver.cpp:105] Iteration 1850, lr = 0.0001
I0625 10:31:05.629693 55699 solver.cpp:330] Iteration 1900, Testing net (#0)
I0625 10:32:31.942708 55699 solver.cpp:397]     Test net output #0: loss = 1.2171 (* 1 = 1.2171 loss)
I0625 10:32:31.942953 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.56125
I0625 10:32:31.943008 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.858281
I0625 10:32:34.229571 55699 solver.cpp:218] Iteration 1900 (0.247886 iter/s, 201.706s/50 iters), loss = 1.09555
I0625 10:32:34.229679 55699 solver.cpp:237]     Train net output #0: loss = 1.09555 (* 1 = 1.09555 loss)
I0625 10:32:34.229701 55699 sgd_solver.cpp:105] Iteration 1900, lr = 0.0001
I0625 10:34:29.597231 55699 solver.cpp:218] Iteration 1950 (0.433399 iter/s, 115.367s/50 iters), loss = 1.20675
I0625 10:34:29.597555 55699 solver.cpp:237]     Train net output #0: loss = 1.20675 (* 1 = 1.20675 loss)
I0625 10:34:29.597607 55699 sgd_solver.cpp:105] Iteration 1950, lr = 0.0001
I0625 10:36:22.575644 55699 solver.cpp:447] Snapshotting to binary proto file /home/sun/MobileNet-Caffe-master/cifar10/model/sun_mobilenet_iter_2000.caffemodel
I0625 10:36:22.662472 55699 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/sun/MobileNet-Caffe-master/cifar10/model/sun_mobilenet_iter_2000.solverstate
I0625 10:36:22.709869 55699 solver.cpp:330] Iteration 2000, Testing net (#0)
I0625 10:36:46.872992 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 18:55:28.542953 55699 solver.cpp:397]     Test net output #0: loss = 1.21284 (* 1 = 1.21284 loss)
I0625 18:55:28.543344 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.568438
I0625 18:55:28.543406 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.863125
I0625 18:55:30.865480 55699 solver.cpp:218] Iteration 2000 (0.00166327 iter/s, 30061.3s/50 iters), loss = 1.22436
I0625 18:55:30.865619 55699 solver.cpp:237]     Train net output #0: loss = 1.22436 (* 1 = 1.22436 loss)
I0625 18:55:30.865661 55699 sgd_solver.cpp:105] Iteration 2000, lr = 0.0001
I0625 18:57:26.834750 55699 solver.cpp:218] Iteration 2050 (0.43115 iter/s, 115.969s/50 iters), loss = 1.04003
I0625 18:57:26.835052 55699 solver.cpp:237]     Train net output #0: loss = 1.04003 (* 1 = 1.04003 loss)
I0625 18:57:26.835108 55699 sgd_solver.cpp:105] Iteration 2050, lr = 0.0001
I0625 18:59:19.649179 55699 solver.cpp:330] Iteration 2100, Testing net (#0)
I0625 19:00:32.214275 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 19:00:45.929957 55699 solver.cpp:397]     Test net output #0: loss = 1.22637 (* 1 = 1.22637 loss)
I0625 19:00:45.930032 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.565
I0625 19:00:45.930083 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.853125
I0625 19:00:48.185585 55699 solver.cpp:218] Iteration 2100 (0.248324 iter/s, 201.35s/50 iters), loss = 1.11598
I0625 19:00:48.185693 55699 solver.cpp:237]     Train net output #0: loss = 1.11598 (* 1 = 1.11598 loss)
I0625 19:00:48.185715 55699 sgd_solver.cpp:105] Iteration 2100, lr = 0.0001
I0625 19:02:42.130201 55699 solver.cpp:218] Iteration 2150 (0.438812 iter/s, 113.944s/50 iters), loss = 1.26691
I0625 19:02:42.130360 55699 solver.cpp:237]     Train net output #0: loss = 1.26691 (* 1 = 1.26691 loss)
I0625 19:02:42.130410 55699 sgd_solver.cpp:105] Iteration 2150, lr = 0.0001
I0625 19:04:33.852036 55699 solver.cpp:330] Iteration 2200, Testing net (#0)
I0625 19:05:59.678753 55699 solver.cpp:397]     Test net output #0: loss = 1.21726 (* 1 = 1.21726 loss)
I0625 19:05:59.678992 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.5775
I0625 19:05:59.679047 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.851406
I0625 19:06:01.939406 55699 solver.cpp:218] Iteration 2200 (0.250239 iter/s, 199.809s/50 iters), loss = 1.17099
I0625 19:06:01.939513 55699 solver.cpp:237]     Train net output #0: loss = 1.17099 (* 1 = 1.17099 loss)
I0625 19:06:01.939563 55699 sgd_solver.cpp:105] Iteration 2200, lr = 0.0001
I0625 19:07:56.085719 55699 solver.cpp:218] Iteration 2250 (0.438035 iter/s, 114.146s/50 iters), loss = 1.16574
I0625 19:07:56.085986 55699 solver.cpp:237]     Train net output #0: loss = 1.16574 (* 1 = 1.16574 loss)
I0625 19:07:56.086017 55699 sgd_solver.cpp:105] Iteration 2250, lr = 0.0001
I0625 19:09:47.757748 55699 solver.cpp:330] Iteration 2300, Testing net (#0)
I0625 19:10:22.150220 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 19:11:14.727015 55699 solver.cpp:397]     Test net output #0: loss = 1.21169 (* 1 = 1.21169 loss)
I0625 19:11:14.727233 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.563906
I0625 19:11:14.727282 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.864062
I0625 19:11:17.098577 55699 solver.cpp:218] Iteration 2300 (0.248741 iter/s, 201.012s/50 iters), loss = 0.993733
I0625 19:11:17.098683 55699 solver.cpp:237]     Train net output #0: loss = 0.993733 (* 1 = 0.993733 loss)
I0625 19:11:17.098709 55699 sgd_solver.cpp:105] Iteration 2300, lr = 0.0001
I0625 19:12:53.146720 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0625 19:13:20.336293 55699 solver.cpp:218] Iteration 2350 (0.405722 iter/s, 123.237s/50 iters), loss = 1.02823
I0625 19:13:20.336442 55699 solver.cpp:237]     Train net output #0: loss = 1.02823 (* 1 = 1.02823 loss)
I0625 19:13:20.336468 55699 sgd_solver.cpp:105] Iteration 2350, lr = 0.0001
I0625 19:15:21.916834 55699 solver.cpp:330] Iteration 2400, Testing net (#0)
I0625 19:16:48.637101 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 19:16:52.260217 55699 solver.cpp:397]     Test net output #0: loss = 1.20708 (* 1 = 1.20708 loss)
I0625 19:16:52.260299 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.572969
I0625 19:16:52.260324 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.859688
I0625 19:16:54.657513 55699 solver.cpp:218] Iteration 2400 (0.233295 iter/s, 214.321s/50 iters), loss = 1.32023
I0625 19:16:54.657629 55699 solver.cpp:237]     Train net output #0: loss = 1.32023 (* 1 = 1.32023 loss)
I0625 19:16:54.657683 55699 sgd_solver.cpp:105] Iteration 2400, lr = 0.0001
I0625 19:18:57.866220 55699 solver.cpp:218] Iteration 2450 (0.405818 iter/s, 123.208s/50 iters), loss = 1.35033
I0625 19:18:57.866439 55699 solver.cpp:237]     Train net output #0: loss = 1.35033 (* 1 = 1.35033 loss)
I0625 19:18:57.866463 55699 sgd_solver.cpp:105] Iteration 2450, lr = 0.0001
I0625 19:20:58.037645 55699 solver.cpp:330] Iteration 2500, Testing net (#0)
I0625 19:22:28.714041 55699 solver.cpp:397]     Test net output #0: loss = 1.14189 (* 1 = 1.14189 loss)
I0625 19:22:28.714277 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.599219
I0625 19:22:28.714313 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.875469
I0625 19:22:31.167291 55699 solver.cpp:218] Iteration 2500 (0.234412 iter/s, 213.3s/50 iters), loss = 1.02923
I0625 19:22:31.167516 55699 solver.cpp:237]     Train net output #0: loss = 1.02923 (* 1 = 1.02923 loss)
I0625 19:22:31.167629 55699 sgd_solver.cpp:105] Iteration 2500, lr = 0.0001
I0625 19:24:35.294800 55699 solver.cpp:218] Iteration 2550 (0.402813 iter/s, 124.127s/50 iters), loss = 1.01155
I0625 19:24:35.295212 55699 solver.cpp:237]     Train net output #0: loss = 1.01155 (* 1 = 1.01155 loss)
I0625 19:24:35.295353 55699 sgd_solver.cpp:105] Iteration 2550, lr = 0.0001
I0625 19:26:36.236946 55699 solver.cpp:330] Iteration 2600, Testing net (#0)
I0625 19:27:26.915524 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 19:28:09.531895 55699 solver.cpp:397]     Test net output #0: loss = 1.1291 (* 1 = 1.1291 loss)
I0625 19:28:09.532073 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.595312
I0625 19:28:09.532101 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.878594
I0625 19:28:11.985249 55699 solver.cpp:218] Iteration 2600 (0.230744 iter/s, 216.69s/50 iters), loss = 1.03083
I0625 19:28:11.985353 55699 solver.cpp:237]     Train net output #0: loss = 1.03083 (* 1 = 1.03083 loss)
I0625 19:28:11.985379 55699 sgd_solver.cpp:105] Iteration 2600, lr = 0.0001
I0625 19:30:14.090277 55699 solver.cpp:218] Iteration 2650 (0.409487 iter/s, 122.104s/50 iters), loss = 1.02101
I0625 19:30:14.090441 55699 solver.cpp:237]     Train net output #0: loss = 1.02101 (* 1 = 1.02101 loss)
I0625 19:30:14.090484 55699 sgd_solver.cpp:105] Iteration 2650, lr = 0.0001
I0625 19:32:14.566864 55699 solver.cpp:330] Iteration 2700, Testing net (#0)
I0625 19:33:44.835855 55699 solver.cpp:397]     Test net output #0: loss = 1.12135 (* 1 = 1.12135 loss)
I0625 19:33:44.836036 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.59875
I0625 19:33:44.836063 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.883125
I0625 19:33:47.220660 55699 solver.cpp:218] Iteration 2700 (0.234599 iter/s, 213.13s/50 iters), loss = 1.14433
I0625 19:33:47.220765 55699 solver.cpp:237]     Train net output #0: loss = 1.14433 (* 1 = 1.14433 loss)
I0625 19:33:47.220811 55699 sgd_solver.cpp:105] Iteration 2700, lr = 0.0001
I0625 19:35:49.851727 55699 solver.cpp:218] Iteration 2750 (0.407731 iter/s, 122.63s/50 iters), loss = 0.948561
I0625 19:35:49.852133 55699 solver.cpp:237]     Train net output #0: loss = 0.948561 (* 1 = 0.948561 loss)
I0625 19:35:49.852169 55699 sgd_solver.cpp:105] Iteration 2750, lr = 0.0001
I0625 19:37:50.100255 55699 solver.cpp:330] Iteration 2800, Testing net (#0)
I0625 19:37:58.308697 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 19:39:20.548928 55699 solver.cpp:397]     Test net output #0: loss = 1.12158 (* 1 = 1.12158 loss)
I0625 19:39:20.551540 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.603437
I0625 19:39:20.551569 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.8775
I0625 19:39:23.074542 55699 solver.cpp:218] Iteration 2800 (0.234497 iter/s, 213.222s/50 iters), loss = 1.0511
I0625 19:39:23.074661 55699 solver.cpp:237]     Train net output #0: loss = 1.0511 (* 1 = 1.0511 loss)
I0625 19:39:23.074692 55699 sgd_solver.cpp:105] Iteration 2800, lr = 0.0001
I0625 19:41:24.879976 55699 solver.cpp:218] Iteration 2850 (0.410492 iter/s, 121.805s/50 iters), loss = 0.95988
I0625 19:41:24.880244 55699 solver.cpp:237]     Train net output #0: loss = 0.95988 (* 1 = 0.95988 loss)
I0625 19:41:24.880273 55699 sgd_solver.cpp:105] Iteration 2850, lr = 0.0001
I0625 19:43:25.090976 55699 solver.cpp:330] Iteration 2900, Testing net (#0)
I0625 19:44:23.938064 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 19:44:55.482915 55699 solver.cpp:397]     Test net output #0: loss = 1.11293 (* 1 = 1.11293 loss)
I0625 19:44:55.487722 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.597812
I0625 19:44:55.487788 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.88
I0625 19:44:57.854468 55699 solver.cpp:218] Iteration 2900 (0.23477 iter/s, 212.974s/50 iters), loss = 1.09517
I0625 19:44:57.854723 55699 solver.cpp:237]     Train net output #0: loss = 1.09517 (* 1 = 1.09517 loss)
I0625 19:44:57.854794 55699 sgd_solver.cpp:105] Iteration 2900, lr = 0.0001
I0625 19:47:00.442816 55699 solver.cpp:218] Iteration 2950 (0.40787 iter/s, 122.588s/50 iters), loss = 0.848436
I0625 19:47:00.443042 55699 solver.cpp:237]     Train net output #0: loss = 0.848436 (* 1 = 0.848436 loss)
I0625 19:47:00.443068 55699 sgd_solver.cpp:105] Iteration 2950, lr = 0.0001
I0625 19:48:59.673624 55699 solver.cpp:330] Iteration 3000, Testing net (#0)
I0625 19:50:29.950871 55699 solver.cpp:397]     Test net output #0: loss = 1.09122 (* 1 = 1.09122 loss)
I0625 19:50:29.955101 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.607344
I0625 19:50:29.955128 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.886875
I0625 19:50:32.345608 55699 solver.cpp:218] Iteration 3000 (0.235958 iter/s, 211.902s/50 iters), loss = 1.01033
I0625 19:50:32.345708 55699 solver.cpp:237]     Train net output #0: loss = 1.01033 (* 1 = 1.01033 loss)
I0625 19:50:32.345733 55699 sgd_solver.cpp:105] Iteration 3000, lr = 0.0001
I0625 19:52:34.516549 55699 solver.cpp:218] Iteration 3050 (0.409266 iter/s, 122.17s/50 iters), loss = 1.17893
I0625 19:52:34.516791 55699 solver.cpp:237]     Train net output #0: loss = 1.17893 (* 1 = 1.17893 loss)
I0625 19:52:34.516814 55699 sgd_solver.cpp:105] Iteration 3050, lr = 0.0001
I0625 19:54:33.976351 55699 solver.cpp:330] Iteration 3100, Testing net (#0)
I0625 19:54:52.999775 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 19:56:04.066967 55699 solver.cpp:397]     Test net output #0: loss = 1.08149 (* 1 = 1.08149 loss)
I0625 19:56:04.067193 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.622031
I0625 19:56:04.067220 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.883125
I0625 19:56:06.666579 55699 solver.cpp:218] Iteration 3100 (0.235683 iter/s, 212.149s/50 iters), loss = 1.05726
I0625 19:56:06.666687 55699 solver.cpp:237]     Train net output #0: loss = 1.05726 (* 1 = 1.05726 loss)
I0625 19:56:06.666746 55699 sgd_solver.cpp:105] Iteration 3100, lr = 0.0001
I0625 19:56:55.601976 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0625 19:58:09.074618 55699 solver.cpp:218] Iteration 3150 (0.408473 iter/s, 122.407s/50 iters), loss = 1.03135
I0625 19:58:09.075076 55699 solver.cpp:237]     Train net output #0: loss = 1.03135 (* 1 = 1.03135 loss)
I0625 19:58:09.075106 55699 sgd_solver.cpp:105] Iteration 3150, lr = 0.0001
I0625 20:00:09.142757 55699 solver.cpp:330] Iteration 3200, Testing net (#0)
I0625 20:01:19.710186 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 20:01:39.416573 55699 solver.cpp:397]     Test net output #0: loss = 1.09489 (* 1 = 1.09489 loss)
I0625 20:01:39.416666 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.609062
I0625 20:01:39.416689 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.879062
I0625 20:01:41.814337 55699 solver.cpp:218] Iteration 3200 (0.23503 iter/s, 212.739s/50 iters), loss = 1.02083
I0625 20:01:41.814739 55699 solver.cpp:237]     Train net output #0: loss = 1.02083 (* 1 = 1.02083 loss)
I0625 20:01:41.814857 55699 sgd_solver.cpp:105] Iteration 3200, lr = 0.0001
I0625 20:03:43.539113 55699 solver.cpp:218] Iteration 3250 (0.410765 iter/s, 121.724s/50 iters), loss = 1.14374
I0625 20:03:43.543344 55699 solver.cpp:237]     Train net output #0: loss = 1.14374 (* 1 = 1.14374 loss)
I0625 20:03:43.543370 55699 sgd_solver.cpp:105] Iteration 3250, lr = 0.0001
I0625 20:05:44.433341 55699 solver.cpp:330] Iteration 3300, Testing net (#0)
I0625 20:07:15.037536 55699 solver.cpp:397]     Test net output #0: loss = 1.05823 (* 1 = 1.05823 loss)
I0625 20:07:15.037732 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.619219
I0625 20:07:15.037784 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.892969
I0625 20:07:17.441972 55699 solver.cpp:218] Iteration 3300 (0.233756 iter/s, 213.898s/50 iters), loss = 1.04825
I0625 20:07:17.442080 55699 solver.cpp:237]     Train net output #0: loss = 1.04825 (* 1 = 1.04825 loss)
I0625 20:07:17.442107 55699 sgd_solver.cpp:105] Iteration 3300, lr = 0.0001
I0625 20:09:19.878687 55699 solver.cpp:218] Iteration 3350 (0.408377 iter/s, 122.436s/50 iters), loss = 1.0414
I0625 20:09:19.879060 55699 solver.cpp:237]     Train net output #0: loss = 1.0414 (* 1 = 1.0414 loss)
I0625 20:09:19.879091 55699 sgd_solver.cpp:105] Iteration 3350, lr = 0.0001
I0625 20:11:19.140141 55699 solver.cpp:330] Iteration 3400, Testing net (#0)
I0625 20:11:49.408150 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 20:12:49.131356 55699 solver.cpp:397]     Test net output #0: loss = 1.04497 (* 1 = 1.04497 loss)
I0625 20:12:49.135180 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.624375
I0625 20:12:49.135236 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.89125
I0625 20:12:51.508153 55699 solver.cpp:218] Iteration 3400 (0.236263 iter/s, 211.629s/50 iters), loss = 0.817092
I0625 20:12:51.508270 55699 solver.cpp:237]     Train net output #0: loss = 0.817092 (* 1 = 0.817092 loss)
I0625 20:12:51.508296 55699 sgd_solver.cpp:105] Iteration 3400, lr = 0.0001
I0625 20:14:54.484207 55699 solver.cpp:218] Iteration 3450 (0.406587 iter/s, 122.975s/50 iters), loss = 0.831851
I0625 20:14:54.484385 55699 solver.cpp:237]     Train net output #0: loss = 0.831851 (* 1 = 0.831851 loss)
I0625 20:14:54.484411 55699 sgd_solver.cpp:105] Iteration 3450, lr = 0.0001
I0625 20:16:53.779418 55699 solver.cpp:330] Iteration 3500, Testing net (#0)
I0625 20:18:14.783128 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 20:18:23.822381 55699 solver.cpp:397]     Test net output #0: loss = 1.08475 (* 1 = 1.08475 loss)
I0625 20:18:23.822465 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.617969
I0625 20:18:23.822485 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.882344
I0625 20:18:26.218422 55699 solver.cpp:218] Iteration 3500 (0.236145 iter/s, 211.734s/50 iters), loss = 1.01208
I0625 20:18:26.218554 55699 solver.cpp:237]     Train net output #0: loss = 1.01208 (* 1 = 1.01208 loss)
I0625 20:18:26.218586 55699 sgd_solver.cpp:105] Iteration 3500, lr = 0.0001
I0625 20:20:28.802775 55699 solver.cpp:218] Iteration 3550 (0.407884 iter/s, 122.584s/50 iters), loss = 1.11785
I0625 20:20:28.803002 55699 solver.cpp:237]     Train net output #0: loss = 1.11785 (* 1 = 1.11785 loss)
I0625 20:20:28.803030 55699 sgd_solver.cpp:105] Iteration 3550, lr = 0.0001
I0625 20:22:28.872047 55699 solver.cpp:330] Iteration 3600, Testing net (#0)
I0625 20:23:58.774480 55699 solver.cpp:397]     Test net output #0: loss = 1.03357 (* 1 = 1.03357 loss)
I0625 20:23:58.774689 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.635312
I0625 20:23:58.774716 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.893125
I0625 20:24:01.158115 55699 solver.cpp:218] Iteration 3600 (0.235455 iter/s, 212.355s/50 iters), loss = 1.06057
I0625 20:24:01.158226 55699 solver.cpp:237]     Train net output #0: loss = 1.06057 (* 1 = 1.06057 loss)
I0625 20:24:01.158254 55699 sgd_solver.cpp:105] Iteration 3600, lr = 0.0001
I0625 20:26:03.283120 55699 solver.cpp:218] Iteration 3650 (0.40942 iter/s, 122.124s/50 iters), loss = 1.26474
I0625 20:26:03.283293 55699 solver.cpp:237]     Train net output #0: loss = 1.26474 (* 1 = 1.26474 loss)
I0625 20:26:03.283320 55699 sgd_solver.cpp:105] Iteration 3650, lr = 0.0001
I0625 20:28:02.558110 55699 solver.cpp:330] Iteration 3700, Testing net (#0)
I0625 20:28:44.156525 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 20:29:32.700512 55699 solver.cpp:397]     Test net output #0: loss = 1.10904 (* 1 = 1.10904 loss)
I0625 20:29:32.700733 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.607344
I0625 20:29:32.700762 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.877187
I0625 20:29:35.174230 55699 solver.cpp:218] Iteration 3700 (0.235971 iter/s, 211.89s/50 iters), loss = 0.995163
I0625 20:29:35.174338 55699 solver.cpp:237]     Train net output #0: loss = 0.995163 (* 1 = 0.995163 loss)
I0625 20:29:35.174365 55699 sgd_solver.cpp:105] Iteration 3700, lr = 0.0001
I0625 20:31:37.016719 55699 solver.cpp:218] Iteration 3750 (0.410368 iter/s, 121.842s/50 iters), loss = 0.797122
I0625 20:31:37.016960 55699 solver.cpp:237]     Train net output #0: loss = 0.797122 (* 1 = 0.797122 loss)
I0625 20:31:37.016990 55699 sgd_solver.cpp:105] Iteration 3750, lr = 0.0001
I0625 20:33:36.212890 55699 solver.cpp:330] Iteration 3800, Testing net (#0)
I0625 20:35:06.045922 55699 solver.cpp:397]     Test net output #0: loss = 1.05912 (* 1 = 1.05912 loss)
I0625 20:35:06.046087 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.619844
I0625 20:35:06.046114 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.892656
I0625 20:35:08.472985 55699 solver.cpp:218] Iteration 3800 (0.236456 iter/s, 211.456s/50 iters), loss = 1.0796
I0625 20:35:08.473243 55699 solver.cpp:237]     Train net output #0: loss = 1.0796 (* 1 = 1.0796 loss)
I0625 20:35:08.473304 55699 sgd_solver.cpp:105] Iteration 3800, lr = 0.0001
I0625 20:37:10.277773 55699 solver.cpp:218] Iteration 3850 (0.410496 iter/s, 121.804s/50 iters), loss = 0.963906
I0625 20:37:10.278049 55699 solver.cpp:237]     Train net output #0: loss = 0.963906 (* 1 = 0.963906 loss)
I0625 20:37:10.278226 55699 sgd_solver.cpp:105] Iteration 3850, lr = 0.0001
I0625 20:39:10.413959 55699 solver.cpp:330] Iteration 3900, Testing net (#0)
I0625 20:39:13.041896 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 20:40:39.929201 55699 solver.cpp:397]     Test net output #0: loss = 1.06017 (* 1 = 1.06017 loss)
I0625 20:40:39.929388 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.627031
I0625 20:40:39.929442 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.886719
I0625 20:40:42.332787 55699 solver.cpp:218] Iteration 3900 (0.235789 iter/s, 212.054s/50 iters), loss = 1.02506
I0625 20:40:42.332897 55699 solver.cpp:237]     Train net output #0: loss = 1.02506 (* 1 = 1.02506 loss)
I0625 20:40:42.332923 55699 sgd_solver.cpp:105] Iteration 3900, lr = 0.0001
I0625 20:40:47.331459 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0625 20:42:43.969614 55699 solver.cpp:218] Iteration 3950 (0.411063 iter/s, 121.636s/50 iters), loss = 0.946651
I0625 20:42:43.971660 55699 solver.cpp:237]     Train net output #0: loss = 0.946651 (* 1 = 0.946651 loss)
I0625 20:42:43.971801 55699 sgd_solver.cpp:105] Iteration 3950, lr = 0.0001
I0625 20:44:44.170384 55699 solver.cpp:447] Snapshotting to binary proto file /home/sun/MobileNet-Caffe-master/cifar10/model/sun_mobilenet_iter_4000.caffemodel
I0625 20:44:44.259841 55699 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/sun/MobileNet-Caffe-master/cifar10/model/sun_mobilenet_iter_4000.solverstate
I0625 20:44:44.324003 55699 solver.cpp:330] Iteration 4000, Testing net (#0)
I0625 20:45:37.399492 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 20:46:14.297174 55699 solver.cpp:397]     Test net output #0: loss = 1.03587 (* 1 = 1.03587 loss)
I0625 20:46:14.297340 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.629844
I0625 20:46:14.297369 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.893594
I0625 20:46:16.650213 55699 solver.cpp:218] Iteration 4000 (0.235097 iter/s, 212.678s/50 iters), loss = 0.811644
I0625 20:46:16.650329 55699 solver.cpp:237]     Train net output #0: loss = 0.811644 (* 1 = 0.811644 loss)
I0625 20:46:16.650357 55699 sgd_solver.cpp:105] Iteration 4000, lr = 0.0001
I0625 20:48:19.183037 55699 solver.cpp:218] Iteration 4050 (0.408057 iter/s, 122.532s/50 iters), loss = 1.1114
I0625 20:48:19.183313 55699 solver.cpp:237]     Train net output #0: loss = 1.1114 (* 1 = 1.1114 loss)
I0625 20:48:19.183349 55699 sgd_solver.cpp:105] Iteration 4050, lr = 0.0001
I0625 20:50:18.805178 55699 solver.cpp:330] Iteration 4100, Testing net (#0)
I0625 20:51:49.581082 55699 solver.cpp:397]     Test net output #0: loss = 1.02248 (* 1 = 1.02248 loss)
I0625 20:51:49.587390 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.638281
I0625 20:51:49.587465 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.895938
I0625 20:51:51.992143 55699 solver.cpp:218] Iteration 4100 (0.234954 iter/s, 212.808s/50 iters), loss = 0.826346
I0625 20:51:51.992290 55699 solver.cpp:237]     Train net output #0: loss = 0.826346 (* 1 = 0.826346 loss)
I0625 20:51:51.992331 55699 sgd_solver.cpp:105] Iteration 4100, lr = 0.0001
I0625 20:53:54.989533 55699 solver.cpp:218] Iteration 4150 (0.406514 iter/s, 122.997s/50 iters), loss = 0.985967
I0625 20:53:54.989790 55699 solver.cpp:237]     Train net output #0: loss = 0.985967 (* 1 = 0.985967 loss)
I0625 20:53:54.989814 55699 sgd_solver.cpp:105] Iteration 4150, lr = 0.0001
I0625 20:55:54.747982 55699 solver.cpp:330] Iteration 4200, Testing net (#0)
I0625 20:56:08.265925 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 20:57:24.615907 55699 solver.cpp:397]     Test net output #0: loss = 1.01462 (* 1 = 1.01462 loss)
I0625 20:57:24.619084 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.647344
I0625 20:57:24.619114 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.89625
I0625 20:57:27.148267 55699 solver.cpp:218] Iteration 4200 (0.235673 iter/s, 212.158s/50 iters), loss = 0.784037
I0625 20:57:27.148376 55699 solver.cpp:237]     Train net output #0: loss = 0.784037 (* 1 = 0.784037 loss)
I0625 20:57:27.148402 55699 sgd_solver.cpp:105] Iteration 4200, lr = 0.0001
I0625 20:59:29.473985 55699 solver.cpp:218] Iteration 4250 (0.408747 iter/s, 122.325s/50 iters), loss = 1.19575
I0625 20:59:29.474202 55699 solver.cpp:237]     Train net output #0: loss = 1.19575 (* 1 = 1.19575 loss)
I0625 20:59:29.474228 55699 sgd_solver.cpp:105] Iteration 4250, lr = 0.0001
I0625 21:01:29.485921 55699 solver.cpp:330] Iteration 4300, Testing net (#0)
I0625 21:02:33.741992 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 21:03:00.095605 55699 solver.cpp:397]     Test net output #0: loss = 1.02979 (* 1 = 1.02979 loss)
I0625 21:03:00.095691 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.629687
I0625 21:03:00.096674 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.895469
I0625 21:03:02.509018 55699 solver.cpp:218] Iteration 4300 (0.234704 iter/s, 213.034s/50 iters), loss = 1.19732
I0625 21:03:02.509133 55699 solver.cpp:237]     Train net output #0: loss = 1.19732 (* 1 = 1.19732 loss)
I0625 21:03:02.509308 55699 sgd_solver.cpp:105] Iteration 4300, lr = 0.0001
I0625 21:05:04.676540 55699 solver.cpp:218] Iteration 4350 (0.409276 iter/s, 122.167s/50 iters), loss = 1.08315
I0625 21:05:04.677000 55699 solver.cpp:237]     Train net output #0: loss = 1.08315 (* 1 = 1.08315 loss)
I0625 21:05:04.677029 55699 sgd_solver.cpp:105] Iteration 4350, lr = 0.0001
I0625 21:07:04.666764 55699 solver.cpp:330] Iteration 4400, Testing net (#0)
I0625 21:08:34.479460 55699 solver.cpp:397]     Test net output #0: loss = 1.07113 (* 1 = 1.07113 loss)
I0625 21:08:34.479640 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.623281
I0625 21:08:34.479665 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.883438
I0625 21:08:37.005239 55699 solver.cpp:218] Iteration 4400 (0.235485 iter/s, 212.328s/50 iters), loss = 0.984957
I0625 21:08:37.005344 55699 solver.cpp:237]     Train net output #0: loss = 0.984957 (* 1 = 0.984957 loss)
I0625 21:08:37.005373 55699 sgd_solver.cpp:105] Iteration 4400, lr = 0.0001
I0625 21:10:39.053179 55699 solver.cpp:218] Iteration 4450 (0.409678 iter/s, 122.047s/50 iters), loss = 0.827132
I0625 21:10:39.053391 55699 solver.cpp:237]     Train net output #0: loss = 0.827132 (* 1 = 0.827132 loss)
I0625 21:10:39.053419 55699 sgd_solver.cpp:105] Iteration 4450, lr = 0.0001
I0625 21:12:38.605049 55699 solver.cpp:330] Iteration 4500, Testing net (#0)
I0625 21:13:03.868484 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 21:14:08.651485 55699 solver.cpp:397]     Test net output #0: loss = 1.02612 (* 1 = 1.02612 loss)
I0625 21:14:08.651634 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.635312
I0625 21:14:08.651669 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.894687
I0625 21:14:11.058734 55699 solver.cpp:218] Iteration 4500 (0.235843 iter/s, 212.005s/50 iters), loss = 1.15543
I0625 21:14:11.059008 55699 solver.cpp:237]     Train net output #0: loss = 1.15543 (* 1 = 1.15543 loss)
I0625 21:14:11.059082 55699 sgd_solver.cpp:105] Iteration 4500, lr = 0.0001
I0625 21:16:15.946899 55699 solver.cpp:218] Iteration 4550 (0.400359 iter/s, 124.888s/50 iters), loss = 0.659467
I0625 21:16:15.947082 55699 solver.cpp:237]     Train net output #0: loss = 0.659467 (* 1 = 0.659467 loss)
I0625 21:16:15.947110 55699 sgd_solver.cpp:105] Iteration 4550, lr = 0.0001
I0625 21:18:17.604615 55699 solver.cpp:330] Iteration 4600, Testing net (#0)
I0625 21:19:32.274241 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 21:19:46.893828 55699 solver.cpp:397]     Test net output #0: loss = 1.07946 (* 1 = 1.07946 loss)
I0625 21:19:46.893926 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.625313
I0625 21:19:46.894102 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.877969
I0625 21:19:49.412168 55699 solver.cpp:218] Iteration 4600 (0.23423 iter/s, 213.465s/50 iters), loss = 0.996229
I0625 21:19:49.412292 55699 solver.cpp:237]     Train net output #0: loss = 0.996229 (* 1 = 0.996229 loss)
I0625 21:19:49.412325 55699 sgd_solver.cpp:105] Iteration 4600, lr = 0.0001
I0625 21:21:52.479008 55699 solver.cpp:218] Iteration 4650 (0.406286 iter/s, 123.066s/50 iters), loss = 0.878364
I0625 21:21:52.479506 55699 solver.cpp:237]     Train net output #0: loss = 0.878364 (* 1 = 0.878364 loss)
I0625 21:21:52.479531 55699 sgd_solver.cpp:105] Iteration 4650, lr = 0.0001
I0625 21:23:13.549548 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0625 21:23:52.859251 55699 solver.cpp:330] Iteration 4700, Testing net (#0)
I0625 21:25:22.931710 55699 solver.cpp:397]     Test net output #0: loss = 1.03111 (* 1 = 1.03111 loss)
I0625 21:25:22.931885 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.642187
I0625 21:25:22.931912 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.89375
I0625 21:25:25.424767 55699 solver.cpp:218] Iteration 4700 (0.234802 iter/s, 212.945s/50 iters), loss = 1.11288
I0625 21:25:25.424872 55699 solver.cpp:237]     Train net output #0: loss = 1.11288 (* 1 = 1.11288 loss)
I0625 21:25:25.424898 55699 sgd_solver.cpp:105] Iteration 4700, lr = 0.0001
I0625 21:27:27.805124 55699 solver.cpp:218] Iteration 4750 (0.408563 iter/s, 122.38s/50 iters), loss = 1.04711
I0625 21:27:27.805574 55699 solver.cpp:237]     Train net output #0: loss = 1.04711 (* 1 = 1.04711 loss)
I0625 21:27:27.805603 55699 sgd_solver.cpp:105] Iteration 4750, lr = 0.0001
I0625 21:29:27.406611 55699 solver.cpp:330] Iteration 4800, Testing net (#0)
I0625 21:30:03.751255 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 21:30:57.991047 55699 solver.cpp:397]     Test net output #0: loss = 1.00859 (* 1 = 1.00859 loss)
I0625 21:30:57.991255 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.644063
I0625 21:30:57.991281 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.897187
I0625 21:31:00.445825 55699 solver.cpp:218] Iteration 4800 (0.235139 iter/s, 212.64s/50 iters), loss = 0.934223
I0625 21:31:00.446056 55699 solver.cpp:237]     Train net output #0: loss = 0.934223 (* 1 = 0.934223 loss)
I0625 21:31:00.446167 55699 sgd_solver.cpp:105] Iteration 4800, lr = 0.0001
I0625 21:33:03.064028 55699 solver.cpp:218] Iteration 4850 (0.407774 iter/s, 122.617s/50 iters), loss = 1.10797
I0625 21:33:03.064184 55699 solver.cpp:237]     Train net output #0: loss = 1.10797 (* 1 = 1.10797 loss)
I0625 21:33:03.064231 55699 sgd_solver.cpp:105] Iteration 4850, lr = 0.0001
I0625 21:35:04.343425 55699 solver.cpp:330] Iteration 4900, Testing net (#0)
I0625 21:36:30.681761 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 21:36:34.353248 55699 solver.cpp:397]     Test net output #0: loss = 0.981603 (* 1 = 0.981603 loss)
I0625 21:36:34.353348 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.648281
I0625 21:36:34.353372 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.903906
I0625 21:36:36.745713 55699 solver.cpp:218] Iteration 4900 (0.233994 iter/s, 213.681s/50 iters), loss = 0.86572
I0625 21:36:36.745817 55699 solver.cpp:237]     Train net output #0: loss = 0.86572 (* 1 = 0.86572 loss)
I0625 21:36:36.745843 55699 sgd_solver.cpp:105] Iteration 4900, lr = 0.0001
I0625 21:38:39.043203 55699 solver.cpp:218] Iteration 4950 (0.408841 iter/s, 122.297s/50 iters), loss = 0.894515
I0625 21:38:39.043434 55699 solver.cpp:237]     Train net output #0: loss = 0.894515 (* 1 = 0.894515 loss)
I0625 21:38:39.043483 55699 sgd_solver.cpp:105] Iteration 4950, lr = 0.0001
I0625 21:40:39.126246 55699 solver.cpp:330] Iteration 5000, Testing net (#0)
I0625 21:42:09.381011 55699 solver.cpp:397]     Test net output #0: loss = 0.973822 (* 1 = 0.973822 loss)
I0625 21:42:09.381250 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.654375
I0625 21:42:09.381304 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.904531
I0625 21:42:11.836530 55699 solver.cpp:218] Iteration 5000 (0.23497 iter/s, 212.793s/50 iters), loss = 1.10414
I0625 21:42:11.836643 55699 solver.cpp:237]     Train net output #0: loss = 1.10414 (* 1 = 1.10414 loss)
I0625 21:42:11.836669 55699 sgd_solver.cpp:105] Iteration 5000, lr = 1e-05
I0625 21:44:14.884343 55699 solver.cpp:218] Iteration 5050 (0.406349 iter/s, 123.047s/50 iters), loss = 0.835911
I0625 21:44:14.884627 55699 solver.cpp:237]     Train net output #0: loss = 0.835911 (* 1 = 0.835911 loss)
I0625 21:44:14.884652 55699 sgd_solver.cpp:105] Iteration 5050, lr = 1e-05
I0625 21:46:17.031153 55699 solver.cpp:330] Iteration 5100, Testing net (#0)
I0625 21:47:04.853943 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 21:47:46.731902 55699 solver.cpp:397]     Test net output #0: loss = 0.965123 (* 1 = 0.965123 loss)
I0625 21:47:46.732115 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.660781
I0625 21:47:46.732143 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.902969
I0625 21:47:49.111135 55699 solver.cpp:218] Iteration 5100 (0.233398 iter/s, 214.226s/50 iters), loss = 0.927242
I0625 21:47:49.111255 55699 solver.cpp:237]     Train net output #0: loss = 0.927242 (* 1 = 0.927242 loss)
I0625 21:47:49.111282 55699 sgd_solver.cpp:105] Iteration 5100, lr = 1e-05
I0625 21:49:52.644901 55699 solver.cpp:218] Iteration 5150 (0.40475 iter/s, 123.533s/50 iters), loss = 0.965252
I0625 21:49:52.650863 55699 solver.cpp:237]     Train net output #0: loss = 0.965252 (* 1 = 0.965252 loss)
I0625 21:49:52.650905 55699 sgd_solver.cpp:105] Iteration 5150, lr = 1e-05
I0625 21:51:51.964572 55699 solver.cpp:330] Iteration 5200, Testing net (#0)
I0625 21:53:22.457162 55699 solver.cpp:397]     Test net output #0: loss = 0.937868 (* 1 = 0.937868 loss)
I0625 21:53:22.457355 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.667188
I0625 21:53:22.457382 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.914219
I0625 21:53:24.841168 55699 solver.cpp:218] Iteration 5200 (0.235638 iter/s, 212.19s/50 iters), loss = 1.24329
I0625 21:53:24.841279 55699 solver.cpp:237]     Train net output #0: loss = 1.24329 (* 1 = 1.24329 loss)
I0625 21:53:24.841305 55699 sgd_solver.cpp:105] Iteration 5200, lr = 1e-05
I0625 21:55:27.141530 55699 solver.cpp:218] Iteration 5250 (0.408831 iter/s, 122.3s/50 iters), loss = 0.765965
I0625 21:55:27.141739 55699 solver.cpp:237]     Train net output #0: loss = 0.765965 (* 1 = 0.765965 loss)
I0625 21:55:27.141765 55699 sgd_solver.cpp:105] Iteration 5250, lr = 1e-05
I0625 21:57:26.884984 55699 solver.cpp:330] Iteration 5300, Testing net (#0)
I0625 21:57:35.210371 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 21:58:56.869192 55699 solver.cpp:397]     Test net output #0: loss = 0.929177 (* 1 = 0.929177 loss)
I0625 21:58:56.869457 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.669688
I0625 21:58:56.869488 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.908281
I0625 21:58:59.224383 55699 solver.cpp:218] Iteration 5300 (0.235758 iter/s, 212.082s/50 iters), loss = 0.702973
I0625 21:58:59.224612 55699 solver.cpp:237]     Train net output #0: loss = 0.702973 (* 1 = 0.702973 loss)
I0625 21:58:59.224679 55699 sgd_solver.cpp:105] Iteration 5300, lr = 1e-05
I0625 22:01:01.448038 55699 solver.cpp:218] Iteration 5350 (0.409088 iter/s, 122.223s/50 iters), loss = 0.665312
I0625 22:01:01.448210 55699 solver.cpp:237]     Train net output #0: loss = 0.665312 (* 1 = 0.665312 loss)
I0625 22:01:01.448237 55699 sgd_solver.cpp:105] Iteration 5350, lr = 1e-05
I0625 22:03:01.055263 55699 solver.cpp:330] Iteration 5400, Testing net (#0)
I0625 22:03:59.581254 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 22:04:30.833911 55699 solver.cpp:397]     Test net output #0: loss = 0.946396 (* 1 = 0.946396 loss)
I0625 22:04:30.834075 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.666406
I0625 22:04:30.834102 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.909219
I0625 22:04:33.177417 55699 solver.cpp:218] Iteration 5400 (0.236151 iter/s, 211.729s/50 iters), loss = 0.785877
I0625 22:04:33.177522 55699 solver.cpp:237]     Train net output #0: loss = 0.785877 (* 1 = 0.785877 loss)
I0625 22:04:33.177585 55699 sgd_solver.cpp:105] Iteration 5400, lr = 1e-05
I0625 22:06:35.164582 55699 solver.cpp:218] Iteration 5450 (0.40988 iter/s, 121.987s/50 iters), loss = 0.690937
I0625 22:06:35.164796 55699 solver.cpp:237]     Train net output #0: loss = 0.690937 (* 1 = 0.690937 loss)
I0625 22:06:35.164831 55699 sgd_solver.cpp:105] Iteration 5450, lr = 1e-05
I0625 22:07:09.029175 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0625 22:08:33.835825 55699 solver.cpp:330] Iteration 5500, Testing net (#0)
I0625 22:10:04.015671 55699 solver.cpp:397]     Test net output #0: loss = 0.922168 (* 1 = 0.922168 loss)
I0625 22:10:04.015805 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.676875
I0625 22:10:04.015851 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.915937
I0625 22:10:06.437175 55699 solver.cpp:218] Iteration 5500 (0.236662 iter/s, 211.272s/50 iters), loss = 0.969458
I0625 22:10:06.437288 55699 solver.cpp:237]     Train net output #0: loss = 0.969458 (* 1 = 0.969458 loss)
I0625 22:10:06.437317 55699 sgd_solver.cpp:105] Iteration 5500, lr = 1e-05
I0625 22:12:07.824636 55699 solver.cpp:218] Iteration 5550 (0.411906 iter/s, 121.387s/50 iters), loss = 0.821128
I0625 22:12:07.825129 55699 solver.cpp:237]     Train net output #0: loss = 0.821128 (* 1 = 0.821128 loss)
I0625 22:12:07.825157 55699 sgd_solver.cpp:105] Iteration 5550, lr = 1e-05
I0625 22:14:08.034360 55699 solver.cpp:330] Iteration 5600, Testing net (#0)
I0625 22:14:26.981729 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 22:15:38.402600 55699 solver.cpp:397]     Test net output #0: loss = 0.923759 (* 1 = 0.923759 loss)
I0625 22:15:38.407541 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.673594
I0625 22:15:38.407655 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.908906
I0625 22:15:40.831034 55699 solver.cpp:218] Iteration 5600 (0.234736 iter/s, 213.005s/50 iters), loss = 0.633974
I0625 22:15:40.831133 55699 solver.cpp:237]     Train net output #0: loss = 0.633974 (* 1 = 0.633974 loss)
I0625 22:15:40.831159 55699 sgd_solver.cpp:105] Iteration 5600, lr = 1e-05
I0625 22:17:42.647871 55699 solver.cpp:218] Iteration 5650 (0.410455 iter/s, 121.816s/50 iters), loss = 0.768846
I0625 22:17:42.648089 55699 solver.cpp:237]     Train net output #0: loss = 0.768846 (* 1 = 0.768846 loss)
I0625 22:17:42.648113 55699 sgd_solver.cpp:105] Iteration 5650, lr = 1e-05
I0625 22:19:42.273576 55699 solver.cpp:330] Iteration 5700, Testing net (#0)
I0625 22:20:52.107784 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 22:21:11.875393 55699 solver.cpp:397]     Test net output #0: loss = 0.942581 (* 1 = 0.942581 loss)
I0625 22:21:11.875476 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.670313
I0625 22:21:11.875501 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.9125
I0625 22:21:14.237768 55699 solver.cpp:218] Iteration 5700 (0.236307 iter/s, 211.589s/50 iters), loss = 0.78358
I0625 22:21:14.237887 55699 solver.cpp:237]     Train net output #0: loss = 0.78358 (* 1 = 0.78358 loss)
I0625 22:21:14.237923 55699 sgd_solver.cpp:105] Iteration 5700, lr = 1e-05
I0625 22:23:16.391486 55699 solver.cpp:218] Iteration 5750 (0.409323 iter/s, 122.153s/50 iters), loss = 1.02562
I0625 22:23:16.391738 55699 solver.cpp:237]     Train net output #0: loss = 1.02562 (* 1 = 1.02562 loss)
I0625 22:23:16.391788 55699 sgd_solver.cpp:105] Iteration 5750, lr = 1e-05
I0625 22:25:16.179256 55699 solver.cpp:330] Iteration 5800, Testing net (#0)
I0625 22:26:46.259256 55699 solver.cpp:397]     Test net output #0: loss = 0.925813 (* 1 = 0.925813 loss)
I0625 22:26:46.263106 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.675625
I0625 22:26:46.263160 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.915625
I0625 22:26:48.627584 55699 solver.cpp:218] Iteration 5800 (0.235588 iter/s, 212.235s/50 iters), loss = 0.924115
I0625 22:26:48.627691 55699 solver.cpp:237]     Train net output #0: loss = 0.924115 (* 1 = 0.924115 loss)
I0625 22:26:48.627715 55699 sgd_solver.cpp:105] Iteration 5800, lr = 1e-05
I0625 22:28:50.314210 55699 solver.cpp:218] Iteration 5850 (0.410894 iter/s, 121.686s/50 iters), loss = 0.745913
I0625 22:28:50.314507 55699 solver.cpp:237]     Train net output #0: loss = 0.745913 (* 1 = 0.745913 loss)
I0625 22:28:50.314538 55699 sgd_solver.cpp:105] Iteration 5850, lr = 1e-05
I0625 22:30:49.419091 55699 solver.cpp:330] Iteration 5900, Testing net (#0)
I0625 22:31:20.205245 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 22:32:19.230958 55699 solver.cpp:397]     Test net output #0: loss = 0.941355 (* 1 = 0.941355 loss)
I0625 22:32:19.231115 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.67125
I0625 22:32:19.231144 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.908125
I0625 22:32:21.699718 55699 solver.cpp:218] Iteration 5900 (0.236535 iter/s, 211.385s/50 iters), loss = 0.653176
I0625 22:32:21.699825 55699 solver.cpp:237]     Train net output #0: loss = 0.653176 (* 1 = 0.653176 loss)
I0625 22:32:21.699851 55699 sgd_solver.cpp:105] Iteration 5900, lr = 1e-05
I0625 22:34:23.995039 55699 solver.cpp:218] Iteration 5950 (0.408847 iter/s, 122.295s/50 iters), loss = 0.844475
I0625 22:34:23.995478 55699 solver.cpp:237]     Train net output #0: loss = 0.844475 (* 1 = 0.844475 loss)
I0625 22:34:23.995528 55699 sgd_solver.cpp:105] Iteration 5950, lr = 1e-05
I0625 22:36:28.265385 55699 solver.cpp:447] Snapshotting to binary proto file /home/sun/MobileNet-Caffe-master/cifar10/model/sun_mobilenet_iter_6000.caffemodel
I0625 22:36:28.376467 55699 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/sun/MobileNet-Caffe-master/cifar10/model/sun_mobilenet_iter_6000.solverstate
I0625 22:36:28.437528 55699 solver.cpp:330] Iteration 6000, Testing net (#0)
I0625 22:37:54.076767 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 22:38:03.401427 55699 solver.cpp:397]     Test net output #0: loss = 0.938641 (* 1 = 0.938641 loss)
I0625 22:38:03.401510 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.660156
I0625 22:38:03.401535 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.914219
I0625 22:38:05.940547 55699 solver.cpp:218] Iteration 6000 (0.225281 iter/s, 221.945s/50 iters), loss = 1.00885
I0625 22:38:05.940656 55699 solver.cpp:237]     Train net output #0: loss = 1.00885 (* 1 = 1.00885 loss)
I0625 22:38:05.940683 55699 sgd_solver.cpp:105] Iteration 6000, lr = 1e-05
I0625 22:40:11.447758 55699 solver.cpp:218] Iteration 6050 (0.398384 iter/s, 125.507s/50 iters), loss = 0.9441
I0625 22:40:11.447930 55699 solver.cpp:237]     Train net output #0: loss = 0.9441 (* 1 = 0.9441 loss)
I0625 22:40:11.447957 55699 sgd_solver.cpp:105] Iteration 6050, lr = 1e-05
I0625 22:42:16.305866 55699 solver.cpp:330] Iteration 6100, Testing net (#0)
I0625 22:43:48.295035 55699 solver.cpp:397]     Test net output #0: loss = 0.928908 (* 1 = 0.928908 loss)
I0625 22:43:48.295282 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.670313
I0625 22:43:48.295310 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.911094
I0625 22:43:50.800925 55699 solver.cpp:218] Iteration 6100 (0.227944 iter/s, 219.352s/50 iters), loss = 0.981173
I0625 22:43:50.801040 55699 solver.cpp:237]     Train net output #0: loss = 0.981173 (* 1 = 0.981173 loss)
I0625 22:43:50.801089 55699 sgd_solver.cpp:105] Iteration 6100, lr = 1e-05
I0625 22:46:17.714254 55699 solver.cpp:218] Iteration 6150 (0.340337 iter/s, 146.913s/50 iters), loss = 0.722212
I0625 22:46:17.714509 55699 solver.cpp:237]     Train net output #0: loss = 0.722212 (* 1 = 0.722212 loss)
I0625 22:46:17.714551 55699 sgd_solver.cpp:105] Iteration 6150, lr = 1e-05
I0625 22:48:31.984135 55699 solver.cpp:330] Iteration 6200, Testing net (#0)
I0625 22:49:17.743105 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 22:50:11.218588 55699 solver.cpp:397]     Test net output #0: loss = 0.929358 (* 1 = 0.929358 loss)
I0625 22:50:11.218801 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.669844
I0625 22:50:11.218828 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.911875
I0625 22:50:13.652369 55699 solver.cpp:218] Iteration 6200 (0.211921 iter/s, 235.937s/50 iters), loss = 0.936861
I0625 22:50:13.652475 55699 solver.cpp:237]     Train net output #0: loss = 0.936861 (* 1 = 0.936861 loss)
I0625 22:50:13.652521 55699 sgd_solver.cpp:105] Iteration 6200, lr = 1e-05
I0625 22:52:07.402513 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0625 22:52:19.709237 55699 solver.cpp:218] Iteration 6250 (0.396649 iter/s, 126.056s/50 iters), loss = 0.957393
I0625 22:52:19.709347 55699 solver.cpp:237]     Train net output #0: loss = 0.957393 (* 1 = 0.957393 loss)
I0625 22:52:19.709372 55699 sgd_solver.cpp:105] Iteration 6250, lr = 1e-05
I0625 22:54:22.312817 55699 solver.cpp:330] Iteration 6300, Testing net (#0)
I0625 22:55:57.737421 55699 solver.cpp:397]     Test net output #0: loss = 0.933243 (* 1 = 0.933243 loss)
I0625 22:55:57.737572 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.670625
I0625 22:55:57.737599 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.912969
I0625 22:56:00.197620 55699 solver.cpp:218] Iteration 6300 (0.22677 iter/s, 220.488s/50 iters), loss = 0.760882
I0625 22:56:00.197708 55699 solver.cpp:237]     Train net output #0: loss = 0.760882 (* 1 = 0.760882 loss)
I0625 22:56:00.197728 55699 sgd_solver.cpp:105] Iteration 6300, lr = 1e-05
I0625 22:58:07.552539 55699 solver.cpp:218] Iteration 6350 (0.392606 iter/s, 127.354s/50 iters), loss = 0.860798
I0625 22:58:07.553009 55699 solver.cpp:237]     Train net output #0: loss = 0.860798 (* 1 = 0.860798 loss)
I0625 22:58:07.553058 55699 sgd_solver.cpp:105] Iteration 6350, lr = 1e-05
I0625 23:00:25.747018 55699 solver.cpp:330] Iteration 6400, Testing net (#0)
I0625 23:00:28.493759 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 23:01:56.057232 55699 solver.cpp:397]     Test net output #0: loss = 0.919758 (* 1 = 0.919758 loss)
I0625 23:01:56.057446 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.677813
I0625 23:01:56.057474 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.911875
I0625 23:01:58.431262 55699 solver.cpp:218] Iteration 6400 (0.216565 iter/s, 230.878s/50 iters), loss = 0.732403
I0625 23:01:58.431361 55699 solver.cpp:237]     Train net output #0: loss = 0.732403 (* 1 = 0.732403 loss)
I0625 23:01:58.431387 55699 sgd_solver.cpp:105] Iteration 6400, lr = 1e-05
I0625 23:04:01.701603 55699 solver.cpp:218] Iteration 6450 (0.405614 iter/s, 123.27s/50 iters), loss = 0.757461
I0625 23:04:01.701766 55699 solver.cpp:237]     Train net output #0: loss = 0.757461 (* 1 = 0.757461 loss)
I0625 23:04:01.701793 55699 sgd_solver.cpp:105] Iteration 6450, lr = 1e-05
I0625 23:06:03.328980 55699 solver.cpp:330] Iteration 6500, Testing net (#0)
I0625 23:06:57.502032 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 23:07:36.116468 55699 solver.cpp:397]     Test net output #0: loss = 0.936317 (* 1 = 0.936317 loss)
I0625 23:07:36.116659 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.668594
I0625 23:07:36.116686 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.913437
I0625 23:07:39.462179 55699 solver.cpp:218] Iteration 6500 (0.229611 iter/s, 217.76s/50 iters), loss = 0.848
I0625 23:07:39.462299 55699 solver.cpp:237]     Train net output #0: loss = 0.848 (* 1 = 0.848 loss)
I0625 23:07:39.462326 55699 sgd_solver.cpp:105] Iteration 6500, lr = 1e-05
I0625 23:09:53.553493 55699 solver.cpp:218] Iteration 6550 (0.372881 iter/s, 134.091s/50 iters), loss = 0.860962
I0625 23:09:53.553735 55699 solver.cpp:237]     Train net output #0: loss = 0.860962 (* 1 = 0.860962 loss)
I0625 23:09:53.553762 55699 sgd_solver.cpp:105] Iteration 6550, lr = 1e-05
I0625 23:12:01.883977 55699 solver.cpp:330] Iteration 6600, Testing net (#0)
I0625 23:13:35.670186 55699 solver.cpp:397]     Test net output #0: loss = 0.925671 (* 1 = 0.925671 loss)
I0625 23:13:35.670325 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.67375
I0625 23:13:35.670352 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.915156
I0625 23:13:38.189986 55699 solver.cpp:218] Iteration 6600 (0.222582 iter/s, 224.636s/50 iters), loss = 0.847391
I0625 23:13:38.190109 55699 solver.cpp:237]     Train net output #0: loss = 0.847391 (* 1 = 0.847391 loss)
I0625 23:13:38.190135 55699 sgd_solver.cpp:105] Iteration 6600, lr = 1e-05
I0625 23:15:45.657155 55699 solver.cpp:218] Iteration 6650 (0.392258 iter/s, 127.467s/50 iters), loss = 0.960411
I0625 23:15:45.657332 55699 solver.cpp:237]     Train net output #0: loss = 0.960411 (* 1 = 0.960411 loss)
I0625 23:15:45.657359 55699 sgd_solver.cpp:105] Iteration 6650, lr = 1e-05
I0625 23:17:52.647758 55699 solver.cpp:330] Iteration 6700, Testing net (#0)
I0625 23:18:07.049429 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 23:19:26.696107 55699 solver.cpp:397]     Test net output #0: loss = 0.914549 (* 1 = 0.914549 loss)
I0625 23:19:26.696295 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.678906
I0625 23:19:26.696323 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.911875
I0625 23:19:29.104066 55699 solver.cpp:218] Iteration 6700 (0.223768 iter/s, 223.446s/50 iters), loss = 0.691057
I0625 23:19:29.104310 55699 solver.cpp:237]     Train net output #0: loss = 0.691057 (* 1 = 0.691057 loss)
I0625 23:19:29.104423 55699 sgd_solver.cpp:105] Iteration 6700, lr = 1e-05
I0625 23:21:36.704519 55699 solver.cpp:218] Iteration 6750 (0.39185 iter/s, 127.6s/50 iters), loss = 1.04865
I0625 23:21:36.704918 55699 solver.cpp:237]     Train net output #0: loss = 1.04865 (* 1 = 1.04865 loss)
I0625 23:21:36.704941 55699 sgd_solver.cpp:105] Iteration 6750, lr = 1e-05
I0625 23:23:41.567833 55699 solver.cpp:330] Iteration 6800, Testing net (#0)
I0625 23:24:47.746306 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0625 23:25:14.355362 55699 solver.cpp:397]     Test net output #0: loss = 0.941435 (* 1 = 0.941435 loss)
I0625 23:25:14.355469 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.666562
I0625 23:25:14.355495 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.912656
I0625 23:25:16.816666 55699 solver.cpp:218] Iteration 6800 (0.227158 iter/s, 220.111s/50 iters), loss = 0.808445
I0625 23:25:16.816777 55699 solver.cpp:237]     Train net output #0: loss = 0.808445 (* 1 = 0.808445 loss)
I0625 23:25:16.816804 55699 sgd_solver.cpp:105] Iteration 6800, lr = 1e-05
I0625 23:27:21.136477 55699 solver.cpp:218] Iteration 6850 (0.402191 iter/s, 124.319s/50 iters), loss = 0.953453
I0625 23:27:21.136662 55699 solver.cpp:237]     Train net output #0: loss = 0.953453 (* 1 = 0.953453 loss)
I0625 23:27:21.136698 55699 sgd_solver.cpp:105] Iteration 6850, lr = 1e-05
I0625 23:29:21.079437 55699 solver.cpp:330] Iteration 6900, Testing net (#0)
I0626 07:09:13.581357 55699 solver.cpp:397]     Test net output #0: loss = 0.912667 (* 1 = 0.912667 loss)
I0626 07:09:13.581600 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.675156
I0626 07:09:13.581637 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.913281
I0626 07:09:15.982250 55699 solver.cpp:218] Iteration 6900 (0.00180409 iter/s, 27714.8s/50 iters), loss = 0.821843
I0626 07:09:15.982471 55699 solver.cpp:237]     Train net output #0: loss = 0.821843 (* 1 = 0.821843 loss)
I0626 07:09:15.982571 55699 sgd_solver.cpp:105] Iteration 6900, lr = 1e-05
I0626 07:11:19.591575 55699 solver.cpp:218] Iteration 6950 (0.404501 iter/s, 123.609s/50 iters), loss = 0.919011
I0626 07:11:19.591826 55699 solver.cpp:237]     Train net output #0: loss = 0.919011 (* 1 = 0.919011 loss)
I0626 07:11:19.591876 55699 sgd_solver.cpp:105] Iteration 6950, lr = 1e-05
I0626 07:13:19.315212 55699 solver.cpp:330] Iteration 7000, Testing net (#0)
I0626 07:13:44.225093 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 07:14:49.276657 55699 solver.cpp:397]     Test net output #0: loss = 0.929709 (* 1 = 0.929709 loss)
I0626 07:14:49.276810 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.67375
I0626 07:14:49.276842 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.912031
I0626 07:14:51.805989 55699 solver.cpp:218] Iteration 7000 (0.235611 iter/s, 212.214s/50 iters), loss = 1.20361
I0626 07:14:51.806092 55699 solver.cpp:237]     Train net output #0: loss = 1.20361 (* 1 = 1.20361 loss)
I0626 07:14:51.806118 55699 sgd_solver.cpp:105] Iteration 7000, lr = 1e-05
I0626 07:15:57.976400 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0626 07:16:54.484063 55699 solver.cpp:218] Iteration 7050 (0.407574 iter/s, 122.677s/50 iters), loss = 0.602477
I0626 07:16:54.487056 55699 solver.cpp:237]     Train net output #0: loss = 0.602477 (* 1 = 0.602477 loss)
I0626 07:16:54.487083 55699 sgd_solver.cpp:105] Iteration 7050, lr = 1e-05
I0626 07:18:54.344499 55699 solver.cpp:330] Iteration 7100, Testing net (#0)
I0626 07:20:10.017380 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 07:20:24.526903 55699 solver.cpp:397]     Test net output #0: loss = 0.924957 (* 1 = 0.924957 loss)
I0626 07:20:24.527000 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.675625
I0626 07:20:24.527025 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.912188
I0626 07:20:26.935647 55699 solver.cpp:218] Iteration 7100 (0.235352 iter/s, 212.448s/50 iters), loss = 0.806437
I0626 07:20:26.935756 55699 solver.cpp:237]     Train net output #0: loss = 0.806437 (* 1 = 0.806437 loss)
I0626 07:20:26.935792 55699 sgd_solver.cpp:105] Iteration 7100, lr = 1e-05
I0626 07:22:30.108166 55699 solver.cpp:218] Iteration 7150 (0.405936 iter/s, 123.172s/50 iters), loss = 0.924365
I0626 07:22:30.108656 55699 solver.cpp:237]     Train net output #0: loss = 0.924365 (* 1 = 0.924365 loss)
I0626 07:22:30.108685 55699 sgd_solver.cpp:105] Iteration 7150, lr = 1e-05
I0626 07:24:30.294060 55699 solver.cpp:330] Iteration 7200, Testing net (#0)
I0626 07:26:00.743175 55699 solver.cpp:397]     Test net output #0: loss = 0.928275 (* 1 = 0.928275 loss)
I0626 07:26:00.743333 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.673437
I0626 07:26:00.743366 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.914062
I0626 07:26:03.194816 55699 solver.cpp:218] Iteration 7200 (0.234647 iter/s, 213.086s/50 iters), loss = 0.948711
I0626 07:26:03.194917 55699 solver.cpp:237]     Train net output #0: loss = 0.948711 (* 1 = 0.948711 loss)
I0626 07:26:03.194943 55699 sgd_solver.cpp:105] Iteration 7200, lr = 1e-05
I0626 07:28:05.065389 55699 solver.cpp:218] Iteration 7250 (0.410273 iter/s, 121.87s/50 iters), loss = 0.882831
I0626 07:28:05.065557 55699 solver.cpp:237]     Train net output #0: loss = 0.882831 (* 1 = 0.882831 loss)
I0626 07:28:05.065584 55699 sgd_solver.cpp:105] Iteration 7250, lr = 1e-05
I0626 07:30:05.233793 55699 solver.cpp:330] Iteration 7300, Testing net (#0)
I0626 07:30:40.800232 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 07:31:34.853796 55699 solver.cpp:397]     Test net output #0: loss = 0.925518 (* 1 = 0.925518 loss)
I0626 07:31:34.854059 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.674531
I0626 07:31:34.854112 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.911094
I0626 07:31:37.300866 55699 solver.cpp:218] Iteration 7300 (0.235588 iter/s, 212.235s/50 iters), loss = 0.696166
I0626 07:31:37.300976 55699 solver.cpp:237]     Train net output #0: loss = 0.696166 (* 1 = 0.696166 loss)
I0626 07:31:37.301002 55699 sgd_solver.cpp:105] Iteration 7300, lr = 1e-05
I0626 07:33:38.800544 55699 solver.cpp:218] Iteration 7350 (0.411526 iter/s, 121.499s/50 iters), loss = 0.853326
I0626 07:33:38.800832 55699 solver.cpp:237]     Train net output #0: loss = 0.853326 (* 1 = 0.853326 loss)
I0626 07:33:38.800879 55699 sgd_solver.cpp:105] Iteration 7350, lr = 1e-05
I0626 07:35:38.494774 55699 solver.cpp:330] Iteration 7400, Testing net (#0)
I0626 07:37:04.949278 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 07:37:08.628978 55699 solver.cpp:397]     Test net output #0: loss = 0.917838 (* 1 = 0.917838 loss)
I0626 07:37:08.629077 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.676406
I0626 07:37:08.629108 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.91375
I0626 07:37:11.104144 55699 solver.cpp:218] Iteration 7400 (0.235512 iter/s, 212.303s/50 iters), loss = 0.827906
I0626 07:37:11.104251 55699 solver.cpp:237]     Train net output #0: loss = 0.827906 (* 1 = 0.827906 loss)
I0626 07:37:11.104276 55699 sgd_solver.cpp:105] Iteration 7400, lr = 1e-05
I0626 07:39:13.104964 55699 solver.cpp:218] Iteration 7450 (0.409836 iter/s, 122s/50 iters), loss = 0.885271
I0626 07:39:13.105201 55699 solver.cpp:237]     Train net output #0: loss = 0.885271 (* 1 = 0.885271 loss)
I0626 07:39:13.105228 55699 sgd_solver.cpp:105] Iteration 7450, lr = 1e-05
I0626 07:41:13.175138 55699 solver.cpp:330] Iteration 7500, Testing net (#0)
I0626 07:42:42.899425 55699 solver.cpp:397]     Test net output #0: loss = 0.910447 (* 1 = 0.910447 loss)
I0626 07:42:42.899612 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.682813
I0626 07:42:42.899638 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.91875
I0626 07:42:45.432346 55699 solver.cpp:218] Iteration 7500 (0.235486 iter/s, 212.327s/50 iters), loss = 0.970215
I0626 07:42:45.432449 55699 solver.cpp:237]     Train net output #0: loss = 0.970215 (* 1 = 0.970215 loss)
I0626 07:42:45.432474 55699 sgd_solver.cpp:105] Iteration 7500, lr = 1e-05
I0626 07:44:47.295197 55699 solver.cpp:218] Iteration 7550 (0.4103 iter/s, 121.862s/50 iters), loss = 0.788264
I0626 07:44:47.295644 55699 solver.cpp:237]     Train net output #0: loss = 0.788264 (* 1 = 0.788264 loss)
I0626 07:44:47.295672 55699 sgd_solver.cpp:105] Iteration 7550, lr = 1e-05
I0626 07:46:46.463937 55699 solver.cpp:330] Iteration 7600, Testing net (#0)
I0626 07:47:34.228274 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 07:48:16.384554 55699 solver.cpp:397]     Test net output #0: loss = 0.938829 (* 1 = 0.938829 loss)
I0626 07:48:16.384694 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.664375
I0626 07:48:16.384721 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.912656
I0626 07:48:18.756266 55699 solver.cpp:218] Iteration 7600 (0.236451 iter/s, 211.46s/50 iters), loss = 1.0887
I0626 07:48:18.756372 55699 solver.cpp:237]     Train net output #0: loss = 1.0887 (* 1 = 1.0887 loss)
I0626 07:48:18.756397 55699 sgd_solver.cpp:105] Iteration 7600, lr = 1e-05
I0626 07:50:20.943773 55699 solver.cpp:218] Iteration 7650 (0.409209 iter/s, 122.187s/50 iters), loss = 0.95994
I0626 07:50:20.944010 55699 solver.cpp:237]     Train net output #0: loss = 0.95994 (* 1 = 0.95994 loss)
I0626 07:50:20.944033 55699 sgd_solver.cpp:105] Iteration 7650, lr = 1e-05
I0626 07:52:19.955459 55699 solver.cpp:330] Iteration 7700, Testing net (#0)
I0626 07:53:49.814589 55699 solver.cpp:397]     Test net output #0: loss = 0.924983 (* 1 = 0.924983 loss)
I0626 07:53:49.814875 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.6775
I0626 07:53:49.814960 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.91125
I0626 07:53:52.260661 55699 solver.cpp:218] Iteration 7700 (0.236612 iter/s, 211.316s/50 iters), loss = 0.916175
I0626 07:53:52.260779 55699 solver.cpp:237]     Train net output #0: loss = 0.916175 (* 1 = 0.916175 loss)
I0626 07:53:52.260805 55699 sgd_solver.cpp:105] Iteration 7700, lr = 1e-05
I0626 07:55:53.568258 55699 solver.cpp:218] Iteration 7750 (0.412177 iter/s, 121.307s/50 iters), loss = 0.812931
I0626 07:55:53.568529 55699 solver.cpp:237]     Train net output #0: loss = 0.812931 (* 1 = 0.812931 loss)
I0626 07:55:53.568590 55699 sgd_solver.cpp:105] Iteration 7750, lr = 1e-05
I0626 07:57:52.762773 55699 solver.cpp:330] Iteration 7800, Testing net (#0)
I0626 07:58:00.867645 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 07:59:23.072052 55699 solver.cpp:397]     Test net output #0: loss = 0.923914 (* 1 = 0.923914 loss)
I0626 07:59:23.072185 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.670313
I0626 07:59:23.072211 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.916094
I0626 07:59:25.412955 55699 solver.cpp:218] Iteration 7800 (0.236023 iter/s, 211.844s/50 iters), loss = 0.724219
I0626 07:59:25.413070 55699 solver.cpp:237]     Train net output #0: loss = 0.724219 (* 1 = 0.724219 loss)
I0626 07:59:25.413096 55699 sgd_solver.cpp:105] Iteration 7800, lr = 1e-05
I0626 07:59:45.027243 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0626 08:01:27.211716 55699 solver.cpp:218] Iteration 7850 (0.410516 iter/s, 121.798s/50 iters), loss = 0.83966
I0626 08:01:27.211993 55699 solver.cpp:237]     Train net output #0: loss = 0.83966 (* 1 = 0.83966 loss)
I0626 08:01:27.212031 55699 sgd_solver.cpp:105] Iteration 7850, lr = 1e-05
I0626 08:03:27.479635 55699 solver.cpp:330] Iteration 7900, Testing net (#0)
I0626 08:04:26.055301 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 08:04:57.302170 55699 solver.cpp:397]     Test net output #0: loss = 0.921405 (* 1 = 0.921405 loss)
I0626 08:04:57.302371 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.669531
I0626 08:04:57.302402 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.915156
I0626 08:04:59.918457 55699 solver.cpp:218] Iteration 7900 (0.235066 iter/s, 212.706s/50 iters), loss = 0.96631
I0626 08:04:59.918582 55699 solver.cpp:237]     Train net output #0: loss = 0.96631 (* 1 = 0.96631 loss)
I0626 08:04:59.918608 55699 sgd_solver.cpp:105] Iteration 7900, lr = 1e-05
I0626 08:07:01.772990 55699 solver.cpp:218] Iteration 7950 (0.410327 iter/s, 121.854s/50 iters), loss = 0.710591
I0626 08:07:01.773427 55699 solver.cpp:237]     Train net output #0: loss = 0.710591 (* 1 = 0.710591 loss)
I0626 08:07:01.773450 55699 sgd_solver.cpp:105] Iteration 7950, lr = 1e-05
I0626 08:09:01.139088 55699 solver.cpp:447] Snapshotting to binary proto file /home/sun/MobileNet-Caffe-master/cifar10/model/sun_mobilenet_iter_8000.caffemodel
I0626 08:09:01.226064 55699 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/sun/MobileNet-Caffe-master/cifar10/model/sun_mobilenet_iter_8000.solverstate
I0626 08:09:01.279376 55699 solver.cpp:330] Iteration 8000, Testing net (#0)
I0626 08:10:31.245124 55699 solver.cpp:397]     Test net output #0: loss = 0.915263 (* 1 = 0.915263 loss)
I0626 08:10:31.245326 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.675
I0626 08:10:31.245352 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.915156
I0626 08:10:33.713989 55699 solver.cpp:218] Iteration 8000 (0.235916 iter/s, 211.94s/50 iters), loss = 0.847687
I0626 08:10:33.714222 55699 solver.cpp:237]     Train net output #0: loss = 0.847687 (* 1 = 0.847687 loss)
I0626 08:10:33.714334 55699 sgd_solver.cpp:105] Iteration 8000, lr = 1e-05
I0626 08:12:36.334373 55699 solver.cpp:218] Iteration 8050 (0.407764 iter/s, 122.62s/50 iters), loss = 0.992175
I0626 08:12:36.334614 55699 solver.cpp:237]     Train net output #0: loss = 0.992175 (* 1 = 0.992175 loss)
I0626 08:12:36.334645 55699 sgd_solver.cpp:105] Iteration 8050, lr = 1e-05
I0626 08:14:36.135823 55699 solver.cpp:330] Iteration 8100, Testing net (#0)
I0626 08:14:54.974192 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 08:16:05.815098 55699 solver.cpp:397]     Test net output #0: loss = 0.920122 (* 1 = 0.920122 loss)
I0626 08:16:05.815279 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.673125
I0626 08:16:05.815306 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.910156
I0626 08:16:08.265069 55699 solver.cpp:218] Iteration 8100 (0.235927 iter/s, 211.93s/50 iters), loss = 0.67991
I0626 08:16:08.265182 55699 solver.cpp:237]     Train net output #0: loss = 0.67991 (* 1 = 0.67991 loss)
I0626 08:16:08.265208 55699 sgd_solver.cpp:105] Iteration 8100, lr = 1e-05
I0626 08:18:09.834540 55699 solver.cpp:218] Iteration 8150 (0.411289 iter/s, 121.569s/50 iters), loss = 0.772843
I0626 08:18:09.834767 55699 solver.cpp:237]     Train net output #0: loss = 0.772843 (* 1 = 0.772843 loss)
I0626 08:18:09.834790 55699 sgd_solver.cpp:105] Iteration 8150, lr = 1e-05
I0626 08:20:10.486215 55699 solver.cpp:330] Iteration 8200, Testing net (#0)
I0626 08:21:20.959581 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 08:21:40.503790 55699 solver.cpp:397]     Test net output #0: loss = 0.913763 (* 1 = 0.913763 loss)
I0626 08:21:40.503873 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.673594
I0626 08:21:40.503896 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.916875
I0626 08:21:43.019244 55699 solver.cpp:218] Iteration 8200 (0.234539 iter/s, 213.184s/50 iters), loss = 0.982666
I0626 08:21:43.019352 55699 solver.cpp:237]     Train net output #0: loss = 0.982666 (* 1 = 0.982666 loss)
I0626 08:21:43.019377 55699 sgd_solver.cpp:105] Iteration 8200, lr = 1e-05
I0626 08:23:45.421857 55699 solver.cpp:218] Iteration 8250 (0.40849 iter/s, 122.402s/50 iters), loss = 0.780789
I0626 08:23:45.422031 55699 solver.cpp:237]     Train net output #0: loss = 0.780789 (* 1 = 0.780789 loss)
I0626 08:23:45.422080 55699 sgd_solver.cpp:105] Iteration 8250, lr = 1e-05
I0626 08:25:44.597584 55699 solver.cpp:330] Iteration 8300, Testing net (#0)
I0626 08:27:14.404074 55699 solver.cpp:397]     Test net output #0: loss = 0.911082 (* 1 = 0.911082 loss)
I0626 08:27:14.404273 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.681719
I0626 08:27:14.404297 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.919062
I0626 08:27:16.775365 55699 solver.cpp:218] Iteration 8300 (0.236571 iter/s, 211.353s/50 iters), loss = 0.665016
I0626 08:27:16.775470 55699 solver.cpp:237]     Train net output #0: loss = 0.665016 (* 1 = 0.665016 loss)
I0626 08:27:16.775647 55699 sgd_solver.cpp:105] Iteration 8300, lr = 1e-05
I0626 08:29:18.509341 55699 solver.cpp:218] Iteration 8350 (0.410735 iter/s, 121.733s/50 iters), loss = 0.94588
I0626 08:29:18.509758 55699 solver.cpp:237]     Train net output #0: loss = 0.94588 (* 1 = 0.94588 loss)
I0626 08:29:18.509785 55699 sgd_solver.cpp:105] Iteration 8350, lr = 1e-05
I0626 08:31:18.405979 55699 solver.cpp:330] Iteration 8400, Testing net (#0)
I0626 08:31:48.998850 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 08:32:48.899718 55699 solver.cpp:397]     Test net output #0: loss = 0.931324 (* 1 = 0.931324 loss)
I0626 08:32:48.903465 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.6725
I0626 08:32:48.903523 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.908125
I0626 08:32:51.436597 55699 solver.cpp:218] Iteration 8400 (0.234823 iter/s, 212.926s/50 iters), loss = 0.923621
I0626 08:32:51.436717 55699 solver.cpp:237]     Train net output #0: loss = 0.923621 (* 1 = 0.923621 loss)
I0626 08:32:51.436763 55699 sgd_solver.cpp:105] Iteration 8400, lr = 1e-05
I0626 08:34:53.306490 55699 solver.cpp:218] Iteration 8450 (0.410277 iter/s, 121.869s/50 iters), loss = 0.860931
I0626 08:34:53.306756 55699 solver.cpp:237]     Train net output #0: loss = 0.860931 (* 1 = 0.860931 loss)
I0626 08:34:53.306780 55699 sgd_solver.cpp:105] Iteration 8450, lr = 1e-05
I0626 08:36:53.124218 55699 solver.cpp:330] Iteration 8500, Testing net (#0)
I0626 08:38:13.957862 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 08:38:23.146729 55699 solver.cpp:397]     Test net output #0: loss = 0.912735 (* 1 = 0.912735 loss)
I0626 08:38:23.146858 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.674375
I0626 08:38:23.146890 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.914062
I0626 08:38:25.476835 55699 solver.cpp:218] Iteration 8500 (0.23566 iter/s, 212.17s/50 iters), loss = 0.844898
I0626 08:38:25.476941 55699 solver.cpp:237]     Train net output #0: loss = 0.844898 (* 1 = 0.844898 loss)
I0626 08:38:25.476989 55699 sgd_solver.cpp:105] Iteration 8500, lr = 1e-05
I0626 08:40:26.951936 55699 solver.cpp:218] Iteration 8550 (0.411611 iter/s, 121.474s/50 iters), loss = 0.813113
I0626 08:40:26.952147 55699 solver.cpp:237]     Train net output #0: loss = 0.813113 (* 1 = 0.813113 loss)
I0626 08:40:26.952170 55699 sgd_solver.cpp:105] Iteration 8550, lr = 1e-05
I0626 08:42:03.403419 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0626 08:42:28.774583 55699 solver.cpp:330] Iteration 8600, Testing net (#0)
I0626 08:44:05.314347 55699 solver.cpp:397]     Test net output #0: loss = 0.920058 (* 1 = 0.920058 loss)
I0626 08:44:05.314522 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.672188
I0626 08:44:05.314549 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.917188
I0626 08:44:08.110114 55699 solver.cpp:218] Iteration 8600 (0.226084 iter/s, 221.157s/50 iters), loss = 0.744574
I0626 08:44:08.110260 55699 solver.cpp:237]     Train net output #0: loss = 0.744574 (* 1 = 0.744574 loss)
I0626 08:44:08.110285 55699 sgd_solver.cpp:105] Iteration 8600, lr = 1e-05
I0626 08:46:17.971087 55699 solver.cpp:218] Iteration 8650 (0.38503 iter/s, 129.86s/50 iters), loss = 0.914439
I0626 08:46:17.971352 55699 solver.cpp:237]     Train net output #0: loss = 0.914439 (* 1 = 0.914439 loss)
I0626 08:46:17.971379 55699 sgd_solver.cpp:105] Iteration 8650, lr = 1e-05
I0626 08:48:27.702311 55699 solver.cpp:330] Iteration 8700, Testing net (#0)
I0626 08:49:11.840916 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 08:50:05.318262 55699 solver.cpp:397]     Test net output #0: loss = 0.908837 (* 1 = 0.908837 loss)
I0626 08:50:05.318470 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.678437
I0626 08:50:05.318496 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.916406
I0626 08:50:08.054194 55699 solver.cpp:218] Iteration 8700 (0.217314 iter/s, 230.082s/50 iters), loss = 1.00111
I0626 08:50:08.054337 55699 solver.cpp:237]     Train net output #0: loss = 1.00111 (* 1 = 1.00111 loss)
I0626 08:50:08.054364 55699 sgd_solver.cpp:105] Iteration 8700, lr = 1e-05
I0626 08:52:21.047375 55699 solver.cpp:218] Iteration 8750 (0.37596 iter/s, 132.993s/50 iters), loss = 0.718764
I0626 08:52:21.047885 55699 solver.cpp:237]     Train net output #0: loss = 0.718764 (* 1 = 0.718764 loss)
I0626 08:52:21.047917 55699 sgd_solver.cpp:105] Iteration 8750, lr = 1e-05
I0626 08:54:23.836776 55699 solver.cpp:330] Iteration 8800, Testing net (#0)
I0626 08:55:56.169490 55699 solver.cpp:397]     Test net output #0: loss = 0.917151 (* 1 = 0.917151 loss)
I0626 08:55:56.169657 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.67875
I0626 08:55:56.169683 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.913281
I0626 08:55:58.586576 55699 solver.cpp:218] Iteration 8800 (0.229845 iter/s, 217.538s/50 iters), loss = 0.740537
I0626 08:55:58.586802 55699 solver.cpp:237]     Train net output #0: loss = 0.740537 (* 1 = 0.740537 loss)
I0626 08:55:58.586864 55699 sgd_solver.cpp:105] Iteration 8800, lr = 1e-05
I0626 08:58:03.403167 55699 solver.cpp:218] Iteration 8850 (0.40059 iter/s, 124.816s/50 iters), loss = 0.833306
I0626 08:58:03.403352 55699 solver.cpp:237]     Train net output #0: loss = 0.833306 (* 1 = 0.833306 loss)
I0626 08:58:03.403380 55699 sgd_solver.cpp:105] Iteration 8850, lr = 1e-05
I0626 09:00:05.838596 55699 solver.cpp:330] Iteration 8900, Testing net (#0)
I0626 09:00:08.659991 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 09:01:37.622481 55699 solver.cpp:397]     Test net output #0: loss = 0.912637 (* 1 = 0.912637 loss)
I0626 09:01:37.622684 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.677031
I0626 09:01:37.622711 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.915313
I0626 09:01:40.060554 55699 solver.cpp:218] Iteration 8900 (0.23078 iter/s, 216.657s/50 iters), loss = 0.748378
I0626 09:01:40.060658 55699 solver.cpp:237]     Train net output #0: loss = 0.748378 (* 1 = 0.748378 loss)
I0626 09:01:40.060685 55699 sgd_solver.cpp:105] Iteration 8900, lr = 1e-05
I0626 09:03:45.526434 55699 solver.cpp:218] Iteration 8950 (0.398518 iter/s, 125.465s/50 iters), loss = 0.913093
I0626 09:03:45.526715 55699 solver.cpp:237]     Train net output #0: loss = 0.913093 (* 1 = 0.913093 loss)
I0626 09:03:45.526744 55699 sgd_solver.cpp:105] Iteration 8950, lr = 1e-05
I0626 09:05:49.500469 55699 solver.cpp:330] Iteration 9000, Testing net (#0)
I0626 09:06:43.755545 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 09:07:21.481849 55699 solver.cpp:397]     Test net output #0: loss = 0.922096 (* 1 = 0.922096 loss)
I0626 09:07:21.487529 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.672656
I0626 09:07:21.487591 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.912188
I0626 09:07:23.967092 55699 solver.cpp:218] Iteration 9000 (0.228896 iter/s, 218.44s/50 iters), loss = 0.805538
I0626 09:07:23.967202 55699 solver.cpp:237]     Train net output #0: loss = 0.805538 (* 1 = 0.805538 loss)
I0626 09:07:23.967228 55699 sgd_solver.cpp:105] Iteration 9000, lr = 1e-05
I0626 09:09:28.867554 55699 solver.cpp:218] Iteration 9050 (0.40032 iter/s, 124.9s/50 iters), loss = 0.693997
I0626 09:09:28.867722 55699 solver.cpp:237]     Train net output #0: loss = 0.693997 (* 1 = 0.693997 loss)
I0626 09:09:28.867749 55699 sgd_solver.cpp:105] Iteration 9050, lr = 1e-05
I0626 09:11:30.263280 55699 solver.cpp:330] Iteration 9100, Testing net (#0)
I0626 09:13:01.247315 55699 solver.cpp:397]     Test net output #0: loss = 0.915438 (* 1 = 0.915438 loss)
I0626 09:13:01.247503 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.677188
I0626 09:13:01.247530 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.914375
I0626 09:13:03.702843 55699 solver.cpp:218] Iteration 9100 (0.232737 iter/s, 214.835s/50 iters), loss = 0.842065
I0626 09:13:03.702950 55699 solver.cpp:237]     Train net output #0: loss = 0.842065 (* 1 = 0.842065 loss)
I0626 09:13:03.702989 55699 sgd_solver.cpp:105] Iteration 9100, lr = 1e-05
I0626 09:15:06.786286 55699 solver.cpp:218] Iteration 9150 (0.40623 iter/s, 123.083s/50 iters), loss = 0.839724
I0626 09:15:06.786681 55699 solver.cpp:237]     Train net output #0: loss = 0.839724 (* 1 = 0.839724 loss)
I0626 09:15:06.786705 55699 sgd_solver.cpp:105] Iteration 9150, lr = 1e-05
I0626 09:17:09.495941 55699 solver.cpp:330] Iteration 9200, Testing net (#0)
I0626 09:17:23.107075 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 09:18:40.854974 55699 solver.cpp:397]     Test net output #0: loss = 0.905341 (* 1 = 0.905341 loss)
I0626 09:18:40.855201 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.683281
I0626 09:18:40.855239 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.912188
I0626 09:18:43.326639 55699 solver.cpp:218] Iteration 9200 (0.230905 iter/s, 216.539s/50 iters), loss = 0.64963
I0626 09:18:43.326874 55699 solver.cpp:237]     Train net output #0: loss = 0.64963 (* 1 = 0.64963 loss)
I0626 09:18:43.326987 55699 sgd_solver.cpp:105] Iteration 9200, lr = 1e-05
I0626 09:20:47.371706 55699 solver.cpp:218] Iteration 9250 (0.403083 iter/s, 124.044s/50 iters), loss = 0.867206
I0626 09:20:47.371932 55699 solver.cpp:237]     Train net output #0: loss = 0.867206 (* 1 = 0.867206 loss)
I0626 09:20:47.371958 55699 sgd_solver.cpp:105] Iteration 9250, lr = 1e-05
I0626 09:22:49.201403 55699 solver.cpp:330] Iteration 9300, Testing net (#0)
I0626 09:23:53.699656 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 09:24:20.206961 55699 solver.cpp:397]     Test net output #0: loss = 0.924526 (* 1 = 0.924526 loss)
I0626 09:24:20.207046 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.668125
I0626 09:24:20.207068 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.915156
I0626 09:24:22.700867 55699 solver.cpp:218] Iteration 9300 (0.232204 iter/s, 215.328s/50 iters), loss = 0.939246
I0626 09:24:22.700984 55699 solver.cpp:237]     Train net output #0: loss = 0.939246 (* 1 = 0.939246 loss)
I0626 09:24:22.701059 55699 sgd_solver.cpp:105] Iteration 9300, lr = 1e-05
I0626 09:26:26.083055 55699 solver.cpp:218] Iteration 9350 (0.405245 iter/s, 123.382s/50 iters), loss = 0.783299
I0626 09:26:26.083290 55699 solver.cpp:237]     Train net output #0: loss = 0.783299 (* 1 = 0.783299 loss)
I0626 09:26:26.083313 55699 sgd_solver.cpp:105] Iteration 9350, lr = 1e-05
I0626 09:27:15.729653 55702 data_layer.cpp:73] Restarting data prefetching from start.
I0626 09:28:27.952059 55699 solver.cpp:330] Iteration 9400, Testing net (#0)
I0626 09:29:59.684528 55699 solver.cpp:397]     Test net output #0: loss = 0.909093 (* 1 = 0.909093 loss)
I0626 09:29:59.684749 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.68125
I0626 09:29:59.684777 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.912969
I0626 09:30:02.131522 55699 solver.cpp:218] Iteration 9400 (0.23143 iter/s, 216.048s/50 iters), loss = 0.85951
I0626 09:30:02.131630 55699 solver.cpp:237]     Train net output #0: loss = 0.85951 (* 1 = 0.85951 loss)
I0626 09:30:02.131676 55699 sgd_solver.cpp:105] Iteration 9400, lr = 1e-05
I0626 09:32:07.359948 55699 solver.cpp:218] Iteration 9450 (0.399272 iter/s, 125.228s/50 iters), loss = 0.78833
I0626 09:32:07.360162 55699 solver.cpp:237]     Train net output #0: loss = 0.78833 (* 1 = 0.78833 loss)
I0626 09:32:07.360185 55699 sgd_solver.cpp:105] Iteration 9450, lr = 1e-05
I0626 09:34:10.529055 55699 solver.cpp:330] Iteration 9500, Testing net (#0)
I0626 09:34:36.212034 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 09:35:42.530153 55699 solver.cpp:397]     Test net output #0: loss = 0.912734 (* 1 = 0.912734 loss)
I0626 09:35:42.530333 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.681875
I0626 09:35:42.530364 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.914062
I0626 09:35:45.061731 55699 solver.cpp:218] Iteration 9500 (0.229673 iter/s, 217.701s/50 iters), loss = 0.84248
I0626 09:35:45.061841 55699 solver.cpp:237]     Train net output #0: loss = 0.84248 (* 1 = 0.84248 loss)
I0626 09:35:45.061866 55699 sgd_solver.cpp:105] Iteration 9500, lr = 1e-05
I0626 09:37:51.148772 55699 solver.cpp:218] Iteration 9550 (0.396555 iter/s, 126.086s/50 iters), loss = 0.906136
I0626 09:37:51.149183 55699 solver.cpp:237]     Train net output #0: loss = 0.906136 (* 1 = 0.906136 loss)
I0626 09:37:51.149205 55699 sgd_solver.cpp:105] Iteration 9550, lr = 1e-05
I0626 09:39:53.512697 55699 solver.cpp:330] Iteration 9600, Testing net (#0)
I0626 09:41:10.735082 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 09:41:25.385351 55699 solver.cpp:397]     Test net output #0: loss = 0.916536 (* 1 = 0.916536 loss)
I0626 09:41:25.387925 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.675937
I0626 09:41:25.387955 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.914688
I0626 09:41:27.850282 55699 solver.cpp:218] Iteration 9600 (0.230733 iter/s, 216.701s/50 iters), loss = 0.829849
I0626 09:41:27.850386 55699 solver.cpp:237]     Train net output #0: loss = 0.829849 (* 1 = 0.829849 loss)
I0626 09:41:27.850411 55699 sgd_solver.cpp:105] Iteration 9600, lr = 1e-05
I0626 09:43:34.022979 55699 solver.cpp:218] Iteration 9650 (0.396284 iter/s, 126.172s/50 iters), loss = 0.735203
I0626 09:43:34.023219 55699 solver.cpp:237]     Train net output #0: loss = 0.735203 (* 1 = 0.735203 loss)
I0626 09:43:34.023247 55699 sgd_solver.cpp:105] Iteration 9650, lr = 1e-05
I0626 09:45:36.262527 55699 solver.cpp:330] Iteration 9700, Testing net (#0)
I0626 09:47:08.146598 55699 solver.cpp:397]     Test net output #0: loss = 0.916217 (* 1 = 0.916217 loss)
I0626 09:47:08.146756 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.669531
I0626 09:47:08.146946 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.919375
I0626 09:47:10.612689 55699 solver.cpp:218] Iteration 9700 (0.230852 iter/s, 216.589s/50 iters), loss = 0.676456
I0626 09:47:10.612902 55699 solver.cpp:237]     Train net output #0: loss = 0.676456 (* 1 = 0.676456 loss)
I0626 09:47:10.613013 55699 sgd_solver.cpp:105] Iteration 9700, lr = 1e-05
I0626 09:49:14.692026 55699 solver.cpp:218] Iteration 9750 (0.402969 iter/s, 124.079s/50 iters), loss = 0.906668
I0626 09:49:14.692312 55699 solver.cpp:237]     Train net output #0: loss = 0.906668 (* 1 = 0.906668 loss)
I0626 09:49:14.692370 55699 sgd_solver.cpp:105] Iteration 9750, lr = 1e-05
I0626 09:51:14.897382 55699 solver.cpp:330] Iteration 9800, Testing net (#0)
I0626 09:51:51.074652 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 09:52:45.378088 55699 solver.cpp:397]     Test net output #0: loss = 0.918155 (* 1 = 0.918155 loss)
I0626 09:52:45.378229 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.675469
I0626 09:52:45.378276 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.912031
I0626 09:52:47.771679 55699 solver.cpp:218] Iteration 9800 (0.234655 iter/s, 213.079s/50 iters), loss = 1.11169
I0626 09:52:47.771805 55699 solver.cpp:237]     Train net output #0: loss = 1.11169 (* 1 = 1.11169 loss)
I0626 09:52:47.771832 55699 sgd_solver.cpp:105] Iteration 9800, lr = 1e-05
I0626 09:54:49.416676 55699 solver.cpp:218] Iteration 9850 (0.411035 iter/s, 121.644s/50 iters), loss = 0.904991
I0626 09:54:49.416954 55699 solver.cpp:237]     Train net output #0: loss = 0.904991 (* 1 = 0.904991 loss)
I0626 09:54:49.417001 55699 sgd_solver.cpp:105] Iteration 9850, lr = 1e-05
I0626 09:56:48.981634 55699 solver.cpp:330] Iteration 9900, Testing net (#0)
I0626 09:58:15.060725 55703 data_layer.cpp:73] Restarting data prefetching from start.
I0626 09:58:18.665665 55699 solver.cpp:397]     Test net output #0: loss = 0.912807 (* 1 = 0.912807 loss)
I0626 09:58:18.665750 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.672344
I0626 09:58:18.665776 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.915
I0626 09:58:21.037525 55699 solver.cpp:218] Iteration 9900 (0.236273 iter/s, 211.62s/50 iters), loss = 1.01068
I0626 09:58:21.037634 55699 solver.cpp:237]     Train net output #0: loss = 1.01068 (* 1 = 1.01068 loss)
I0626 09:58:21.037820 55699 sgd_solver.cpp:105] Iteration 9900, lr = 1e-05
I0626 10:00:22.803813 55699 solver.cpp:218] Iteration 9950 (0.410624 iter/s, 121.766s/50 iters), loss = 0.819517
I0626 10:00:22.804230 55699 solver.cpp:237]     Train net output #0: loss = 0.819517 (* 1 = 0.819517 loss)
I0626 10:00:22.804253 55699 sgd_solver.cpp:105] Iteration 9950, lr = 1e-05
I0626 10:02:22.787652 55699 solver.cpp:447] Snapshotting to binary proto file /home/sun/MobileNet-Caffe-master/cifar10/model/sun_mobilenet_iter_10000.caffemodel
I0626 10:02:22.941501 55699 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/sun/MobileNet-Caffe-master/cifar10/model/sun_mobilenet_iter_10000.solverstate
I0626 10:02:23.913235 55699 solver.cpp:310] Iteration 10000, loss = 0.725427
I0626 10:02:23.913466 55699 solver.cpp:330] Iteration 10000, Testing net (#0)
I0626 10:03:53.850054 55699 solver.cpp:397]     Test net output #0: loss = 0.906747 (* 1 = 0.906747 loss)
I0626 10:03:53.850257 55699 solver.cpp:397]     Test net output #1: top1/acc = 0.681406
I0626 10:03:53.850284 55699 solver.cpp:397]     Test net output #2: top5/acc = 0.915937
I0626 10:03:53.850296 55699 solver.cpp:315] Optimization Done.
I0626 10:03:53.850364 55699 caffe.cpp:259] Optimization Done.
